The challenging problem of cooperative retransmission in the wireless networks is investigated in this paper. This paper introduces the centralized and distributed Markov decision process (MDP) frameworks in the context of cooperative retransmission. Specifically, a MDP model with the global channel information is first constructed for the cooperation problem in the MAC layer. It is shown that this global MDP is able to perform optimally, where the objective is to minimize the total number of required transmissions for a successful packet delivery to the destination. When the global information is unavailable, we show that the suitable distributed MDP models can replace the global model for a near-optimal performance. Furthermore, the reinforcement learning methods are investigated when the MDP model is unavailable. Interestingly, simulation results confirm that the learning methods also provide an acceptable performance despite their simplicity and low overhead.
