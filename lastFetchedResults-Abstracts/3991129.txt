A method is presented for nonlinear function identification and application to learning control. The control objective is to identify and compensate for a nonlinear disturbance function. The nonlinear disturbance function is represented as an integral of a predefined kernel function multiplied by an unknown influence function. Sufficient conditions for the existence of such a representation are provided. Similarly, the nonlinear function estimate is generated by an integral of the predefined kernel multiplied by an influence function estimate. Using the time history of the plant, the learning rule indirectly estimates the unknown function by updating the influence function estimate. It is shown that the estimate function converges to the actual disturbance asymptotically. Consequently, the controller achieves the disturbance cancellation asymptotically. The method is extended to repetitive control applications. It is applied to the control of robot manipulators. Simulation and actual real-time implementation results using the Berkeley/NSK robot arm show that the proposed learning algorithm is more robust and converges at a faster rate than conventional repetitive controllers
