Human-symbiotic systems have been increasingly studied in recent years. Objective recognition by such systems often does not agree with subjective recognition by users. Therefore, it is an important to estimate users´ subjective states appropriately. Information on what a user can see and what he/she cannot see in the environments is one of important clues to estimate his/her subjective states and predict next actions. In our previous work, we have proposed a system for estimating a user´s three-dimensional field of view using an RGB-D camera. This system can know what the user can/cannot see in environments in pixels of captured image. However, this system has only a single camera, so the field of estimation in the system is limited to be narrow. In this paper, to overcome this disadvantage, we propose a system for estimating a user´s field of view with multiple RGB-D cameras. The proposed system achieves the estimation in a wider region than the previous system by using the multiple cameras cooperatively. We show effectiveness of the proposed system through some experiments in real environments.
