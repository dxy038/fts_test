This paper presents a novel approach to explicit duration modelling for HMM-based speech synthesis. The proposed approach is a two-step process. The first step in this process is state level phone alignment and conversion of phone durations into the number of frames. In the second step, a hidden Markov model (HMM) is trained whereby the observation is the number of frames in each state and the hidden state the phone. Finally, the duration of each state (the number of frames) is generated from the trained HMM. Hidden semi-Markov model (HSMM) is the baseline for explicit duration modelling in HMM-based speech synthesis. Both objective and perceptual evaluation on a held-out test set showed comparable results with a baseline HSMM-based speech synthesis. This duration modelling approach is computationally simpler than HSMM and produces comparable results in terms of the quality of synthetic speech.
