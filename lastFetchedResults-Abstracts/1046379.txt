The primary objective of this study is to develop a numerical model for turbulent, free-falling liquid films subjected to sensible heating. The model is used to explore the influences of waves and interfacial dampening of turbulent eddies on fluid flow and heat transfer. The model represents two-dimensional axisymmetric film flow on a vertical circular tube, with both the computational domain and operating conditions matching those of an experimental database for water films. Interfacial waves are observed to be prevalent for all operating conditions and associated with a dominant repeated wave shape. Good agreement is achieved between the predicted axial variations of the heat transfer coefficient and experimental data, including an upstream decline in the upstream thermal development region, and slow downstream increase resulting from intensified turbulence and interfacial waviness. Predicted relations for both the film thickness and heat transfer coefficient are shown to agree well with popular experimental correlations. It is shown that turbulence is fully suppressed at the interface, with zero eddy diffusivity both at the wall and interface, and a maximum in between.
