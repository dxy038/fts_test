Support Vector Machines (SVM) are playing an increasing role for detection problems in various engineering domains, notably in statistical signal processing, pattern recognition, image analysis, and communication systems. In this paper, we present a new method for optimizing Support Vector Machines for classification problems. An implicit reformulation of the optimization problem is proposed. The bias term is added to the primal problem formulation, which leads to eliminating the equality constraint. In order to deal with large data set problems, we propose a decomposition method, Sequential Maximum Gradient Optimization (SMGO), that relies on the selection of the working set via the search of the highest absolute values of the gradient. Furthermore, considering the quadratic nature of the dual problem, the optimum step-size is analytically determined. Moreover the solution, the gradient and the objective function are recursively calculated. The Gram matrix has not to be stored. SMGO is easy to implement and able to perform on large data sets.
