We investigate visual feedback for virtual grasps, especially cues to improve behavior after real fingers enter a virtual object. To date, such visual cues have usually been developed in an ad-hoc manner, with minimal or no studies that can guide selection. Existing guidelines are based largely on other interaction types and provide inconsistent and potentially-misleading information when applied to grasping. We compare several different visual feedback types including those most commonly seen for virtual hand interaction and with some novel visual aspects. The visuals were tuned in a pilot study, and our main study evaluated results in terms of objective performance (finger penetration, release time, and precision) and subjective rankings. Performancewise, the most promising techniques all directly reveal penetrating hand configuration in some way. Subjectively, most techniques are better than simple interpenetrating visuals, with color changes being most promising. The results enable selection of the best cues based on the relevant tradeoffs. Results also provide a needed basis for more focused studies of specific visual cues and for better informing studies of multimodal feedback.
