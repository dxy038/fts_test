This paper presents a method to calibrate the gain and memory errors of a pipelined analog-to-digital converter (ADC) used in an adaptively equalized baseband receiver. Both types of errors degrade ADC linearity, which significantly limits overall system performance. Adaptive finite-impulse-response filters at the output of each pipeline stage correct gain and memory errors and also perform channel equalization. The least-mean-square (LMS) algorithm is used to adapt the filter coefficients. The objective is to minimize the mean square error across the sheer in the receiver. Simulation results are presented to demonstrate improved performance with calibration.
