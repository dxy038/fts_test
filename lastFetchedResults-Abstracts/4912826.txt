Fault detection and isolation (FDI) and design of optimal maintenance policies have been traditionally studied separately by the control community and domain experts on the one hand and the operations research community on the other. The objective of this paper is to provide a unified approach where maintenance decisions are driven by real-time FDI signals. Such an approach allows systematic analysis and design of FDI with the objective of minimizing the overall costs of operations and maintenance (O&amp;M). Our approach relies on the following steps. First, the information about the assets, their likely failure modes (as generated by failure modes and effects analysis or from historical service data), service business processes, and costs associated with fixing the assets are captured from designers or practitioners. The Unified Modeling Language (UML) is used as an expressive way to capture and display such information. Next, this information is used to arrive at a representation of the asset degradation and maintenance process as a Markov process. Finally, the asset management problem is formulated as an optimal control over the Markov process. We show how the fundamental properties of FDI drive the O&amp;M costs and the solution to the control problem through their impact on transition probabilities of the Markov process. We illustrate the approach by a numerical example for maintaining proper refrigerant charge levels in Rankine cycle equipment
