The Soil Moisture and Ocean Salinity (SMOS) mission carries the Microwave Imaging Radiometer using Aperture Synthesis (MIRAS) instrument. It is the first time that an interferometric radiometer is in orbit. The objective of this paper is to assess the quality of the brightness temperatures (TBs) derived from this novel instrument, as processed with the SMOS operational chain at the end of the SMOS commissioning phase. Extensive comparisons have been conducted between reconstructed TBs derived from MIRAS measurements (MIRAS TB) and TBs simulated using the default radiative transfer model implemented in the European Space Agency SMOS ocean salinity processor and the European Centre for Medium-Range Weather Forecast forcings. At first order, the North-South variability of MIRAS TB due to geophysical variations of temperature, salinity, and wind speed over the ocean is consistent with the simulated L-band signal, and the standard deviation of the MIRAS TB minus the model simulations is close to the theoretical radiometric resolution. On the other hand, biases of several Kelvins, that depend on the location in the field of view, are observed between averaged MIRAS TB and simulations. After these biases are removed, the North-South gradient of sea surface salinity is well sensed by MIRAS except at high wind speed.
