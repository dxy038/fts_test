Convergence dynamics of continuous-time bidirectional neural networks with constant transmission delays are studied. Without assuming the symmetry of synaptic connection weights and the monotonicity and differentiability of activation functions, Lyapunov functionals and Halanay-type inequalities are constructed and employed to derive delay independent sufficient conditions under which the continuous-time networks converge exponentially to the equilibria associated with temporally uniform external inputs to the networks. Discrete-time analogues of the continuous-time networks are formulated and we study their dynamical characteristics. It is shown that the convergence dynamics of the continuous-time networks are preserved by the discrete-time analogues without any restriction on the discretization step-size. Several examples are given to illustrate the advantages of the discrete-time analogues in numerically simulating the continuous-time networks.
