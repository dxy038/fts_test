In this paper, we formulate the problem of optimal disturbance rejection in the case where the disturbance is generated as the output of a stable system in response to an input which is assumed to be of unit amplitude, but is otherwise arbitrary. The objective is to choose a controller that minimizes the maximum amplitude of the plant output in response to such a disturbance. Mathematically, this corresponds to requiring uniformly good disturbance rejection over all time. Since the problem of optimal tracking is equivalent to that of optimal disturbance rejection if a feedback controller is used (see [7, sect. 5.6]), the theory presented here can also be used to design optimal controllers that achieve uniformly good tracking over all time rather than a tracking error whose L<inf>2</inf>-norm is small, as is the case with the currently popular <img alt="H_{\\infty }" src="/images/tex/3267.gif"/> theory. The present theory is a natural counterpart to the existing theory of optimal disturbance rejection (the so-called <img alt="H_{\\infty }" src="/images/tex/3267.gif"/> theory) which is based on the assumption that the disturbance to be rejected is generated by a stable system whose input is square-integrable and has unit energy. It is shown that the problem studied here has quite different features from its predecessor. Complete solutions to the problem are given in several important cases, including those where the plant is minimum phase or when it has only a single unstable zero. In other cases, procedures are given for obtaining bounds on the solution and for obtaining suboptimal controllers.
