The objective of image fusion is to combine relevant information from two or more images of the same scene into a single composite image which is suitable for human and machine perception. Spatial domain based methods produce spatial distortions in the fused image which can be well handled by the use of wavelet transform based methods. In this paper, we proposed a pixel-level image fusion scheme using multiresolution steerable pyramid wavelet transform. Wavelet coefficients at different decomposition levels are fused using absolute maximum fusion rule. Two important properties shift invariance and self-reversibility of steerable pyramid wavelet transform are advantageous for image fusion because they are capable to preserve edge information and hence reducing the distortion in the fused image. Experimental results show that the proposed method improves fusion quality by reducing loss of relevant information present in individual images. For quantitative evaluation, we have used fusion metrics as fusion factor, fusion symmetry, entropy and standard deviation.
