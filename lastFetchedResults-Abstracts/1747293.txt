Multitask learning or learning multiple related tasks simultaneously has shown a better performance than learning these tasks independently. Most approaches to multitask multiclass problems decompose them into multiple multitask binary problems, and thus cannot effectively capture inherent correlations between classes. Although very elegant, traditional multitask support vector machines are restricted by the fact that different learning tasks have to share the same set of classes. In this paper, we present an approach to multitask multiclass support vector machines based on the minimization of regularization functionals. We cast multitask multiclass problems into a constrained optimization problem with a quadratic objective function. Therefore, our approach can learn multitask multiclass problems directly and effectively. This approach can learn in two different scenarios: label-compatible and label-incompatible multitask learning. We can easily generalize the linear multitask learning method to the non-linear case using kernels. A number of experiments, including comparisons with other multitask learning methods, indicate that our approach for multitask multiclass problems is very encouraging.
