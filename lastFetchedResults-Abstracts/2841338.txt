Importance measure analysis judges the relative importance of components in a system and reveals how each component contributes to the system reliability. In the design of large and complex systems, importance measure analysis can therefore be employed to guide an optimization tool which design decisions to investigate to gain higher reliability. While previous research has mainly concentrated on developing analytical importance measure techniques, the automatic and frequent computing of importance measures as required in the context of design space exploration has got very few, if any attention. This paper presents a highly efficient technique to compute the reliability and structural importance measures of components of a system. The proposed technique considers the reliability of a system implementation and subsequently analyzes the importance measures of its components based on a state-of-the-art Monte Carlo simulation. The technique can therefore estimate the importance measures of all components concurrently, highly improving the performance of the computation compared, e. g., to the well-known Birnbaum approach by the factor of 2n with n being the number of components. Moreover, we show how this algorithm can be extended to support importance measure analysis in the existence of transient faults which is essential since in future systems, transient faults are expected to cause relatively more failures than permanent faults. We integrated the proposed analysis approach in an existing multi-objective local-search algorithm that is part of an automatic system-level design space exploration which seeks for system implementations with highest reliability at lowest possible cost. Experimental results show that the proposed algorithm performs efficiently with negligible imprecision, even for large realworld examples.
