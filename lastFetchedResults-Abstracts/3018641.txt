Over the last decade researchers have devised algorithms that can provide similarity measures between pairs of face images. These have been somewhat successful in estimating the similarities between face images under controlled conditions. However, those similarity measures do not parallel subjective similarity, as perceived by humans. In some applications it is important to have a similarity metric that closely parallels that of humans. This paper describes a method for discovering the high-level features that are used by humans to judge facial similarity through the use of "lexical basis functions" gleaned from a lexicon of the English language. This method estimates the similarity of each pair of images in a set of face images by two independent methods - by the subjective evaluation of human observers, and by the use of "lexical basis functions" to represent the multidimensional content of each image with a feature vector. The similarity measure computed with these feature vectors is shown to corr-elate with the subjective judgment of human observers, and thus provides both a more objective method for evaluating and expressing image content, and a possible path to automating the process of similarity measurement in the future.
