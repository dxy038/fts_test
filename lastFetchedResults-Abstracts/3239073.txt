Self-adaptive differential evolution (SaDE) is a wellknown DE variant, which has received considerable attention since it was developed. SaDE gradually adapts its trial vector generation strategy and the accompanying parameter setting via learning the preceding performance of multiple candidate strategies and their associated parameter settings. This work systematically investigates SaDE on the CEC-2013 real-parameter single-objective optimization testbed. Parameter sensitivity analysis is carried out by using advanced statistical hypothesis testing methods, aiming to detect statistically significantly superior parameter settings. This analysis reveals that SaDE is actually less sensitive to the parameter choice since quite a number of parameter settings can lead to the statistically significantly better performance than the other settings. Based on this finding, we report SaDEÂ´s performance using one of the parameter settings advocated by sensitivity analysis and statistically compare this performance with that of a widely used classic DE (DE/rand/1/bin). The comparison results significantly favor SaDE.
