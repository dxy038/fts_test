Recently, the authors have described two stochastic algorithms, based on the controlled random search, for the global optimization. This paper deals with the use of these algorithms in estimating the parameters of nonlinear regression models. Several criteria like residual sum of squares, sum of absolute deviations and sum of trimmed squares are chosen. The algorithms are experimentally tested on a set of the well-known tasks chosen in such way that most classical techniques based on objective function derivatives fail while treating them. The basic features of the algorithms (rate of convergence and reliability) as well as their applicability to nonlinear regression models are discussed in more detail.
