Laughter is one important aspect when it comes to non-verbal communication. Though laughter is often associated with the feeling of happiness, it may not always be the case; laughter may also portray different kinds of emotions. We infer that a variety of other emotions exist during laughter and occurrence and therefore investigate this phenomenon. It is the objective of this research to be able to identify the underlying emotions in Filipino laughter. This research focuses on studying existing machine learning techniques on emotion identification through audio signals from laughter in order to derive more suitable solutions. In this research, we present a comparative study of the performances of Multilayer Perceptron (MLP) and Support Vector Machines (SVM) using our system. Manual segmentation was done on recorded audio and pre- processing was implemented using low-pass filters. The 13 Mel-frequency cepstral coefficients (MFCCs) and prosodic features (pitch, intensity and formants), were extracted from audio signals and were separately fed to the machine classifier. Results had shown that highest rate of correctly classified instances is achieved using prosodic features only. MLP yielded a 44.4444% rate while SVM has a 18.5185% rate.
