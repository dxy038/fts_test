Recently Li et al. proposed a parameter selection method for Gaussian radial basis function (GRBF) in support vector machine (SVM). In his paper cosine similarity was calculated between two vectors based on the properties of GRBF kernel function. Li´s method can determine an optimal sigma in SVM and thus efficiently improve its performance, yet it is limited by only focusing on a fixed original feature space and may suffer if the space contains some irrelevant and redundant features, especially in a high-dimensional feature space. In this paper, Li´s method is extended to a flexible feature space so that feature selection and parameter selection are conducted at the same time. A feature subset and sigma are determined by minimizing the objective function that considers both within-class and between-class cosine similarities. Our experimental results demonstrate that the proposed method has a better performance than Li´s method and traditional SVM in terms of classification accuracy.
