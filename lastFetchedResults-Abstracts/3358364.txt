We consider closed-loop feedback (CLF) stochastic model predictive control of nonlinear time-invariant systems with imperfect state information. In this class of control problems, future information feedback is considered in the decision making process, and thus, the effect of the control influencing the state uncertainty is taken into account. The main challenge in the solution is to find a good approximation to the arising stochastic dynamic programming problem, which is computationally not tractable. In this work, future information is considered in the form of conditional state probability densities. Thus, the objective is it to optimize the state and its uncertainty as a combined problem. We propose to discretize the state space by a novel scenario generation approach based on deterministic sampling. A distance based threshold determines the narrowness of the discretization. The dynamic programming problem is formulated such that the approximate cumulative control cost function can be explicitly evaluated offline. The online calculation consists of a one-step prediction and the interpolation of the explicit cost function in order to calculate the control input. The effectiveness of this novel method is presented by means of a simulation.
