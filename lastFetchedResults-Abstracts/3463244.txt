As the input/output (I/O) data rate increases to several gigabits per second, determining the performance of high-speed interfaces using conventional simulation and measurement techniques is becoming very challenging. The models of the interconnects have to be broadband and accurate to represent high frequency and second-order effects such as frequency dependence of dielectric losses and surface roughness. The large and small signal behaviors of the transmitter and receiver circuitries have to be correctly represented in link analysis. In addition, the system simulation needs to properly capture the interactions between the circuits and interconnect subsystems to optimize the overall system. However, determining the values of the critical link parameters and their correlations can be complicated. Some of the key parameters are not deterministic and some cannot be observed directly. A combined modeling and measurement approach is indispensable to determine the performance of high-speed links. This paper presents the modeling and characterization techniques employed in the design and verification of a 16 Gb/s bidirectional asymmetrical memory interface. Direct frequency and time-domain methods as well as indirect techniques based on bit-error-rate testing are used to model and determine important link parameters. Complex de-embedding procedures are utilized to extract parameters from externally observed data. On-chip measurements are also used to complement off-chip instrumentation and accurately measure the true performance of the link. The modeling and characterization of prototypes are also discussed and model-to-hardware correlations are presented at component and system levels. Based on both simulation and measurement results, the behavioral model of the complete system is constructed and statistical simulation technique is used to predict the yield and performance at low bit error rate.
