This paper introduces a new approach to haptic feedback during teleoperated robot-assisted surgery. Haptic feedback allows to display to the surgeon the local mechanical properties of the tissue being manipulated, as well as additional information, such as navigation cues. However, when the same end-effector is used to present multiple types of information, there is the risk of confusing the sources of force feedback signals provided to the operator. The objective of this work is to study how to efficiently combine remote tissue sensing and haptic guidance, in order to make the surgeon aware of the source of the stimuli. We propose to use vibrotactile feedback to render navigation cues and kinesthetic feedback to reproduce the mechanical properties of the tissue. The viability of this approach is validated with two experiments where vibrotactile-guided navigation achieves promising performance and allows users to easily disambiguate forces due to the action of guiding constraints and forces due to the interaction with the remote tissue.
