In this paper we introduce a novel visual perception model that aims to quantify the localized tolerance to noise for arbitrary imagery. The model is built by mixing the outputs from entropy and a differential localized standard deviation filter. The mixture is then low-pass filtered and normalized to provide a model that produces substantially better perceptual hi-fidelity than existing tools of similar complexity. Although there exist numerous applications for the new model, from compression to medical imaging and denoising, we demonstrate its efficacy using an image annotation application. The objective is to embed 32 bits of meta-data into a single image in a way that is robust to aggressive JPEG compression and cropping. We demonstrate the effectiveness of the novel model as well as the developed annotation technology using a database of high-challenge images
