Bayesian maximum a posteriori estimation (MAP) is a very popular way to recover unknown signals and images by using jointly observed data and priors formulated as a probability law. In a variational context, a MAP estimate minimizes an objective function where the priors are seen as a regularization or diffusion term. Independently of such interpretations, MAP estimates are implicit functions of the data and of the functions expressing the priors. This point of view enabled the author to exhibit analytical relations between prior functions and the features of the relevant estimates. These results entail important consequences and questions which are the subject of this paper. Namely, they reveal an essential gap between prior models and the way these are effectively involved in a MAP estimate. Hence the question about the rationale of MAP estimation. At the same time, they give precious indications about the hyperparameters and suggest how to construct estimators which indeed respect the priors
