This paper investigates the potential of the compressed sensing (CS) paradigm for video streaming in Wireless Multimedia Sensor Networks. The objective is to study performance limits and outline key design principles that will be the basis for cross-layer protocol stacks for efficient transport of compressive video streams. Hence, this paper investigates the effect of key video parameters (i.e., quantization, CS samples per frame, and channel encoding rate) on the received video quality of CS images transmitted through a wireless channels. It is shown that, unlike JPEG-encoded images, CS-encoded images exhibit an inherent resiliency to channel errors, caused by the unstructured image representation; this leads to basically zero loss in image quality for random channel bit error rates as high as 10<sup>-4</sup>, and low degradation up to 10<sup>-3</sup>. Furthermore, it is shown how, unlike traditional wireless imaging systems, forward error correction is not beneficial for wireless transmission of CS images. Instead, an adaptive parity scheme that drops samples in error is proposed and shown to improve image quality. Finally, we present our initial investigations on a low-complexity, adaptive video encoder that performs low-complexity motion estimation.
