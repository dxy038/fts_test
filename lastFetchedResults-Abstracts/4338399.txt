This paper presents a solution to the problem of timing measurements for the optimal control of stochastic dynamical systems. It is demonstrated that the optimal timing of measurements depends on the optimal control problem being considered. These type of problems arises in many application areas where there is a cost associated in making measurements. These results provide techniques necessary for the design of control systems requiring a minimum number of measurements and also those systems for which there is a measurement budget. Furthermore, it is shown that considering an estimation objective only, i.e., the measurement sequence which gives the smallest variance at the final time, is not necessarily the best policy if the estimate is to be used to optimally control the observed process
