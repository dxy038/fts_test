In this paper, we introduce a continuous-time distributed algorithm, which enables nodes in a static, undirected network to cooperatively solve a convex optimization problem, where the objective function is a sum of uniformly strictly convex functions observed locally by the nodes, and the feasible set is defined by inequality/equality constraints known to every node. The algorithm operates by forcing the node estimates of the unknown minimizer to achieve consensus, while satisfying Karush-Kuhn-Tucker-like conditions. By using a Lyapunov-like function defined by the Bregman divergence of the individual problem Lagrangian and analyzing its upper right-hand derivative, we show that our algorithm asymptotically drives all the estimates to the minimizer. The results of this paper generalize our earlier Zero-Gradient-Sum algorithms for problems without constraints, and relax the required assumption from strong convexity to uniform strict convexity.
