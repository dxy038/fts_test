Following an overview of two-dimensional (2-D) parametric motion models commonly used in video manipulation and compression, we introduce trifocal transfer, which is an image-based scene representation used in computer vision, as a motion compensation method that uses three frames at a time to implicitly capture camera/scene motion and scene depth. Trifocal transfer requires a trifocal tensor that is computed by matching image features across three views and a dense correspondence between two of the three views. We propose approximating the dense correspondence between two of the three views by a parametric model in order to apply the trifocal transfer for object-based video compression and background mosaic generation. Backward, forward, and bidirectional motion compensation methods based on trifocal transfer are presented. The performance of the proposed motion compensation approaches using the trifocal model has been compared with various other compensation methods, such as dense motion, block motion, and global affine transform on several video sequences. Finally, video compression and mosaic synthesis based on the trifocal motion model are implemented within the MPEG-4 Video Verification Model (VM), and the results are compared with those of the standard MPEG-4 video VM. Experimental results show that the trifocal motion model is superior to block and affine models when there is depth variation and camera translation
