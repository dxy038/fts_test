This paper proposes a neural network based self-organing control concept for a robotic manipulator. The end-effector position and orientation control loop is closed using visual data to generate the necessary manipulator control inputs. The objective is to move the end-effector to a place, where the manipulator can easily grip a given object. Instead of processing inverse kinematics, the nonlinear mapping between image data and joint angles is learned using two neural networks. The system organizes itself for any manipulator configuration by this learning process. The effectiveness of the proposed system is confirmed by computer simulations.
