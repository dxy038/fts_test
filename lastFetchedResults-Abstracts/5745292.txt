Many interesting papers have been written in the recent past on kernel clustering and many attractive results have also been demonstrated. Here we question the rationality behind such clustering approaches. Using simple data sets we argue and demonstrate that it is not a good idea to find clusters in the kernel space when the objective is to look for clusters in the original data because in the kernel space the data may have a different geometry from that in the original feature space. In particular we demonstrate the following : (1) improper choice of the number of clusters may lead to very counterintuitive clusters (e.g., instead of merging nearby clusters, it may merge clusters that are far from each other) and (2) improper choice of kernel parameters has a significant effect on the extracted clusters and it can even impose arbitrary cluster structures that are undoubtedly absent in the original data. However, we definitely do not imply that kernel clustering can never produce desirable results. In fact, kernel clustering could be useful provided we can choose right kernel parameters. But the process being unsupervised, we do not have a solution to this issue yet. In this study, for illustration, we use one variant of the kernel Fuzzy C-Means (KFCM) clustering algorithm in conjunction with Polynomial kernels.
