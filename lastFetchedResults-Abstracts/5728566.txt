The objective of this work is to explore the potential use of electroencephalography (EEG) as a means for silent communication by way of decoding imagined speech from measured electrical brain waves. EEG signals were recorded at University of California, Irvine (UCI) from 7 volunteer subjects imagining two syllables, /ba/ and /ku/, without speaking or performing any overt actions. Our goal is to classify these imagined syllables and based on the resulting accuracy assess the feasibility of this task. In this research, the EEG data are preprocessed to reduce the effects of artifacts and noise, and autoregressive (AR) coefficients are extracted as features for imagined syllable classification using a k-Nearest Neighbor classifier. Initial results suggest that it is possible to identify imagined speech.
