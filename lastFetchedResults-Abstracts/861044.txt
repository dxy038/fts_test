Based on the identification technique of active constraints, we propose a Newton-like algorithm and a quasi-Newton algorithm for solving the box-constrained optimization problem. The two algorithms require only the solution of a lower-dimensional system of linear equations at each iteration. In the proposed quasi-Newton algorithm, we make use of an approximate direction derivative of the multiplier functions so that only first-order derivatives of the objective function are needed to evaluate. Under mild assumptions, global convergence of the two algorithms is established. In particular, locally quadratic convergence for the Newton-like algorithm and locally superlinear convergence for the quasi-Newton algorithm are obtained without assuming that the strict complementarity condition holds at the solution.
