Motivated by concepts in quantum mechanics and particle swarm optimization (PSO), quantum-behaved particle swarm optimization (QPSO) was proposed as a variant of PSO with better global search ability. Although it has been shown to perform well in finding optimal solutions for many optimization problems, there has so far been little theoretical analysis on its convergence and performance. This paper presents a convergence analysis and performance evaluation of the QPSO algorithm and it also proposes two variants of the QPSO algorithm. First, we investigate in detail the convergence of the QPSO algorithm on a probabilistic metric space and prove that the QPSO algorithm is a form of contraction mapping and can converge to the global optimum. This is the first time that the theory of probabilistic metric spaces has been employed to analyze a stochastic optimization algorithm. We provided a new definition for the convergence rate of a stochastic algorithm as well as definitions for three types of convergence according to the correlations between the convergence rate and the objective function values. With these definitions, the effectiveness of the QPSO is evaluated by computing and analyzing the time complexity and the convergence rate of the algorithm. Then, the QPSO with random mean best position (QPSO-RM) and the QPSO with ranking operator (QPSO-RO) are proposed as two improvements of the QPSO algorithm. Finally, some empirical studies on popular benchmark functions are performed in order to make a full performance evaluation and comparison between QPSO, QPSO-RM, QPSO-RO and other variants of PSO.
