As the density in digital magnetic recording is increased, various linear as well as nonlinear signal distortions affect the performance of detection algorithms. These include transition noise and electronics noise. The objective of this work is to evaluate the performances of several detection techniques at different linear densities, noise environments, and channel mismatch conditions using Monte Carlo simulation. The algorithms considered are the conventional peak detection, various maximum likelihood sequence detection methods and decision feedback type techniques
