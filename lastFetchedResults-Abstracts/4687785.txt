In this paper we propose a framework for activity recognition based on space-time interest point in video surveillance. Single type interest point feature is not sufficient to identify the activity therefore we have considered multi-class activities fussed in three dimensional (spatial &amp; time) coordinate to achieve our objective with maximum accuracy. Our experiment shows that fusing multi class activity using global feature provides a copious representation of human daily action when compared to the use of a single feature type. This paper model the spatial temporal distribution of interest points for identification of various short or long duration activities. It is scalable in nature and work efficiently under conditions of dynamic background, changing camera view angle or zooming, front and sidelong activities. It assumes that human being is performing action. The experiment on two benchmark datasets show propitious results when compared with the state-of-the-art methods.
