The authors consider the problem of optimal allocation of measurement resources when: (1) the total measurement cost and time duration of measurements is fixed; and (2) the cost of an individual measurement varies inversely with the (controllable) measurement accuracy. The objective is to determine the time distribution of measurement variances that minimizes a measure of error in forecasting a discrete-time, vector stochastic process by a linear estimator. The metric of estimation error used is the trace of weighted sum of estimation error covariance matrices at various time indices. When the stochastic process is a scalar, it is shown that this problem reduces to solving a quadratic programming problem with nonnegativity constraints on the optimization variables. For the special case when the vector stochastic process is the state of a linear, finite-dimensional stochastic system, the problem reduces to the solution of a nonlinear optimal control problem
