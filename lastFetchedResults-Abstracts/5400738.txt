In AI systems so far developed, more knowledge (typically stored as "rules") entails slower processing; in the case of humans, the more knowledge attained (in the form of experience), the speed/efficiency of performing new related tasks is improved. Experience-based (EB) identification and control is explored with the objective of achieving more human-like processes for \´intelligent\´ computing agents. The notion of experience is being successfully addressed via a novel concept for applying reinforcement learning (RL), called HLLA -higher level learning algorithm. The key idea is to re-purpose the RL method (to a "higher level") such that instead of creating an optimal controller for a given task, an already achieved collection of such solutions for a variety of related contexts is provided (as an experience repository), and HLLA creates a strategy for optimally selecting a solution from the repository. The selection process is triggered by the agent becoming aware that a change in context has occurred, followed by the agent seeking information about what changed -a process here called context discernment - and finally, by selection. Typically, context discernment entails a form of system identification (SID); substantial enhancement of SID is also achieved via the EB methods. Examples are given.
