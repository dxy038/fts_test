This paper presents a new method for automatic generation of speaker-dependent phonological rules in order to decrease recognition errors caused by pronunciation variability. The proposed method generates phonological rules by using objective speakerÂ´s continuous speech and corresponding standard pronunciation, resulting in forming a multiple-pronunciation dictionary from a single-pronunciation dictionary. The method makes it possible to generate automatically speaker-dependent and recognizer-dependent phonological rules, and be applied to both a top-down recognizer and a bottom-up recognizer, while conventional methods are based on hand-derived general phonological rules such as coarticulation knowledge or are applied only to a bottom-up recognizer. Phrase recognition experiments with concatenated phoneme HMMs showed that the generated rules can decrease recognition errors and play a role of speaker adaptation at the phonological level
