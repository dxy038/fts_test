We introduce an input system that is based on bidirectional strokes that are segmented by tactile landmarks. By giving the user tactile feedback about the length of a stroke during input, we decrease the dependence of the GUI on the visual display. By concatenating separate strokes into multistrokes, complex commands may be entered, which may encode commands, data content, or both simultaneously. To demonstrate their power, we show how multistrokes can be used to traverse a menu hierarchy quickly. In addition, we show how inter-landmark segments of the sensor may be used for continuous and discrete parameter entry, resulting in a multifunctional interaction paradigm. We also introduce multiwidgets, which allow the direct control of multiple virtual widgets without the need to change the state of the device or use modifier buttons. This approach to input does not depend on material displayed visually to the user, and, thanks to tactile guidance, may be used by expert users as an eyes-free user interface. We believe that these benefits make this interaction system especially suitable for wearable computer systems that use a head-worn display and wrist-worn watch-style devices.
