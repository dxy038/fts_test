Egocentric videos are foreseen to be collected pervasively as smart glasses continue emerging in the market. Large amount of interpersonal social events will be recorded and stored online as big video data. However, limited method has been proposed to retrieve useful social information from them, such as other peopleÂ´s identity, emotion and head gestures. In this paper, we propose retrieving 3D facial shape motion, which can be further used in estimating these facial related information during social interaction. In order to achieve this objective, we opt to adopt two major methods, including facial landmark localization on 2D videos and 3D shape reconstruction. Our system incorporates these methods into the map-reduce framework such that big video data can be processed in a scalable manner. Tested on a public facial dataset, the proposed system has greatly improved time efficiency by 92% on a private cloud. The experimental results have also demonstrated the scalability of the proposed system.
