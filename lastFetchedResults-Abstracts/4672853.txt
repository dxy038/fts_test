A procedure has been developed for estimating the optimum allocation of distributed generation (DG) units in distribution systems. The approach is based on a single-target model in which the objective is loss minimization. The main goal of this work is to explore the application of a Monte Carlo based method for loss minimization of a three-phase distribution system when considering the intermittent nature of some distributed resources and the time varying shape of the node loads. The procedure has been implemented in an open environment in which OpenDSS is driven from MATLAB. Some examples illustrate the scope of the proposed procedure.
