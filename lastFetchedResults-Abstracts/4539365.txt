The author describes development of a voiced/unvoiced speech classifier using a multilayer perceptron. The goal is to design an accurate classifier which performs well for speech outside the training set. This includes speech with background noise present and speech collected from microphones whose frequency response varies to a small degree from that used to collect the training speech. Several combinations of voicing features are examined as inputs to the classifier. Three objective functions for classifier training are compared. Performance with and without a hidden layer is compared with that of a linear discriminant designed with FisherÂ´s method. Over 30000 frames of hand classified speech are used for training and testing. A classifier with an error rate of less than 2% on the training data is found
