We study the distributed subgradient method for multi-agent optimization problem, where multiple agents try to cooperatively optimize the sum of their local convex objective functions but subject to communication delays. By augmenting delay nodes in communication network, the optimization problem with communication delays is converted into the optimization problem without communication delays. Meanwhile, the corresponding adjacency matrix associated with the augmented communication network may be stochastic and all its diagonal entries are not necessarily positive. Thus, this weakens some typical requirements for the adjacency matrix in literature. Then with the help of the related result of non-reversible Markov theory, we prove that the convergence of the proposed optimization algorithm can still be guaranteed provided that communication delays are upper bounded. The obtained results show that communication delays induce more updated errors. Finally, an example is given to demonstrate the effectiveness of the optimization algorithm.
