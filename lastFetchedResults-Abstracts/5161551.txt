The objective of this study is to investigate alternative ways for representing suitably, with the fewest possible assumptions, the information derived from video recordings. It proposes a set of statistical descriptors capable of summarizing all the available information from each video frame. A sequence of such features expresses the object motion implicitly without the need for object detection techniques and tedious pre-processing. A video application such as the human action recognition is then tackled as a time-series classification problem. Neural networks are used for the time-series learning; when they are simulated with a new human action video, their predictions constitute the input a typical classifier would require, in order for it to decide which model (from the known time-series) has possibly generated this video.
