Neural networks (NNs) that are trained to perform classification may not perform as well when used as a module in a larger system. We introduce a novel, system-level method for training NNs with application to counting white blood cells. The idea is to phrase the objective function in terms of total count error rather than the traditional class-coding approach because the goal of this particular recognition system is to accurately count white blood cells of each class, not to classify them. An objective function that represents the sum of the squared counting errors (SSCE) is defined. A batch-mode training scheme based on back-propagation and gradient descent is derived. Sigma and crisp counts are used to evaluate the counting performance. The testing results show that the network trained to minimize SSCE performs better in counting than a classification network with the same structure even though both are trained a comparable number of iterations. This result is consistent with the principle of least commitment of D. Marr (1982)
