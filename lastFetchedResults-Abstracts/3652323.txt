Methods for conducting model-based computer vision from low-SNR (&#10877;1 dB) image data are presented. Conventional algorithms break down in this regime due to a cascading of noise artifacts, and inconsistencies arising from the lack of optimal interaction between high- and low-level processing. These problems are addressed by solving low-level problems such as intensity estimation, segmentation, and boundary estimation jointly (synergistically) with intermediate-level problems such as the estimation of position, magnification, and orientation, and high-level problems such as object identification and scene interpretation. This is achieved by formulating a single objective function that incorporates all the data and object models, and a hierarchy of constraints in a Bayesian framework. All image-processing operations, including those that exploit the low and high-level variables to satisfy multi-level pattern constraints, result directly from a parallel multi-trajectory global optimization algorithm. Experiments with simulated low-count (7-9 photons/pixel) 2-D Poisson images demonstrate that compared to non-joint methods, a joint solution not only results in more reliable scene interpretation, but also a superior estimation of low-level imaging variables. Typically, most object parameters are estimated to within a 5% accuracy even with overlap and partial occlusion
