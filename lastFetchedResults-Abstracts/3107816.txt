We consider the problem of using an exponential detection function to search for a target whose motion is a Markov process satisfying a stochastic differential equation of the diffusion type. The overall objective is to minimize the probability of nondetection. The approach is to reformulate the problem as one of seeking an optimal control (search strategy) with an optimal stopping time. The decision as to whether or not to stop searching corresponds to whether or not the target has been detected, and the goal is to detect while expending a minimum amount of search effort. The final results appear in the form of a normed BellmanÂ´s equation or, equivalently, in terms of a variational inequality, and constitute a set of sufficient conditions for the optimal strategy. Some previous approaches to the problem using other techniques and assumptions are also discussed for comparative purposes.
