This paper proposes a scheme of emotion recognition from audio-visually stimulated EEG (electroencephalography) signals, the choice of signal being influenced by the fact that these signals are the direct unaltered outcome of oneÂ´s brain activity and hence cannot be voluntarily suppressed. The EEG signals have been recorded using the NEUROWIN EEG amplifier of Nasan Medicals with a sampling rate of 250Hz from electrodes positioned at F3, F4, Fp1 and Fp2, since they lie over the frontal and pre-frontal lobe. The Raw EEG signals obtained need to be processed and classified into different emotional categories, using various features and intelligent classification algorithms. Features from these signals have been extracted using wavelet transform, statistical parameters and Hjorth parameter estimation, which are then classified using linear support vector machine (LSVM) and k-nearest neighbour (kNN). These extracted features are classified into the two different negative emotion classes of sad and disgust, with an average classification accuracy of the sad emotion being 78.04% and disgust being 76.31%. With our objective of development of emotionally challenged machines and devices that could become compatible with the emotional state of the user and nullify the effects of negative emotions on their work performance; the proposed scheme takes us a step closer to realisation of the same.
