We formulate and analyze a dynamic scheduling problem for a class of transportation systems in a Markov Decision Process (MDP) framework. A transportation system is represented by a polling model consisting of a number of stations and a server with switch-over costs and constraints on its movement (the model we have analyzed is intended to emulate key features of an elevator system). Customers request service in order to be transported by the server from various arrival stations to a common destination station. The objective is to minimize a cost criterion that incorporates waiting costs at the arrival stations. Two versions of the basic problem are considered and structural properties of the optimal policy in each case are derived. It is shown that optimal scheduling policies are characterized by switching functions dependent on state information consisting of queue lengths formed at the arrival stations.
