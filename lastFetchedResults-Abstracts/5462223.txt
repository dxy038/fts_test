Over the last decade, many methods for adaptively filtering two-dimensional (2D) or three-dimensional (3D) datasets have been proposed. Although the primary objective of this filtering technique is to reduce the noise while avoiding blurring the edges, applications aimed at diagnostic, automated segmentation and surgery show a growing interest in enhancing the features contained in the image flow. Most of the methods proposed so far emerged from studying the physics of the considered modality and therefore show only a marginal capability to be extended across modalities. Moreover, adaptive filtering belongs to the family of processing-intensive algorithms. Existing technology has often been driven to simplifications and modality specific optimization to sustain the expected performances. Using general-purpose graphic processing units (GPGPUs) or the cell broadband engine (CBE) processor for accelerating the backprojection step allows considering real-time tomographic reconstruction. In order to reduce the dose for realtime CT, adaptively filtering the 2D projections data prior to reconstructing the volume is a technique that has shown significant image quality improvements. In this study, we have taken a generalized approach for adaptive filtering based on multiple oriented filters. Mapping the filtering part to the embedded, real-time image processing while proposing a user/application-defined adaptive recombination of the filter outputs allow changing the smoothing and edge enhancement properties of the filter without changing the oriented-filter parameters. We have implemented the filtering on a CBE processor and the adaptive recombination on an off-the-shelf PC, connected via Gigabit Ethernet. This implementation is capable of filtering projections of 5122 pixels at a throughput in excess of 40 frames per second while allowing the change of the parameters in real time.
