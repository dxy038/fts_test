A framework is presented for the destabilization of dynamical systems that are subject to disturbances and controls. Such destabilizing controllers are designed using a methodology analogous to "gain scheduling". At each point in the state space, the controller is designed to destabilize the local linearization of the system. The local destabilization objective is formulated as a linear quadratic (LQ) optimal control problem with an indefinite performance objective, and is therefore similar to problems in differential games and H<sup>&#8734; </sup> norm calculations. Optimal feedback controls are thus readily computed by solving the appropriate Ricatti equations. This problem formulation is motivated by the objective of mixing enhancement in nonlinear dynamical systems, which in turn motivates the consideration of these LQ problems with finite-time horizons and exponentially discounted performance objectives
