The use of evolutionary programming to train a neural network is addressed by examining a simple classification problem involving two populations of interest. The first follows a Gaussian distribution having zero means and unit variance; the second is also Gaussian, but with a mean of one and unit variance. Ten independent samples are drawn from either one of the populations with the objective being to properly identify the appropriate underlying distribution. A network consisting of 10 input nodes, a single hidden layer of 10 nodes, and a final classifying node was constructed. To train the network, evolutionary programming was used to minimize the sum of the squared differences between each target output and the actual network output. A population of 10 parent vectors representing the 121 weights and biases of the network was maintained, and the limit of evolution was chosen to be 1000 generations. A training set of 100 patterns, 50 from each population, was determined randomly and then fixed for the extent of the evolution. The results indicate that evolutionary programming is useful for discovering the optimal set of weights in a neural network
