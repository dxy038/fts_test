Posterior probability support vector machines (PPSVMs) are proved to have good generalization performance and robustness against outliers. However, the disadvantage of a PPSVM is lack of sparseness of solution, i.e., the number of support vectors is still too large. This results in high computational burden and decision time. In this paper, we present two approaches to obtain sparse PPSVMs, which are expected to combine benefits of both PPSVMs and sparse classifiers. The first approach sparsifies the PPSVMs by adding l<sub>1</sub> norm penalties on the dual cost function of soft margin PPSVMs. The second one handles a mixed l<sub>1</sub>-l<sub>2</sub> multi-objective optimization by interior-point algorithm. Simulation results show that both approaches have good generalization performance, good robustness against outliers, and high efficiency on decision evaluation.
