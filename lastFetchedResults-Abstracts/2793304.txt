The principle objective of this paper is to demonstrate the learning capability of soar agent. An intelligent agent is an independent entity which observes through sensors and acts using actuators upon an environment. Intelligent agents learn the knowledge to achieve their goals and by learning, the agent will enhance its knowledge. This paper will elaborate the status of various memories i.e. semantic, episodic and working memory simultaneously. With the help of 8 puzzle game as an example, we present the learning capability, as by playing game repeatedly the soar agent will improve. Also we will use a unique memory representation method for representing various states of the game in memories so, that it will take less space to store the single state. We will show the whole process of solving impasses, creating sub goals, storing chunks in episodic memory from working memory etc.
