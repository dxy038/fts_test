In-network queuing in the Internet-style networks enables the distributed operation and scalability across the network at the cost of excessive delay and tardy flow completion times. Data center networking, in contrast, are proposed to depart from this classical approach and avoid in-network queuing all together. In this new class of network solutions serving interdata center traffic, a densely packed fairly local area network of stationary end hosts are often managed by a single entity, allowing for fine-grained management and scheduling of flows across the data center. The overall objective of this work is to develop a framework, from first principles, which relies on the unique attributes of data centers to propose a transformative novel networking architecture with increased level of efficiency and significantly smaller latency. By separating the control and data planes, the proposed hybrid architecture avoids in-network queuing and results in significantly lower delay. The critical technical challenge is to design end-end circuit switching mechanisms that account for monitoring as well as circuit reconfiguration delays. Furthermore, the design has to minimize the computational complexity of the scheduling algorithm as well as the cost of monitoring across the network. In this context, this paper underlines a family of recent technologies and networking advances as promising enablers and discusses the most significant set of challenges.
