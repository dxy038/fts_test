VoIP is very useful but it there are quality issues when delays or losses occur in the network. Thus, VoIP quality assessment for voice quality assurance or improvement is important. Voice quality assessment is mainly divided into objective and subjective methods. However, several researchers prefer subjective methods to objective methods because the term `voice qualityÂ´ is very subjective. According to that idea, this paper proposes a model for estimating VoIP quality provided by G.729, a common codec used over WAN, that has been created from subjective Mean Opinion Score (MOS), obtained from Thai users who use Thai, which is a tonal language and certainly different from other languages. For experiment and data gathering, the conversation-opinion tests with 354 native Thai users was conducted using a VoIP testbed system and G.729, under 17 test conditions, covering packet loss of 0-10% and packet delay of 0-800ms. Then, the gathered data was used to create the subjective MOS estimation model. Furthermore, a different set of subjective MOS data have been gathered from 64 native Thai users as the test set for the model evaluation. For model fitting, Matlab was applied, whereas Mean Absolute Percent Error (MAPE) was used for model evaluation. After obtaining the subjective MOS model, MAPE was calculated to evaluate the model. It has been found that the MAPE is 12.39%, which means this model is good (10% &lt;; MAPE &lt;; 20% means good). However, the MAPE may vary, depending on the test set. In conclusion, this paper presents a model of VoIP quality estimation for G.729 based on Thai users who communicate using the Thai language, called ThaiVQE-G729 for short. After evaluating the performance of this model, it has been confirmed that it is a good model. Therefore, this model is reliable and suitable to estimate MOS of G.729 in the Thai environment. Besides, this concept might be a prototype for other countries (e.g. China, Japan and Korea), due to the perceptual vo- ce quality can be affected by language and culture.
