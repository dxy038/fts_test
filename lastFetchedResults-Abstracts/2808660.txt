The objective of this work is to study the suitability of existing spectral mapping methods for enhancement of throat microphone (TM) speech, and propose a more elegant method for spectral mapping. Gaussian mixture models (GMM) and neural networks (NN) have been used for spectral mapping. Though GMM-based mapping captures the variability among speech sounds through multiple mixtures, it can only provide a linear map between the source and the target. On the other hand, NN-based mapping is capable of providing a nonlinear map but a single mapping scheme may not handle variability across different speech sounds. Incorporating the advantages from these approaches, we propose a spectral mapping method using multiple neural networks. Speech data is clustered using k-means algorithm, and a separate neural network is employed to capture the mapping within each cluster. Objective evaluation has shown that proposed method is better than both GMM-base and NN-base mapping schemes.
