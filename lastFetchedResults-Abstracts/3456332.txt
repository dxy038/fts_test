Dynamic game theory has recently received considerable attention as a possible technology for formulating control actions for decision makers in an extended complex enterprise that involves an adversary. Examples of such enterprises are very common in military operations. Enterprises of this type are typically modeled by a highly nonlinear discrete time dynamic system whose state is controlled by two teams of decision makers each with a different objective function and possibly with a different hierarchy of decision making. Because of the complexity of such systems, the traditional solutions from dynamic game theory that involve optimizing objective functions over the entire time horizon of the system are computationally extremely difficult, if not impossible, to derive. We discuss a solution approach where at each step the controllers limit the computation of their actions to a short time horizon that may involve only the next few time steps. This moving horizon solution, although suboptimal in the global sense, is very useful in taking into account the possible near-term control actions of the adversary. To illustrate this solution methodology, we consider an example of an extended military enterprise that involves two opposing forces engaged in a battle.
