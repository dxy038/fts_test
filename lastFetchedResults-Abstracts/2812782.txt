Only a small part of the large intensities interval found in high dynamic range scenes can be captured with usual image sensors. This is why delivered images may contain under or overexposed pixels. A popular approach to overcome this problem is to take several images using different exposure parameters, and then fuse them into one single image. This exposure fusion is mostly performed as a weighted average between the corresponding pixels. The challenge is to find weights that produce best fused image quality and in a minimum amount of operations to meet real time requirements. In this paper we present a supervised learning method to estimate generalized exposure fusion weights and we demonstrate how they can be used to fuse any exposures very fast. Subjective and objective comparisons with some relevant works are conducted to prove the effectiveness of the proposed method.
