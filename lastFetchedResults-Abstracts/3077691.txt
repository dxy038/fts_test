Our previous study on maximum relative margin estimation (MRME) of HMM (C. Liu et al., 2005) demonstrated its advantage over the standard minimum classification error (MCE) training. In this paper, we report our recent improvement on MRME. Specifically, two novel approaches are proposed to handle recognition errors in training sets for the MRME. One is a new training criterion based on a combination of MRME and MCE objective functions. The other approach proposes to remove a strong constraint in the original MRME algorithm, so that MRME algorithm can be applied to all training data as opposed to only correctly recognized data in the original MRME approach. Both new approaches can take advantage of more training data during the large margin training and can bootstrap directly from MLE models without a separate MCE training step. Improvement on recognition accuracy has been achieved on a speaker independent connected digit strings recognition task using the TIDIGITS database
