We consider the problem of binary hypothesis testing using binary decisions from independent and identically distributed (i.i.d). sensors. Identical likelihood-ratio quantizers with threshold &#955; are used at the sensors to obtain sensor decisions. Under this condition, the optimal fusion rule is known to be a k-out-of-n rule with threshold k. For the Bayesian detection problem, we show that given k, the probability of error is a quasi-convex function of &#955; and has a single minimum that is achieved by the unique optimal &#955;<sub>opt </sub>. Except for the trivial situation where one hypothesis is always decided, we obtain a sufficient and necessary condition on &#955;<sub>opt</sub>, and show that &#955;<sub>opt</sub> can be efficiently obtained via the SECANT algorithm. The overall optimal solution is obtained by optimizing every pair of (k, &#955;). For the Neyman-Pearson detection problem, we show that the use of the Lagrange multiplier method is justified for a given fixed k since the objective function is a quasi-convex function of &#955;. We further show that the receiver operating characteristic (ROC) for a fixed k is concave downward
