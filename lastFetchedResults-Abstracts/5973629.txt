Conjugate gradient methods are important for large-scale unconstrained optimization. In this paper, we propose anew formula &#195;&#159;<sub>k</sub> for unconstrained optimization, which is the hybrid from HS method, LS method and CD method. From the construction of the new formula &#195;&#159;<sub>k</sub>, we use a direction which is different from traditional d<sub>k</sub>. The direction satisfies descent conditions naturally. And d<sub>k</sub> <sup>T</sup>g<sub>k</sub>=-&#194;&#191;g<sub>k</sub>&#194;&#191;<sup>2</sup> depends neither on the line search used nor on the convexity of the objective function. Under suitable conditions, we prove that the new method can ensure the global convergence. Numerical experiments show that the algorithm is efficient.
