A Markov decision problem is formulated and solved for a redundant database system. The objective function is expressed in terms of the expenditure of average time required for the system to recover from server failures or to serve queries. Control actions include data restoration and system overhaul, and are taken based on the state of servers and the service demands. The steady-state availability of the database and the expected query response time are quantified under optimal control policies derived from several sets of cost criteria for the case of reduced state model that disregards the service demand information, as well as the full state model.
