Neural networks for linear and quadratic programming are analyzed. The network proposed by M.P. Kennedy and L.O. Chua (IEEE Trans. Circuits Syst., vol.35, pp.554-562, May 1988) is justified from the viewpoint of optimization theory and the technique is extended to solve optimization problems, such as the least-squares problem. For quadratic programming, the network converges either to an equilibrium or to an exact solution, depending on whether the problem has constraints or not. The results also suggest an analytical approach to solve the linear system <e1>Bx </e1>=<e1>b</e1> without calculating the matrix inverse. The results are directly applicable to optimization problems with <e1>C</e1><sup>2</sup> convex objective functions and linear constraints. The dynamics and applicability of the networks are demonstrated by simulation. The distance between the equilibria of the networks and the problem solutions can be controlled by the appropriate choice of a network parameter
