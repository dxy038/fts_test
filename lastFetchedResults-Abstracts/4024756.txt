This paper presents a method for the matching of underwater images acquired with acoustic sensors. As a final objective, the system aims at matching data from two-dimensional scenes. The proposed approach carries out a hypothetical reasoning based on objects, represented by shadows and echoes in the sonar images, and their available features. The problem of determining measures which are invariant to changes in sonar settings and noise characteristics is addressed by mapping robust features for sonar images to a qualitative representation. To cope with the viewpoint charging appearance, the method is based on the conservation of objects´ relative position from one image to another. We attempt to match geometrical structures formed by the association of three objects. The hypothetical reasoning is conducted in a decision tree framework. A tree node is generated by two objects´ association, each one belonging to a respective image. Hypotheses propagation consists of creating new nodes from neighboring associations. The matching solution is determined by the selection of the decision tree´s longest branch. Thus, the association mechanism is a depth-first procedure. The proposed method has been applied to real high-resolution side-scan sonar images. The matching process has shown successful and promising results which have been further improved. In particular, the parceled shadows (during the segmentation procedure) problem has been tackled
