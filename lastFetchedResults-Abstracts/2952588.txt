Successful practical applications of MLP networks trained by first order line search optimization approaches initiated a wave of interest in improving the speed of convergence and finding the optimum structure. Recently, training procedures have been implemented that incorporate dynamic structural changes of a network during a learning phase. The objective is to optimize the size of a network and yet maintain good performance. Essential part of structure modifying algorithms is the formulation of criteria for detecting the irrelevant structural elements. Performance measures for MLP networks previously designed by the authors (1997) allow the derivation of the individual performance measure Ipm(u<sub>1</sub>). The underlying reference ground for the individual performance measure Ipm(u<sub>1</sub>) is the estimate of a spectral radius of an error matrix for a neural network. The estimate of a spectral radius can be affected by imposed modifications of structure. This paper presents the first deterministic analytical apparatus for observing the effects of structural modifications on the estimate of a spectral radius. Theoretical material has wide applicability. However, it is especially useful for developing training procedures incorporating the dynamic structural changes and also for monitoring the performance of MLP networks
