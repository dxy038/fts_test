Many high-order systems have a large state space. Such systems need to additional computation time for complex calculation to find the output response. Traditionally, iteration methods have been applied to solve this problem. In this paper advantages of stability equation method derived by Parmer, [1], and the error minimization technique used in genetic-fuzzy algorithm have been combined to propose a new method for order reduction of linear dynamic systems described via state-space models. Genetic part has been used in this formulation to find the optimal solution(s) to minimize the objective function &#194;&#191;J&#194;&#191; that depends on the error term between the original output and the desired or reduced output. Fuzzy sets have been used to determine the step size action (point crossover or multiple crossover) depending upon fuzzy rules based on the current and previous error terms. An example of reduced order modeling from power systems is presented to illustrate the algorithm.
