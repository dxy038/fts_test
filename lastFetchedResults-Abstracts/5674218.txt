In this paper we consider a class of nonsmooth optimization problems and investigate an algorithm which makes use of approximations of the derivative. We study a growth condition on the objective and various conditions on the step-sizes and the Quasi-Newton operators to obtain linear, superlinear and quadratic rates of convergence. These results are applied to a class of Broyden updates and two inexact step-size rules.
