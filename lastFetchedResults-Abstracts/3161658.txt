The central goal in multiagent systems is to design local control laws for the individual agents to ensure that the emergent global behavior is desirable with respect to a given system level objective. In many systems, such as cooperative robotics or distributed power control, the design of these local control algorithms is further complicated by additional coupled constraints on the agentsÂ´ actions. There are several approaches in the existing literature for designing such algorithms stemming from classical optimization theory; however, many of these approaches are not suitable for implementation in multiagent systems. This paper seeks to address the design of such algorithms using the field of game theory. Among other things, this design choice requires defining a local utility function for each decision maker in the system. This paper seeks to address the degree to which utility design can be effective for dealing with these coupled constraints. In particular, is it possible to design local agent utility functions such that all pure Nash equilibrium of the unconstrained game (i) optimize the given system level objective and (ii) satisfy the given coupled constraint. This design would greatly simplify the distributed control algorithms by eliminating the need to explicitly consider the constraints. Unfortunately, we illustrate that designing utility functions within the standard game theoretic framework is not suitable for this design objective. However, we demonstrate that by adding an additional state variable in the game environment, i.e., moving towards state based games, we can satisfy these performance criteria by utility design. We focus on the problem of consensus control to illustrate these results.
