Recently announced RGB-D cameras like Microsoft Kinect are attractive sensing systems providing RGB images along with registered depth information at a high frame rate. This advantage makes such cameras greatly useful in the context of robotics, especially for dense 3D mapping in home environment. However, depth information they provide is usually incomplete and imprecise. This paper presents a method that effectively rectifies depth maps, particularly for missing regions, via fusion of 2D-3D images. Segmentation for plane fitting as well as Markov random field based optimization are applied successively to achieve our objective. We test our algorithm on a range of data with varying kinds and amount of incompleteness.
