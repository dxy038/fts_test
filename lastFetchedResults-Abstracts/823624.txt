A usual technique to generate upper bounds on the optimum of a quadratic 0–1 maximization problem is to consider a linear majorant (LM) of the quadratic objective function f and then solve the corresponding linear relaxation. Several papers have considered LMs obtained by termwise bounding, but the possibility of bounding groups of terms simultaneously does not appear to have been given much attention so far. In the present paper a broad and flexible computational framework is developed for implementing such a strategy. Here is a brief overview of our approach: in the first place, a suitable collection of “elementary” quadratic functions of few variables (typically, 3 or 4) is generated. All the coefficients of any such function (block) are either 1 or −1, and agree in sign with the corresponding coefficients of the given quadratic function. Next, for each block, a tightest LM (i.e., one having the same value as the block in as many points as possible), or a closest LM (i.e., one minimizing the sum of slacks) is computed. This can be accomplished through the solution of a small mixed-integer program, or a small linear program, respectively. Finally, the objective function is written as a weighted sum of blocks, with non-negative weights. Replacing in this expression each block by the corresponding LM yields an LM of f. We shall choose the weights in this process so that the maximum value of the resulting linear function is as small as possible. This amounts to a large-scale (but still polynomial-size) linear program, which may be solved exactly or, for larger instances, approximately by truncated column generation. The results of a set of 480 numerical tests with up to 200 variables are presented: the upper bounds on the quadratic optimum obtained by the above procedure are (provably) never worse, and often turn out to be substantially sharper, than those resulting from termwise bounding. Moreover, our bounds turn out to be close to the optimum in many (although not all) instances of some well-known benchmarks.
