The goal of this paper is to propose a new perceptually-based objective technique that uses radial basis functions neural networks, instead of regression algorithms, to estimate the nonlinear mapping function that best represents the relationship among input (perceptual parameters) and output (speech quality) variables in a database. In the proposed technique, the perceptual parameters are obtained by: (1) emulating several known features of perceptual processing of speech sounds by the human ear (including critical-band masking, equal loudness, and the intensity-loudness power law operations) to map the speech power spectrum into the auditory power spectrum (bark domain), (2) deriving the perceptual LPC coefficients from the auditory spectrum that is used to calculate, for each frame, the cepstrum distance between the input and the output coded speech signals; (3) using the radial basis functions neural network to map the perceptual cepstrum distance per frame into the corresponding estimated speech quality. After extensive experimentation and validation of the proposed techniques, the results indicate that the proposed technique is shown to be effective for estimating the coded speech quality
