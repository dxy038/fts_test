Let X be an Rd-valued random variable with unknown density f. Let X1, …, Xn be i.i.d. random variables drawn from f. The objective is to estimate f(x), where x=(x1, …, xd). We study the pointwise convergence of two new density estimates, the Hilbert product kernel estimated!n ∑i=1n ∏j=1d 12 log n |xj−Xij|, where Xi=(Xi1, …, Xid), and the Hilbert k-nearest neighbor estimatek(d−1)!2dn logd−1(n/(k(d−1)!)) ∏dj=1 |xj−X(k) j|, where X(k)=(X(k) 1, …, X(k) d), and X(k) is the kth nearest neighbor of x when points are ordered by increasing values of the product ∏dj=1 |xj−X(k) j|, and k=o(log n), k→∞. The auxiliary results needed permit us to formulate universal consistency results (pointwise and in L1) for product kernel estimates with different window widths for each coordinate, and for rectangular partitioning and tree estimates. In particular, we show that locally adapted smoothing factors for product kernel estimates may make the kernel estimate inconsistent even under standard conditions on the bandwidths.
