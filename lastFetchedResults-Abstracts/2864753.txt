Outlier detection is a method to improve performances of machine learning models. In this paper, we use an outlier detection method to improve the performance of our proposed algorithm called decision boundary making (DBM). The primary objective of DBM algorithm is to induce compact and high performance machine learning models. To obtain this model, the DBM reconstructs the performance of support vector machine (SVM) on a simple multilayer perceptron (MLP). If machine learning model has compact and high performance, we can implement the model into mobile application and improve usability of mobile devices, such as smart phones, smart tablets, etc. In our previous research, we obtained high performance and compact models by DBM. However in few cases, the performances are not well. We attempt to use a SVM-based outlier detection method to improve the performance in this paper. We define outlier using the method, and remove these outliers from training data that is generated by DBM algorithm. To avoid deleting normal data, we set a parameter &#948;<sub>outlier</sub>, which is used to control the boundary for deciding outlier point. Experimental results using public databases show the performance of DBM without outliers is improved. We investigate and discuss the effectiveness of parameter &#948;<sub>outlier</sub> as well.
