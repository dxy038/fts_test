A large number of non-dominated fuzzy rule-based classifiers are often obtained by applying a multiobjective fuzzy genetics-based machine learning (MoFGBML) algorithm to a pattern classification problem. The obtained set of non-dominated classifiers can be used to analyze their accuracy-interpretability tradeoff relation. One important issue, which has not been discussed in many studies on MoFGBML, is the choice of a single final classifier from a large number of non-dominated classifiers. The selected classifier is used for the classification of new input patterns. In this paper, we focus on this important research issue: classifier selection from a large number of non-dominated fuzzy rule-based classifiers. In general, it is not easy to choose a single final solution from non-dominated solutions in multiobjective optimization. This is because further information on the decision maker´s preference is needed to choose the single final solution. In addition to this general difficulty in multiobjective optimization, MoFGBML has its own difficulty in classifier selection, which is the difference between training data accuracy and test data accuracy. While our true objective is to maximize the test data accuracy (i.e., classifier´s generalization ability), only the training data accuracy is available for fitness evaluation and classifier selection. In this paper, we discuss why classifier selection is difficult in MoFGBML.
