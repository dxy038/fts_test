This paper considers the performance of cross-validation across runs in terms of efficiency and accuracy and a method for improving it. A heuristic method loosely inspired by MitchellÂ´s concept and version spaces technique is proposed for recognising when and to what extent the learning runs obtain an optimal generalisation performance. The approach used, the neural bidirectional convergence (NBDC), converges towards a solution from dual pairs of directions. The pair members provide complementary information for each other that is unavailable to uni-directional learning and which allows candidate concept elimination. Tests are carried out on classification problems in comparison with standard uni-directional cross-validation. The results indicate that NBDC is able to terminate learning at either more efficient junctures or with better generalisation accuracy or both depending on the problem
