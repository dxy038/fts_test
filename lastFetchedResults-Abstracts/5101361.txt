In this paper, we propose a novel large-margin based approach for multiple kernel learning (MKL) using biconvex optimization, called Adaptive Multiple Kernel Learning (AdaMKL). To learn the weights for support vectors and the kernel coefficients, AdaMKL minimizes the objective function alternately by learning one component while fixing the other at a time, and in this way only one convex formulation needs to be solved. We also propose a family of biconvex objective functions with an arbitrary &#8467;<sub>p</sub>-norm (p &#8805; 1) of kernel coefficients. As our experiments show, AdaMKL performs comparably with state-of-the-art convex optimization based MKL approaches, but its learning is much simpler and faster.
