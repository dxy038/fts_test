New techniques for circuit optimization, useful when the Hessian matrix of the objective function can be calculated explicitly, are investigated. First, a technique to save computation when calculating the gradient and Hessian is considered. Then it is shown that calculating the Hessian requires considerably more computation than calculating the gradient. To reduce the cost, three algorithms are developed. The first involves recomputing the Hessian less often than the gradient, while the other two are nonlinear search techniques, based on an incremental steepest descent, and minimization of a quadratic within a hypersphere. An algorithm combining all the ideas is presented, and shown to be effective with examples. An easily implemented check on the positive definiteness of the Hessian matrix is also explained, and shown to be advantageous.
