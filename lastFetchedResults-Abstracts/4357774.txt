The performance of machine learning algorithm depends on features considered from the dataset. High dimensional dataset degrades the performance of learning algorithm as learning algorithm try to analyze and accommodate all the features. Feature selection technique is used as a pre-processing step to analyze and compress large data set. The main objective of feature selection technique is to identify relevant features and removes redundant features from high dimensional dataset. The main goal of feature selection technique is to reduce dimensions of dataset, improve classification accuracy, reduce computational cost, and better visualization of data. By considering only useful features, the performance of classification algorithm can be improved. To select reduced set of relevant features from set of all features, various search techniques such as complete search, random search and sequential search etc. are used. Each generated subset of features is validated using various evaluation techniques such as filter, wrapper, and hybrid approach. The main aim of any search technique is to generate optimal subset of features. A general methodology of feature selection process is summarized in this paper on the basis of search and evaluation techniques. In this paper, we provide a comprehensive review of the recent developments in feature selection techniques. Classification with appropriate feature selection technique has shown better performance in the field of machine learning.
