We explore the idea of combining images from optical and SAR (synthetic aperture radar) sensors relative to the same scene on the Earth\Â´s surface with special emphasis on applications to urban areas detection. Indeed the images obtained with the two sensors are complementary and an effective image fusion approach may provide a useful tool to achieve a better understanding of the observed scene. The underlying basic assumptions of the proposed fusion approach are: the images to be fused refer to the same scene and are coregistered, moreover the images change in the same locations in the scene, and, consequently, have similar "structures". The idea is to fuse the two images (optical and SAR) defining an objective function that quantifies the difference in "structure" between the two unknowns that represent the two "fused" images and that contains a penalization term to establish a relation between the unknowns and the measured data, and minimizing this objective function using a proper numerical algorithm. The urban detection algorithm used is very simple and corresponds to recognize brilliant areas in the images. Some numerical results obtained using real data with the proposed fusion and urban areas detection procedures are presented. The numerical results show that the proposed SAR/optical data fusion procedure facilitates the detection of urban areas
