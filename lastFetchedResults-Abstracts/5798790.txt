The development of scalable architectures at store levels of a layered model has concentrated on processor parallelism balanced against scalable memory bandwidth, primarily through distributed memory structures of one kind or another. A great deal of attention has been paid to hiding the distribution of memory to produce a single store image across the memory structure. It is unlikely that the distribution and concurrency aspects of scalable computing can be completely hidden at that level. This paper argues for a store layer which respects the need for caching and replication, and to do so at an &#8220;object&#8221; level granularity of memory use. These facets are interrelated through atomic processes, leading to an interface for the store which is strongly transactional in character. The paper describes the experimental performance of such a layer on a scalable multi-computer architecture. The behaviour of the store supports the view that a scalable cached &#8220;transactional&#8221; store architecture is a practical objective for high performance based on parallel computation across distributed memories
