Undirected graphical models such as Markov random fields or Boltzmann machines prove useful in many signal processing and machine learning tasks. However, parameter estimation in these models is difficult due to the intractable normalising constant in their probability density functions. One powerful technique for parameter estimation in such models is score matching. This technique makes use of an objective function which is independent of the normalising constant and constitutes locally consistent estimators for the parameters of such models. However, score matching is only applicable to fully-observed models. In this paper, we extend the applicability of score matching to models with latent variables. Our estimators are unbiased, based on Monte Carlo integration. Unbiased gradient estimators open the way to optimisation through stochastic approximation. We demonstrate the performance of our methodology on two synthetic problems.
