This paper proposes an approach to analyze pulse waveform dependent bit error rate (BER) performance of a DS-CDMA ultra wideband (UWB) radio, which operates in a frequency selective fading channel. The analysis takes into account almost all real operational conditions, such as asynchronous transmissions, RAKE receiver, multiple access interference (MAI), multipath interference (MI), log-normal shadowing, and noise. The main objective of the paper is to reveal the relationship between time domain characteristics of pulse waveforms and BER of a UWB radio. It is shown through analysis (also validated by simulation) that the normalized mean squared auto-correlation function (ACF) of the pulse waveforms can be used as an effective merit figure to judge the suitability for their applications in a DS-CDMA UWB radio. In fact, the normalized mean squared auto-correlation function (ACF) governs the average inter-chip interference caused by imperfect auto-correlation function of the pulse waveforms. The paper concludes that, as long as the power spectral density (PSD) functions of the pulse waveforms fit the FCC spectral mask, the pulse waveformsÂ´ normalized mean squared ACF should be minimized to ensure an acceptable BER.
