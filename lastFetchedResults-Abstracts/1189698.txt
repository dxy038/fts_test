Transparent models search for a balance between interpretability and accuracy. This paper is about the estimation of transparent models of chaotic systems from data, which are accurate and simple enough for their expression to be understandable by a human expert. The models we propose are discrete, built upon common blocks in control engineering (gain, delay, sum, etc.) and optimized both in their complexity and accuracy.

The accuracy of a discrete model can be measured by means of the average error between its prediction for the next sampling period and the true output at that time, or ‘one-step error’. A perfect model has zero one-step error, but a small error is not always associated with an approximate model, especially in chaotic systems. In chaos, an arbitrarily low difference between two initial states will produce uncorrelated trajectories, thus a model with a low one-step error may be very different from the desired one. Even though a recursive evaluation (multi-step prediction) improves the fitting, in this work we will show that a learning algorithm may not converge to an appropriate model, unless we include some terms that depend on estimates of certain properties of the model (so called ‘invariants’ of the chaotic series). We will show this graphically, by means of the reconstructed attractors of the original system and the model. Therefore, we also propose to follow a multi-objective approach to model chaotic processes and to apply a simulated annealing-based optimization to obtain transparent models.
