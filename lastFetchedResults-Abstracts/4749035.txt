This paper analyzes the relation between peer review and multi-indicators evaluation for scientific and technical assessment. Based on the data of the 2007 Times Higher-QS world university rankings, we use two methods, multiple linear regression analysis and kappa agreement test, for analysis. The results show that the data abundance affects the agreement between peer review and multi-indicators evaluation. We conclude that comprehensive evaluation in combination with peer review is a better choice in lack of data. Regression goodness-of-fit can be used to assess data abundance. Peer review should be the basis for the choice of indicators and indicator weights. However, multi-indicators evaluation is more stable and objective.
