Packet buffers in router/switch interfaces constitute a central element of packet networks. The appropriate sizing of these buffers is an important and open research problem. Much of the previous work on buffer sizing modeled the traffic as an exogenous process, i.e., independent of the network state, ignoring the fact that the offered load from TCP flows depends on delays and losses in the network. In TCP-aware work, the objective has often been to maximize the utilization of the link, without considering the resulting loss rate. Also, previous TCP-aware buffer sizing schemes did not distinguish between flows that are bottlenecked at the given link and flows that are bottlenecked elsewhere, or that are limited by their size or advertised window. In this work, we derive the minimum buffer requirement for a drop-tail link, given constraints on the minimum utilization, maximum loss rate, and maximum queueing delay, when it is feasible to achieve all three constraints. Our results are applicable when most of the traffic (80-90%) at the given link is generated by large TCP flows that are bottlenecked at that link. For heterogeneous flows, we show that the buffer requirement depends on the harmonic mean of their round-trip times, and on the degree of loss synchronization. To limit the maximum loss rate, the buffer should be proportional to the number of flows that are bottlenecked at that link, when that number exceeds a certain threshold. The maximum queueing delay constraint, on the other hand, provides a simple upper bound on the buffer requirement. We also describe how to estimate the parameters of our buffer sizing formula from packet and loss traces, evaluate the proposed model with simulations, and compare it with two other buffer provisioning schemes.
