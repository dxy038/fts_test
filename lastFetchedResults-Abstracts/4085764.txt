In this paper, a framework for applying reinforcement learning (RL) to the design and control of power system stabilizers (PSSs) is proposed. A near-optimal coordinated design for several PSSs is achieved using reinforcement learning. The objective of the control policy is to enhance the stability of a multi-machine power system by increasing the damping ratio of the least-damped modes. An RL method called Q-learning is applied to find a near-optimal control policy for controlling PSSs. With this control policy, the agent can change the gain of PSSs automatically in such a way that a predefined goal is nearly always satisfied. A modified Q-learning algorithm is proposed to enhance the convergence speed of the conventional algorithm toward a near-optimal policy. This is achieved by using selective initial state criteria instead of choosing the initial state randomly in each episode. The validity of the proposed method has been tested on a two-area, four-machine power system using nonlinear time-domain simulation under severe disturbances.
