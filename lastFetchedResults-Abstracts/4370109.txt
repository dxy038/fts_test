In independent component analysis (ICA), both linear and nonlinear, one of the best objective functions is the mutual information (MI) of the estimated components. However, use of the MI demands the estimation of the probability densities of those components from a finite number of training samples. Several forms of smoothing have been used to estimate these densities from data, including series expansions and Gaussian kernels. This paper proposes a new way to estimate these densities, simultaneously with the ICA operation. The resulting system is a neural network with a specialized architecture, optimized by a single objective function - the output entropy. The paper includes experimental results, which also illustrate that it is possible to perform nonlinear blind source separation when the mixtures have smooth nonlinearities
