Different fuzzy rule-based learning algorithms use the sequential covering strategy. This model applies a problem decomposition strategy, in which the task of finding a complete rule base is reduced to a sequence of subproblems in each of which the solution is to add a single rule. Now, we are interested in introducing additional capabilities in this strategy in order to review the knowledge previously extracted. Thus, our main objective is that in each iteration instead of only being able to add rules, we can propose three different options: to add the best rule that increases the prediction capability of the rule base, to add the best rule that replaces one or more rules previously learned without loosing accuracy or do not add any rule, if the rule base can not be improved. The experimental results show that this proposal maintains the accuracy of the model as well as the average number of rules but significantly reducing the number of conditions per database, which means that rules are more general. Therefore, this new iterative scheme improves the interpretability of the model obtained.
