This paper focuses on the evolution of ARTMAP architectures, using genetic algorithms, with the objective of improving generalization performance and alleviating the ART category proliferation problem. We refer to the resulting architectures as GFAM, GEAM, and GGAM. We demonstrate through extensive experimentation that evolved ARTMAP architectures exhibit good generalization and are of small size, while consuming reasonable computational effort to produce an optimal or a sub-optimal network. Furthermore, we compare the performance of GFAM, GEAM and GGAM with other competitive ARTMAP architectures that have appeared in the literature and addressed the category proliferation problem in ART. This comparison indicates that GFAM, GEAM and GGAM have superior performance (generalize better, are of smaller size, and require less computations) compared with other competitive ARTMAP architectures.
