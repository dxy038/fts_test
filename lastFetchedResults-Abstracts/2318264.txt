The objective of this study is to evaluate the impact of the high resolution SRTM topography and Corine Land Cover data on simulated meteorological variables (wind speed at ten metres height, temperature at 2 m height and precipitation) in WRF. We compare the results with the WRF simulation using the standard 30-arc second USGS Land Cover and topography, and with observations of the ARPA network. We focus on the Lombardy region (north Italy) for the periods January–February and July–August 2008.

alysis shows that simulated average wind speeds are in general lower by the WRF simulation with the SRTM and Corine Land Cover than the WRF simulation with the 30-arc second USGS and agrees better with the observations. The reason for this is that the Corine Land Cover shows a larger fraction of the ‘urban and built-up’ category than the USGS data set, which leads to more friction and higher roughness in the domain and lowers the wind speeds at ground level. For the winter period, the WRF simulation with the SRTM and Corine Land Cover calculates on average higher temperatures over the model domain (between ~ 0.2 and ~ 1.0 °C and up to ~ 1.2 °C for Milan) than the simulation using USGS data. For the summer period the differences in average temperatures are larger up to 2.7 °C, while for Milan the differences are around 0.7 °C. The differences are related to the higher fraction of urban and built-up area in the Corine Land Cover, which affects the sensible and latent heat fluxes in the model domain and holds the heat between the buildings. R2 values are on average a factor of 1.03 and 1.14 higher for the winter and summer periods, respectively. Comparing the hit rate statistics of the precipitation events reveals that probability of detection of the precipitation event and the Hansen–Kuipers score is on average 1% higher by the simulation with SRTM and Corine Land Cover than the WRF simulation with the standard USGS data set.
