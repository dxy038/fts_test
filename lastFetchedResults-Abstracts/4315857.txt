A gaze direction planning algorithm for simultaneous localization and mapping (SLAM), is presented. The objective of the algorithm is to calculate the gaze direction which minimizes estimation error over a given time horizon. This is made possible by gathering data so that the expected information gain is maximized. Existing approaches perform a greedy optimization only over the next time step and usually neglect the limited field of view of the sensors. In the proposed approach information gain is used as an objective function, in order to perform multiple step planning. This way, the novel gaze direction strategy anticipates all possible trajectories and viewing angles over a specific time horizon, performing better than other existing approaches when it comes to sensors with limitations, as most visual ones. Relative entropy of the covariance matrix provided by the extended Kalman filter (EKF) SLAM algorithm is used, as an information metric for each possible gaze direction during the multi-step planning. The aim is to create an intelligent perception module which can provide a robot with an accurate environmental model. Such a perception module is especially suited for vision-based humanoid robots
