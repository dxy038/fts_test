Association rules discovery is one of the most important tasks in knowledge discovery in data bases. The rules produced with a priori-like algorithms are then usually used for decision aiding in expert and knowledge based systems and/or by a human end user. Unfortunately such algorithms may produce huge amounts of rules and thus one of the most important steps in association rules discovery nowadays is the evaluation and the interpretation of their interestingness. Objective measures provide numerical information on the quality of a rule and a rule is said "of quality" if its evaluation by a measure is greater than a user defined threshold. In this paper we propose a new specificity of association rule objective interestingness measures: the threshold sensitivity. By dealing with this problem we intend to provide means of measuring the strength/robustness of the interest of a rule. We propose a general framework allowing us to determine the number of examples that a rule can lose while remaining acceptable, for a panel of classical measures that are transformation of the confidence
