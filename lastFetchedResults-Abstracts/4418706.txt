Compared with Support Vector Machine (SVM) that has shown success in classification tasks, Support Vector Clustering (SVC) is not widely viewed as a competitor to popular clustering algorithms. The reason is easy to state that classical SVC is of high cost and moderate performance. In spite of ever-appearing variants of SVC, they fail in solving two problems well. Focusing on these two problems, this paper proposes a Shrunk Support Vector Clustering (SSVC) algorithm that makes an effort to address two difficulties simultaneously. In the optimization piece SSVC pursues a shrunk hypersphere in feature space that only dense-region data are included in. In the labeling piece of SSVC, a new labeling approach is designed to cluster support vectors firstly, and then label other data. The development of the shrunk hypersphere is implemented by optimizing a strongly convex objective, which can be converted to a linear equation system. A fast training method is given to reduce the heavy computation burden that is necessary in SVC to solve a quadratic optimization problem. The new labeling approach is based on geometric nature of the shrunk model and works in a simple but informed way. That removes the randomness encoded in SVC labeling piece and then improves clustering accuracy. Experiments indicate SSVCÂ´s better performance and efficiency than its peers and much appealing facility compared with the state of the art.
