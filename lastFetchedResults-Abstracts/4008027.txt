Intercell interference is the major limitation to the performance of future cellular systems. Despite the joint detection and joint transmission techniques aiming at interference cancellation which suffer from the limited possible cooperation among the nodes, power allocation is a promising approach for optimizing the system performance. If the interference is treated as noise, the power allocation optimization problem aiming at maximizing the sum rate with a total power constraint is nonconvex and up to now an open problem. In the present paper, the solution is found by reformulating the nonconvex objective function of the sum rate as a difference of two concave functions. A globally optimum power allocation is found by applying a branch-and-bound algorithm to the new formulation. In principle, the algorithm partitions the feasible region recursively into subregions where for every subregion the objective function is upper and lower bounded. For each subregion, a linear program is applied for estimating the upper bound of the sum rate which is derived from a convex maximization formulation of the problem with piecewise linearly approximated constraints. The performance is investigated by system-level simulations. The results show that the proposed algorithm outperforms the known conventional suboptimum schemes. Furthermore, it is shown that the algorithm asymptotically converges to a globally optimum power allocation.
