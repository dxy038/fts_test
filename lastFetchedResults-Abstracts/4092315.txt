This paper studies the impact of channel estimation error on the performance of a two-way amplify-and-forward (AF) relay network and investigates the optimal transmit resource allocation that minimizes the impact. In particular, we consider a three node network, consisting of two user terminals mathbb{T}_A and mathbb{T}_B and a half duplex relay node mathbb{R}, where only mathbb{T}_A and mathbb{T}_B are equipped with channel estimators. Assuming block flat fading channel model, we adopt two estimation theoretic performance metrics, namely the Bayesian Cramer-Rao lower bound (CRLB) and the mean-squared error (MSE) of the linear minimum mean square error (LMMSE) channel estimate, and an information theoretic performance metric, namely the average sum-rate lower bound, as our optimality criteria. For a fixed transmission block length and under the total transmit power constraint, we investigate the optimal training vector design, the optimal number of training symbols in the training vector, the optimal power allocation between training and data in a transmission block, and the optimal power allotment between three nodes, such that these performance metrics are optimized, via utilizing bi-objective optimization methods. Our simulation results demonstrate that the optimal solutions corresponding to each performance metric vary, as the relay location and the system signal-to-noise ratio (SNR) change. They also reveal interesting symmetry relationship between these optimal solutions and the relay location.
