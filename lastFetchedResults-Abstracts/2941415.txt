In this work, recurrent neural networks used in data rectification can be regarded as a particular form of discrete extended Kalman filter (DEKF), one that predicts the process states one step into the future, but does not correct the prediction when the new measurement becomes available. By reformulating the rectification problem using a more general objective function during network training, it is shown that optimal state correction can be built into the network and that the network can be &#8220;tuned&#8221; to yield the desired response characteristics. Networks trained in this way can lead to process models which are less biased than networks trained without state correction. The optimal state correcting recurrent neural network is demonstrated using a simple example
