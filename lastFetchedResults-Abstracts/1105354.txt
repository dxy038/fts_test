A hybrid method, combining the radiative transfer theory and the method of moments (MoM), is proposed to study the potential effect of the lunar surface roughness on the microwave brightness temperature. The total upward emission reaching the lunar surface from below media is calculated by the radiative transfer theory, and then the brightness temperature is obtained by weighting the bidirectional transmission coefficients which is computed using the MoM. The method is validated by both flat and rough surface models with analytic solutions. With the hybrid method, brightness temperatures from simulated lunar model are calculated and compared to those from a flat layered model. The comparisons show that the effect of rough surface on brightness temperature cannot be ignored and also depends on many other factors, such as observation angle and polarizations. For vertical polarization, an optimal observation angle may exist to reduce the effect of surface roughness. These results indicate that the knowledge of lunar surface roughness is important in microwave remote sensing to the Moon and may probably provide a guide to lunar projects in future.
