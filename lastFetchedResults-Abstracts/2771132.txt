The objective of the paper is to embed perception rules into the kernel-based target tracking algorithm and to evaluate to what extent these rules are able to improve the original tracking algorithm, without any additional computational cost. To this aim, the target is represented through features that are related to its visual appearance; then, it is tracked in subsequent frames using a metric that, again, correlates well with the human visual perception (HVP). The use of HVP rules are twofold advantageous: it allows us to both increase tracking efficacy and considerably reduce the computational cost of the tracking process-thanks to the reduced size of the perceptual feature space. Various tests on video sequences have shown the stability and the robustness of the proposed framework, also in the presence of both other moving objects and partial or complete target occlusion in a limited number of subsequent frames.
