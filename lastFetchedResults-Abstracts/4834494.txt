We present a method that combines Bayesian learning, a statistical technique, with the HONEST network, a high order neural network with the property that the mapping embodied by the network can always be described by a polynomial-like equation. In a classification task, the objective is to learn to classify feature vectors into classes. When the distribution of the features is known, statistical methods can often produce better performance than backward error propagation networks. However, if the feature distribution is not known for certain, then the performance of a statistical method will depend on how well the assumed distribution matches the actual distribution. In the method we present, we first use Bayesian learning, with an assumption of a multivariate normal distribution, to learn a quadratic polynomial mapping and then use the HONEST network to improve, or fine-tune, this mapping through backward error propagation. We apply this technique to the feature combination stage of a CONNECT-4 evaluation function
