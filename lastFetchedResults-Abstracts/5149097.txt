A novel method based on an algorithm by Pedersen et. al. using independent component analysis and binary time-frequency masking to iteratively segregate sources from a stereo recording is proposed here to improve the quality of estimated sources and reduce artifacts (musical noise). The inspiration comes from research in auditory scene analysis which indicates that the human auditory system uses a spectrogram-like time-frequency representation with variable frequency resolution for performing stream segregation and perceptual grouping. A time-frequency transform with a variable frequency based on the discrete cosine transform and amplitude modulation is suggested. A method for perfect reconstruction and a way to exploit short-time stationarity of the sources have also been suggested. Simulation results indicate significant improvements in objective evaluation criteria like percentage of energy loss and signal-to-noise ratio improvement. Subjective listening tests indicate a marked improvement in estimated signal quality with strongly reduced artifacts.
