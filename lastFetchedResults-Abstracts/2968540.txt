We consider connectionist compression schemes using auto-associative networks, demonstrate the advantages gained by imposing different constraints on allowed network weights, and give a comparison with pruning of the unconstrained auto-associative network. In this paper we demonstrate the advantages for generalisation performance of constraining weights symmetrically using weight sharing, and by constraining functional symmetry by the use of enhanced backpropagation networks trained bidirectionally. In the process, we derive the stochastic bidirectional training algorithm
