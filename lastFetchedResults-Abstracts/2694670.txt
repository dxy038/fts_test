In this paper we propose an evolutionary technique based in a Lyapunov method (instead of Pareto) for mono-objective optimization, that associate to every Markov-ergodic process a Lyapunov-like mono-objective function. We show that for a class of controllable finite Markov Chains supplied by a given objective-function the system and the trajectory dynamics converge. For representing the trajectory-dynamics properties local-optimal policies are defined to minimize the one-step decrement of the cost-function. We propose a non-converging state-value function that increase and decrease between states of the decision process. Then, we show that a Lyapunov mono-objective function, which can only decrease (or remain the same) over time, can be built for this Markov decision processes. The Lyapunov mono-objective functions analyzed in this paper represent the most frequent type of behavior applied in practice in problems of evolutionary and real coded genetic algorithms considered within the Artificial Intelligence research area. They are naturally related with the, so-called, fixed-local-optimal actions or, in other words, with one-step ahead optimization algorithms widely used in the modern optimization theory. For illustration purposes, we present a simulated experiment that shows the trueness of the suggested method.
