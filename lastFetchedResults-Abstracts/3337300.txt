In this paper, we recognize the need of de-identifying a face image while preserving a large set of facial attributes, which has not been explicitly studied before. We verify the underling assumption that different visual features are used for identification and attribute classification. As a result, the proposed approach jointly models face de-identification and attribute preservation in a unified optimization framework. Specifically, a face image is represented by the shape and appearance parameters of AAM. Motivated by k-Same, we select k images that share the most similar attributes with those of a test image. Instead of using the average of k images, adopted by k-Same methods, we formulate an objective function and use gradient descent to learn the optimal weights for fusing k images. Experimental results show that our proposed approach performs substantially better than the baseline method with a lower face recognition rate, while preserving more facial attributes.
