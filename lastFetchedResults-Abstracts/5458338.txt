Emotion recognition in human-computer reaction is getting more important due to numerous potential applications it has. Most research works paid more attention on speech analysis and facial expression to achieve this. However, audio and visual expressions can be consciously adapted and often artificial. Hence, a more objective approach has been paid attention, which is on physiological signal analysis since it is more robust and accurate as these signals are corresponding to internal physiology. Four physiological signals (EMG, ECG, SC and RSP) has been chosen in this work. These signals will be pre-processed through feature reduction before applied into our proposed network (multi-channel ARAM) for multi-channel emotion recognition. ARAM can be trained on-line while at the same time, maintaining stability even with fast and incremental training, leads to a comparable results with other off-line networks (LDA, kNN and MLP).
