This paper describes a general framework of speaker recognition on summed-channel condition for both enrolling and test data. We present several methods for clustering the target speaker who is involved in multiple summed-channel enrolling excerpts. In our approach, each excerpt is segmented separately by a speaker diarization system as the first stage. Then segments belonging to the same speaker are clustered to train the target speaker model, and speaker verification is applied finally. We propose several effective objective functions to measure the purity of clustered segments in multi-session enrollment. Different confidence measures for summed-channel scoring are also presented. We report experimental results on female part in the NIST 2008 speaker recognition evaluation data, which show that our approach applied on summed-channel condition loses only 1% of the performance measured by equal error rates (EER) compared to the two-channel condition.
