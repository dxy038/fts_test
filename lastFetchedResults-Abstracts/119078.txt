The objective of ecological experiments is often to determine whether observed effects are large enough to be ecologically important. Despite this, effect size measures and associated measures of precision are frequently missing in published ecological research. In many cases, P-values are the only information available with which to assess the ecological importance of observed effects, but they provide a poor means of assessment. It is argued that specifying an important effect size a priori and then presenting observed effects with their associated confidence intervals is often a more informative way of presenting ecological data. A hypothetical data set is analysed and interpreted using both Pvalues and confidence intervals and the results from these two approaches compared. Effects interpreted using P-values were either statistically significant or not, while confidence intervals provided information about statistical significance, the precision of the estimates, and produced a range within which values for the true effects might plausibly lie. The results show that both statistically significant (<0.001) and non-significant (0.100) P-values did not provide useful information about the importance of their associated effects. The capacity to use confidence intervals for analysing complex ANOVA designs is discussed and the implications of different data analysis and presentation techniques for forest management are considered.
