The trade-off between the granularity of the data representation and the recognition accuracy is examined in this paper. We show that unless a particular criterion is satisfied, there is no guarantee of achieving a prescribed recognition accuracy. This criterion of interest, is the mutual information content between the measurements and the class identities. A novel method for the objective evaluation of intrinsic error in recognition as sampling rate varies, is described. This approach is general enough to permit the evaluation of error even when the parameter under study takes a different form. To demonstrate this we present results in feature subset selection and multiple classifier combination. In the case of feature selection, the measurements are the features. In the case of multiple classifier combination it is the &#8220;quality&#8221; of the individual classifiers, evalulated based on the mutual information between the classifier parameters and class identities
