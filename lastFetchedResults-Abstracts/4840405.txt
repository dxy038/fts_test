Combining a surrogate model and a heuristic-based optimizer for multi-objective optimization is now a common approach to make best use of the available computational budget. One possible combination is to use a local surrogate that acts as a guide for local search as a module of the heuristic algorithm. The local search works by optimizing the scalarizing function and uses the local surrogate as a cheap replacement of the original function. Various scalarizing functions exist and an understanding of the advantages and disadvantages of these functions is needed for further improvement of the optimization algorithms. In this paper, various scalarizing functions implemented inside a single surrogate assisted local search memetic algorithm (SS-MOMA) framework are compared. The scalarizing functions studied here are the Tchebycheff type (SS-MOMA-TC) and weighted sum (SS-MOMA-WS) with 15-dimensional ZDT1, ZDT2, and ZDT3 test problems as the benchmark problems using the generational distance and diversity metrics as performance indicators. On the ZDT1, ZDT2, and ZDT3 problems, SS-MOMA-TC clearly outperforms SS-MOMA-WS. The results show that the Tchebycheff scalarizing function can enhance the diversity of the non-dominated solutions independent of the convexity of the problem, but it encounters a slight difficulty with the discontinuous Pareto front of ZDT3.
