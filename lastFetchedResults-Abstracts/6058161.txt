In this paper, we present a novel method for adaptive fusion of multimodal surveillance images, based on Non-Subsampled Contourlet Transform (NSCT), which has an improved performance over Visual Sensor Networks (VSN). In sensor networks, energy consumption and bandwidth are the main factors that determine the lifetime of the sensors. In order to reduce the energy and bandwidth used in transmission, the proposed method uses Compressive sensing (CS) which can compress the input data in the sampling process efficiently. Since CS is more efficient for sparse signals, in this work, each sensor image is first decomposed into sparse and dense components. We have introduced Contourlet Transform for this decomposition because of its ability to capture and represent smooth boundaries of objects in images, so that the reconstructed images have a better quality. The reconstructed input images are fused using an adaptive algorithm based on NSCT in a centralized server. The improvement in the quality of the fused image is achieved by the use of an image fusion metric and a search algorithm to assign optimum weights to the various regions in the segmented source images. Experimental results show, no significant change in the quality of the fused images with and without compression. The results show that the proposed method achieves better visual quality and objective metrics than the state-of-art methods.
