The Carrier-to-Noise density ratio (C/N<sub>0</sub>) in a Global Navigation Satellite System (GNSS) receiver is an important parameter to measure the quality of a GNSS signal. The most traditional C/N<sub>0</sub> estimation technique is implemented based on the Narrowband and the Wideband Power Ratio (NWPR), which works just perfectly for the legacy GPS LI C/A receiver. With the advent of new modernized GNSS signals from different systems, some basic signal characteristics of these signals have also changed in such a way that they might no longer enjoy the similar C/N<sub>0</sub> estimation performance that NWPR-based C/N<sub>0</sub> estimation does for GPS LI C/A signal. For example, in case of BeiDou B1I signal, the presence of an extra tier of modulation (i.e., Neumann-Hoffman code) for Dl signal, and the higher data bit rate in D2 signal may deteriorate the performance of NWPR-based C/No estimation technique. In view of this particular issue, two noise-estimation based C/N<sub>0</sub> estimation techniques, namely Signal-to-Noise Power Ratio (SNPR) and Signal-to-Noise Variance Ratio (SNVR), are implemented along with the traditional NWPR-based C/N<sub>0</sub> technique for four different GNSS signals in L1/E1/B1 bands. The objective of this paper is to evaluate the performance of these three C/N<sub>0</sub> estimation techniques via Matlab-based signal simulations and also via hardware signal simulator and a software-defined multi-GNSS receiver. The simulation results show that the SNPR and SNVR-based C/N<sub>0</sub> estimation techniques offer much better estimation performance than the traditional NWPR-based technique in weak signal condition and also with the signals which have relatively higher data bit rate (i.e., BeiDou Bl D2 signal and Galileo El signal).
