This note considers the problem of stabilizing a linear dynamical system (&#931;) whose state equation includes a time-varying uncertain parameter vector <img alt="q(\\cdot)" src="/images/tex/3200.gif"/> . Given the dynamics <img alt="\\dot{x}(t)=A(q(t))x(t)+ B(q(t))u(t)" src="/images/tex/3623.gif"/> and a bounding set <img alt="Q" src="/images/tex/6.gif"/> for the values <img alt="q(t)" src="/images/tex/2545.gif"/> , the objective is to choose a control law <img alt="u(t)=p(x(t))" src="/images/tex/3624.gif"/> guaranteeing uniform asymptotic stability for all admissible variations of <img alt="q(\\cdot)" src="/images/tex/3200.gif"/> . Our results differ from previous work in one fundamental way; that is, we show that when working with linear controllers, it is possible to dispense with all assumptions on <img alt="B(\\cdot)" src="/images/tex/3625.gif"/> which have been made by previous authors (e.g., see [1]-[9]). This elimination of hypotheses on <img alt="B(\\cdot)" src="/images/tex/3625.gif"/> is accomplished roughly as follows: the system <img alt="(\\Sigma ) {\\underline {\\underline \\Delta }} (A(q), B(q))" src="/images/tex/3626.gif"/> is shown to be equivalent to another system <img alt="(\\Sigma ^{+}) {\\underline {\\underline \\Delta }} (A^{+}(q), B^{+})" src="/images/tex/3627.gif"/> as far as stabilization is concerned. Since <img alt="B^{+}" src="/images/tex/3628.gif"/> is a constant matrix (independent of <img alt="q" src="/images/tex/62.gif"/> ), the desired result is readily obtained.
