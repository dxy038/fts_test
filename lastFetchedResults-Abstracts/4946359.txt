The problem of selecting a subset of sensors in a distributed object tracking environment that optimizes an objective function consisting of a trade-off between data accuracy and energy consumption is known to be NP-hard. The problem is exacerbated because of the uncertainty and dynamic nature of either sensor characteristics or the environment or both. We propose, for the first time, a novel framework based on a reinforcement learning approach, to deal with the problems of computational complexity, dynamic nature and uncertainty for sensor subset selection. Our proposed sensor subset selection approach is completely decentralized and sensors do not need to know even the presence of other sensors in the system. This makes our approach extremely scalable and easy to implement in a distributed system. To the best of our knowledge, this is the first application of reinforcement learning to the domain of sensor subset selection.
