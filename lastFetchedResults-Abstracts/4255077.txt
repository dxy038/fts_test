Consider the problem of noisy Bayesian active learning given a sample space, a finite label set, and a finite set of label generating functions from the sample space to the label set, also known as the function class. The objective is to identify the function in the function class that generates the labels using as few label queries as possible and with low probability of error despite possible corruption by independent noise. The key to achieving this objective relies on the selection of queries in a strategic and adaptive manner. The problem generalizes the problem of noisy generalized binary search [1]. This paper explores the connection between the above Bayesian active learning problem and the problem of information acquisition in which a Bayesian decision maker is responsible for dynamically collecting noisy observations so as to enhance her/his information in a speedy manner about an underlying phenomena of interest with a constraint on the probability of error. This view of the problem allows for developing a general lower bound on the expected number of queries to identify the function that generates the labels in terms of the observation noise statistics, the desired probability of error, and the cardinality of the function class. Furthermore, viewing the problem as an information acquisition problem enables a deterministic and Markov heuristic policy based on greedy maximization of Extrinsic Jensen-Shannon divergence [2]. The performance of this heuristic is compared with the state of the art strategies for noisy generalized binary search. In the case where the function class is sample-rich, it is shown that this heuristic is better than previous results and, in particular, matches the earlier proposed lower bound asymptotically.
