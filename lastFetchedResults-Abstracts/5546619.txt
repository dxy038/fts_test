Cloud computing focuses on supporting high scalable and high available parallel and distributed computing, based on the infrastructure built on top of large scale clusters which contain a large number of cheap PC servers, to process the huge amounts of data generated by Internet. As the core of cloud computing, Google´s MapReduce programming model and Google File System (GFS) provide such computing power. Granular computing (GrC) is an objective world outlook and methodology. From the point of GrC, this paper surveys the Google´s MapReduce programming model, analyses how to express its process of data granulation and computing more accurately and more strictly during the parallel and distributed computing.
