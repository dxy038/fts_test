A Bayesian framework for deformable pattern classification was proposed by K.W. Cheung et al. (1998), with promising results for isolated handwritten character recognition. Its performance, however degrades significantly when it is applied to detect deformable patterns in complex scenes, where the amount of outliers due to other neighboring objects or the background is usually large. Also, the fact that the associated evidence measure does not penalize models resting on white space results in a high false alarm rate. Another Bayesian framework for deformable pattern detection is proposed. The framework possesses the intrinsic property of matching with only part of an image (segmentation) and its associated evidence measure can penalize white space implicitly. However, limited data exploration capability is the major trade-off. By properly combining the two frameworks, a new matching algorithm called bidirectional matching is proposed. This combined approach possesses the advantages of the two frameworks and gives robust results for non-rigid shape extraction. To evaluate the performance of the proposed approach, we have applied it to shape-based handwritten word retrieval. Using a subset of the bb dataset in the CEDAR database, we can achieve a recall rate of 59% and a precision rate of 43%
