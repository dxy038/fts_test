This paper presents a machine learning classifier algorithm based on MOGA (Multi-Objective Genetic Algorithm), which applies the information entropy theory to optimize the MOGA and then can be used to discretize the continuous attributes. According to the practical problems, the fitness vector can be constructed by judging multi-objective functions to find the Pareto optimal solutions. Combining the classic set theories with the two relationships, i.e. coverage and contradictory, between chromosomes, more reasonable selection rules can be worked out to delete the redundant chromosomes and get more efficient classification rules. The new algorithm was applied to Iris and Wine dataset from UCI. By comparison, the algorithm in this paper has higher classification accuracy than KNN, C4.5 and NaiveBayes.
