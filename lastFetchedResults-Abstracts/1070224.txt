An important tool in the management of floods is the use of rainfall–runoff models to predict the arrival of discharge peaks. These models generally use rainfall and potential evapotranspiration rates as input, and relate these to the catchment discharge through a number of conceptual equations. The parameters of these equations are estimated through a comparison of the modeled discharge to the observations. Only one variable, catchment discharge, is thus generally used to calibrate and validate these models. The objective of this paper is to validate the internal model dynamics of two widely used rainfall–runoff models using baseflow estimates. The baseflow time series used in this paper are obtained through the use of a physically-based digital baseflow filter. These models, the Hydrologiska Byråns Vattenbalansavdelning (HBV) model and the Probability Distributed Model (PDM), were calibrated using 1 year of hourly discharge data. The HBV model uses a linear reservoir for the modeling of groundwater flow, while the PDM uses a cubic reservoir for this purpose. In order to assess the impact of the type of reservoir choice, the cubic reservoir in the PDM was also replaced by a linear reservoir. Two different parameter estimation algorithms were used for model calibration. The Shuffled Complex Evolution (SCE-UA) algorithm minimizes the Root Mean Square Error between the model simulations and the observations, while Multistart Weight-Adaptive Recursive Parameter Estimation (MWARPE) uses the Extended Kalman Filter equations in an iterative, Monte-Carlo framework. MWARPE was found to lead to the best discharge simulations, but the differences with the results obtained from the SCE-UA algorithm were relatively small. When only the modeled discharge was analyzed, no clear picture emerged of which model produced the best results. However, it has been found that the replacement of the cubic groundwater reservoir in the PDM by a linear reservoir resulted in a strongly improved model performance with respect to the baseflow. Further, MWARPE consistently led to the best baseflow estimates for the three models, while the HBV model resulted in the best simulations of the baseflow, regardless of the calibration algorithm. The overall conclusion of this paper is that, even though it may be difficult to assess which model and calibration algorithm resulted in the best discharge estimates, the MWARPE calibration algorithm and the HBV model consistently led to the best internal model dynamics.
