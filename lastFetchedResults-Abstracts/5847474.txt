Content-based multimedia database indexing and retrieval tasks require automatic extraction of descriptive features that are relevant to the subject materials i.e., images, video etc. The typical low-level features that are extracted in images and video include measures of color, texture, or shape. Although these features can easily be obtained, they do not give a precise idea of the image content. Extracting more descriptive features and higher level entities, such as text and human faces is important. Text embedded in images and video, especially captions provide brief and important content information, such as the name of players or speakers, the title, location, date of an event, etc. Besides, text-based search has been successfully applied in many applications, while the robustness and computation cost of feature matching algorithms based on other high-level features is not efficient enough to be applied to large databases. The objective of this paper is to compare two basic approaches of text extraction in natural (non-document) images namely; edge-based and connected-component based. These algorithms are implemented and evaluated using a set of images of natural scenes that vary along the dimensions of lighting, scale and orientation. Accuracy, precision and recall rates for each approach are analyzed to determine the success and limitations of each approach. Recommendations for improvements are given based on the results.
