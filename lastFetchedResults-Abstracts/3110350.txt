In this paper, L<sup>1</sup>-norm minimization criterion is proposed to treat model matching control problem in the case of inputs are assumed to be arbitrary signals but with bounded magnitude that can not be treated by H&#194;&#191;-theory. The objective is to find a controller such that the maximum difference between outputs of a prespecified model and closed-loop compensated system is minimized. The results show that the solution will lead to a finite-dimensional nonlinear programming.
