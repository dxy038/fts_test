This paper analyzes in detail some theoretical aspects in the modeling of a proposed readout architecture for pixel detectors. The readout architecture is designed for a chip containing about 3000 pixels of 50 &#956;m&#215;400 &#956;m. The main objective is to get the maximum pixel hit readout with the minimum probability of hit loss. The readout architecture is modeled as a Markov stochastic process. The pixel front-end and readout are simulated and tested with Monte Carlo data. The simulations allow to optimize the communication channel bandwidths and local buffering. The probability of system overflow of the simulated system is compared with the one obtained by modeling
