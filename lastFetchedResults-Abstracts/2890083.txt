Energy consumption for Cloud providers and data centers is a major problem. Dynamic Power Management is a common solution to this problem, switching off and on idle servers as needed. However, failing to predict the impact of switching costs may adversely affect energy and/or SLA violations. This paper contributes a policy that adaptively decides when to switch servers on and off under a workload of parallel jobs. Its objective is to minimize both the energy consumption and the number of SLA violations. Experimental results using Cloud Sim show that our proactive policy strikes a good balance between consumed energy and the number of SLA violations and compares favorably with other policies from the literature.
