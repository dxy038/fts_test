Data partitioning, such as bagging and boosting, has been extensively used in the construction of multiple classifier systems. One objective of data partitioning is to achieve uncorrelated classifiers. Most existing techniques achieve diversity through random partitioning, and they do not take advantage of the information within data patterns before training. In this work, combining techniques are studied and categorized from a new perspective. In addition, we introduce two new measures, total diversity index and imbalance, with which multiple classifiers can be compared. Several simulations and comparative studies have been carried out on a common benchmark data set and results are presented
