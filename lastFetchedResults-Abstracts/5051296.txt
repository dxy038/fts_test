Both Euclidean distance- and cosine-based similarity models are widely used for measures of document similarity in information retrieval and document categorization. These two similarity models are based on the assumption that term vectors are orthogonal. But this assumption is not true. Term associations are ignored in such similarity models. In the document categorization context, we analyze the properties of term-document space, term-category space and category-document space. Then, without the assumption of term independence, we propose a new mathematical model to estimate the association between terms and define an &#949;-similarity model of documents. Here we make best use of existing category membership represented by the corpus as much as possible, and the objective is to improve categorization performance. Experiments have been done with a k-NN classifier over the Reuters-5178 corpus. The empirical results show that utilization of term association can improve the effectiveness of the categorization system and the &#949;-similarity model outperforms those without term association.
