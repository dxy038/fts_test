An algorithm for performing simultaneous growing and pruning of cascade-correlation (CC) neural networks is introduced and tested. The algorithm adds hidden units as in standard CC, and removes unimportant connections by using optimal brain damage (OBD) in both the input and output phases of CC. To this purpose, OBD was adapted to prune weights according to two separate objective functions that are used in CC to train the network, respectively. Application of the new algorithm to two databases of the PROBEN1 benchmarks reveals that this new dual-phase pruning technique is effective in significantly reducing the size of CC networks, while providing a speed-up in learning times and improvements in generalization over novel test sets.
