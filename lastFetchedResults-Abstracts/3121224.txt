Existing research demonstrates that classifier ensembles can improve on the performance of the single dasiabestpsila classifier. However, for some problems, although the ensemble may obtain a lower classification error than any of the base classifiers, it may not provide the desired trade-off among the classification rates of different classes. In many applications, classes are not of equal importance, but the preferred trade-off may be hard to quantify a priori. In this paper, we adopt multi-objective techniques to create Pareto optimal sets of classifiers and ensembles, offering the user the choice of preferred trade-off. We also demonstrate that the common practice of developing a single ensemble from an arbitrary (diverse) selection of base classifiers will be inferior to a large proportion of those classifiers.
