The Boltzmann Machine has been introduced as a means to perform global optimization for multimodal objective functions using the principles of simulated annealing. In this paper we consider its utility as a spurious-free content-addressable memory and provide bounds on its performance in this context: a) We show how to exploit the machine´s ability to escape local minima, in order to use it, at a constant temperature, for unambiguous associative pattern-retrieval in noisy environments. An association rule, which creates a sphere of influence around each stored pattern, is used along with the Machine´s dynamics to match the machine´s noisy input with one of the pre-stored patterns. Spurious fixed points, whose regions of attraction are not recognized by the rule, are skipped, due to the Machine´s finite probability to escape from any state. b) We propose the use of the incremental Hebbian rule as a learning scheme for the Boltzmann-Machine-based content addressable memory. This learning rule is different from the probability-distribution-matching learning rules which are used at present for the Machine´s weights in the global-minimizer application. We interpret the incremental Hebbian rule as a steepest-descent algorithm, maximizing the probability of pattern stabilization during learning. C) We describe the Hamming distance from a stored pattern using a birth-and-death Markov chain, and find bounds on the retrieval probabilities. Our bounds allow an assessment of the Machine´s efficiency as a content-addressable memory.
