We have been engaged in research on computational auditory scene analysis to attain sophisticated robot/computer human interaction by manipulating real-world sound signals. The objective of our research is the understanding of an arbitrary sound mixture including non-speech sounds and music as well as voiced speech, obtained by robotÂ´s ears, that is, microphones embedded in the robot. We have coped with three main issues in computational auditory scene analysis, that is, sound source localization, separation, and recognition of separated sounds for a mixture of speech signals as well as polyphonic music signals. This paper overviews our results in robot audition, in particular, missing feature theory based integration of sound source separation and automatic speech recognition, and those in music information processing, in particular, drum sound equalizer
