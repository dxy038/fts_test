Multi-channel opportunistic spectrum access in unslotted primary systems is considered. The primary occupancy of each channel is modeled as a general on-off renewal process. The distributions of the busy and idle times and the utilization factors of all channels are unknown to the secondary user. The objective of the secondary user is to identify and exploit the best channel (i.e., the channel with the least primary traffic) through efficient online learning. A dynamic channel access policy is constructed that achieves the throughput offered by the best channel under certain mild conditions on the busy/idle time distributions. More specifically, the cost associated with learning the unknown channel occupancy models over a horizon of length T diminishes at the rate of log T/T. The policy is obtained by constructing a hypothetical multi-armed bandit with virtual reward which, while not directly reflecting throughput, preserves the ranking of the channels in terms of throughput.
