In this paper, speech commands based on natural spoken language are used so that two or more same colored objects are tracked by a robot manipulator. More precisely, after receiving a speech command regarding the color information, the end-effector of the robot is controlled to approach a desired object out of many objects by using image, in which the image information is further applied to the human if a more correct motion of the robot is required. Thus, the present objective is to obtain a smoother cooperative system between human and robot, by coordinating speech and image information.
