Audio transform coding methods generally employ an assumption of locally stationary signals. However, as demands on coding efficiency increase, the assumption of stationarity becomes increasingly challenging. In this article we study a parametric method for modeling variability in an audio signal, especially with voiced speech in mind. Namely, we model modulation in fundamental frequency and amplitude, with the objective of allowing normalization of the signal to satisfy the stationarity requirements of transform based coders.
