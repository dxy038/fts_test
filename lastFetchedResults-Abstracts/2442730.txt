Binarization strategies decompose the original multi-class dataset into multiple two-class subsets, learning a different binary model for each new subset. One-vs-All (OVA) and One-vs-One (OVO) are two of the most well-known techniques: One-vs-One separates a pair of classes in each binary sub-problem, ignoring the remaining ones; and One-vs-All distinguishes one class from all the other classes. In this paper, we present two new OVA and OVO combinations where the best base classifier is applied in each sub-problem. The first method is called OVA + OVO since it combines the outputs obtained by OVA and OVO decomposition strategies. The second combination is named New One Versus One All (NOV@), and its objective is to solve the problems found in OVA when different base classifiers are used in each sub-problem. In order to validate the performance of the new proposal, an empirical study has been carried out where the two new methods are compared with other well-known decomposition strategies from the literature. Experimental results show that both methods obtain promising results, especially NOV@.
