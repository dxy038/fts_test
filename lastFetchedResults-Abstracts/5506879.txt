We investigate the problem of sharing the resources of a single server with time-varying capacity with the objective of minimizing the mean delay. We formulate the resource allocation problem as a Markov Decision Process. The problem is not solvable analytically in full generality, and we thus set out to obtain an approximate solution. In our main contribution, we extend the framework of multi-armed bandits to develop a heuristic solution of index type. At every given time, the heuristic assigns an index to every user that depends solely on its current state, and serves the user with highest current index value. We show that in the case of constant capacity, the heuristic policy is equivalent to the so-called Gittins index rule, which is known to be optimal under the assumption of constant capacity.
