Evolutionary algorithms (EAs) are widely employed for solving optimization problems with rugged fitness landscapes. Opposition-based learning (OBL) is a recent tool developed to improve the convergence rate of EAs. In this paper, we derive the probabilities that distances between OBL points and the optimization problem solution are less than the distance between a given EA individual and the optimal solution. We find that the quasi-reflected opposition point yields the highest probability and is the most likely candidate to be closer to the optimal solution. We then employ CEC 2013 competition benchmark problems and select a set of trajectory optimization problems from the European Space Agency to study the performance of three OBL algorithms in conjunction with three different EAs. The CEC 2013 test suit simulations indicate that quasi-reflection accelerates the performance of the EA, especially for more difficult composition functions. The space trajectory experiments reveal that differential evolution with opposition generally returns the best objective function value for the chosen minimization problems.
