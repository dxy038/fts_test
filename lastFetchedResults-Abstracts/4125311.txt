Explaining the mismatch between predicted timing behavior from modeling and simulation, and the observed timing behavior measured on silicon chips can be very challenging. Given a list of potential sources, the mismatch can be the aggregate result caused by some of them both individually and collectively, resulting in a very large search space. Furthermore, observed data are always corrupted by some unknown statistical random noises. In this paper, we examine how trying to explain the mismatch observed on silicon can be classified as an ill-posed problem, where ill posed means that the solution may not be unique or stable. Thus, a small change in the observed response can have a large change in the predicted solution. To solve ill-posed problems, a statistical learning theory uses a principle called regularization. This paper proposes using a statistical learning method called support vector (SV) analysis to statistically analyze all known sources of uncertainty with the objective to rank which sources contribute the most to the observed mismatch. Experimental results are presented under different error assumption models to compare two kinds of SV ranking approaches to four other ranking approaches, where some use the idea of regularization and others do not. This paper is concluded by showing a self cross-validation approach to validate the ranking results when there is no true ranking available, as the case with actual silicon.
