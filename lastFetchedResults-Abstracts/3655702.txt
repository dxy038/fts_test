To improve bidirectional associative memory (BAM), a modified bidirectional decoding strategy (MBDS) network has been proposed. The former is a two-layer structure in which stored associations are recalled by directionally updating the neuron state through the connecting weights M and M<sup>T</sup>. The latter is an extension of the former in which two hidden layers are augmented and the corresponding extra connection weights-M<sub>x</sub>, M<sub>y</sub>, Tx, and T<sub>y</sub>-are encoded. The authors introduce a new updating rule for MBDS networks, called neighbor-layer updating (NLU), which gathers all weighted activations of all neighbor layers. The neighbor layers are defined as the layers in which there are direct synaptic weights connected to each other. Because of modification of the connection weights-M<sub>x</sub>, M<sub>y</sub>, Tx, and T<sub>y</sub>-and the constant bias inputs of MBDS, all stored associations are guaranteed to be recalled using NLU. Furthermore, with the aid of the Cohen-Grossberg theorem, all discrete MBDS results can be extended to continuous MBDS (CMBDS). The authors also give stability proofs of both discrete MBDS and CMBDS, Computer simulations demonstrate that the proposed CMBDS can be applied to recall pure bipolar patterns in the presence of gray-scale noise. The authors show that by removing BAM connections (matrix M) from the MBDS structure, a bidirectional holographic memory (BHM) is obtained. Both derivation and simulation indicate that one can remove the matrix M from the MBDS structure if the dimension of the training associations is larger than 16
