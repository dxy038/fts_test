We present a high order multivariate approximation scheme for scattered data sets. Each data point is represented as a Taylor series, and the high order derivatives in the Taylor series are treated as random variables. The approximation coefficients are then chosen to minimize an objective function at each point by solving an equality constrained least squares. The approximation is an interpolation when the data points are given as exact, or a nonlinear regression function when nonzero measurement errors are associated with the data points. Using this formulation, the gradient information on each data point can be used to significantly reduce the approximation error. All parameters of the approximation scheme can be computed automatically from the data points. An uncertainty bound of the approximation function is also produced by the scheme. Numerical experiments demonstrate that although this method is more computationally intensive than traditional methods, it produces more accurate approximation functions.
