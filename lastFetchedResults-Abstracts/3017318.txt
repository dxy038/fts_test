Support vector machines (SVMs) are now thought as a powerful method for solving pattern recognition problems. SVMs are usually formulated as quadratic programming. Using another distance function, SVMs are formulated as linear programming. SVMs generally tend to make overlearning. In order to overcome this difficulty, the notion of soft margin method is introduced. In this event, it is difficult to decide the weight for slack variable reflecting soft margin. The soft margin method is extended to multi objective linear programming. It is shown through several examples that SVM reformulated as multi objective linear programming can give a good performance in pattern classification.
