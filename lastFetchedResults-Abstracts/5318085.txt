Previous attempts at performing automatic photointerpretation have met with limited success. Many rely on one-shot methods which try to interpret an image in one pass through the data with no provisions for error correction, while effectively looking through a peephole, one small image segment at a time. They generally lack the ability to utilize contextual information (parking lots are associated with roads and buildings), internal details (roads contain shoulders, center stripes, and vehicles), as well as multiple competing interpretation hypotheses to build up the `big pictureÂ´, as is likely done in the mind of a human photointerpreter. The objective of this work is to apply such concepts, which are motivated by biological systems directly, or through neural network paradigms indirectly, to achieve a more synergistic and robust algorithm for performing image interpretation. The following is a presentation of the second version of this algorithm, called Multi-Pass multi-Resolution (MPR) image interpretation
