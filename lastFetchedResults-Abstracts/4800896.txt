Dynamic game theory has received considerable attention as a possible technology for formulating control actions for agents in an extended complex enterprise that involves an adversary. Examples of such enterprises are very common in military operations, decentralized electric energy systems, and competitive manufacturing processes. Enterprises of this typed typically involve two teams of decision agents each with a different objective function and possibly with a different hierarchy of decision-making Because of the complexity of such systems, traditional solutions from dynamic game theory are computationally extremely difficult, if not impossible, to derive. We discuss a solution approach where at each step the control agents limit the computation of their actions to a short time horizon that may involve only the next few time steps. This moving horizon solution, although suboptimal in the global sense, is very useful in taking into account the possible near-term control actions of the adversary. We illustrate this solution methodology using an example of an air military operation that involves two opposing forces
