Summary form only given, as follows. To design large neural networks, a notation suitable for standardization has been developed utilizing the C++ programming language. The primary objective of the notation was to develop a concise and simple syntax to represent large neural networking systems that might utilize a variety of paradigms, and to be portable over a wide range of systems. The C++ programming language was selected since it has the promise of becoming the next de facto standard and has been demonstrated to be available on a wide range of hardware platforms. From a functional point of view, the C++ language has proven to be a suitable platform also for such a syntax. With the ability to overload selected operators, it becomes as simple as `training&gt;&gt;a0&gt;&gt;a1&gt;&gt;a3&gt;&gt;out´ to represent a feedforward perceptron. A training cycle is represented as `a0&lt;&lt;=a1&lt;&lt;=a3&lt;&lt;=training´. The syntax can represent feedback from selected outputs and from selected networks, thus supporting the ability to handle multisource inputs and the fan-out of results, systemwide
