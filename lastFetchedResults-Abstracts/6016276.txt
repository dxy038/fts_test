It is common practice for systems to be subjective to operational testing during their development program. The objective of this testing is to evaluate the performance, including reliability, of the system under conditions that represent actual use conditions. Because of expense, resources, schedule, and other considerations, these operational tests rarely represent exactly the actual use conditions. Rather, stated mission profile conditions are specific for the operational testing. These mission profiles conditions are typically general statements that guide the testing on an average basis during the testing. Because of practical constraints the elements that make up the mission profile conditions are typically tested under varying schedules with the intent that on average the mission profile conditions are met. It is also common practice that reliability corrective actions are incorporated into the system during this type of testing. That is, the test is often an operational mission profile reliability growth test. Under these conditions, we usually have a lack of structure for managing the elements that make up the mission profiles, which makes it very difficult to have an agreed-on methodology for estimating the systemÂ´s reliability. This is especially true if reliability growth is occurring. Many systems fail operational testing because key assessments parameters can not be made in a straightforward clear manner so that management can take timely and appropriate action. This paper addresses this issue and presents a methodology currently being applied on major Department of Defense programs for operational reliability growth testing.
