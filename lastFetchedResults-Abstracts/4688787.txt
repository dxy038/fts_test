The single address-space that shared-memory architectures offer simplifies programming, problem partitioning, and dynamic load balancing as compared to other programming models for parallel computing systems such as e.g. Message passing. Unfortunately, as we scale shared-memory architectures to large configurations, the resulting memory system latencies may limit their performance potentials. Finding cost-effective solutions to the memory-system latency issue has become an important research objective and is the main focus of this minitrack. Loosely speaking, scalability for these systems refers to optimizing both the performance and the implementation cost. While it is not meaningful to strictly define the term scalability, it is an important intuitive goal when evaluating new shared-memory architectures.&lt;<etx>&gt;</etx>
