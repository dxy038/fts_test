Ubiquitous Life Care (u-Life care) is one of the most focus area of research. To provide robust healthcare services, recognition of patient daily life activities is required. Context information with real-time daily life activities can help in better services, service suggestions, and change in system behaviour for better healthcare. Human health, profile, as well as activities are monitored and processed intelligently for better care with low cost. In this paper, we focus on intelligent manipulation of activities using Context-aware Activity Manipulation Engine (CAME) core of Human Activity Recognition Engine (HARE), recognized using video-based, wearable sensor-based and location-based activity recognition engines for context analysis of the activities performed. The objective of CAME is to receive real-time low level activity information from Activity Recognition Engines and infer higher level activities, make situation analysis, and after intelligent processing of activities with their corresponding information take appropriate decisions. To achieve this objective, two phase filtering technique for intelligent processing of information (represented in ontology) is used and appropriate decisions based on description logic rules (incorporating expert knowledge). The experimental results for intelligent processing of activity information showed relatively good accuracy.
