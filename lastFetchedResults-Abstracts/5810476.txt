Assessment of surgical skill, arising from the synthesis of the cognitive and sensorimotor capabilities of the surgeon, has predominantly been a subjective task. Development of quantitative metrics-of-performance with clinical relevance and other desirable characteristics (repeatability and stability) has always lagged behind. New opportunities for objective and automated assessment frameworks have arisen by virtue of technological advances in computation, video-processing, and data-acquisition, especially in the robotic Minimally Invasive Surgical (rMIS) realm. Most efforts focus on semi-quantitative (Likert scale) or inadequately validated, spatially- or temporally-aggregated quantitative metrics derived from direct physical measurements. In this work we propose an automated surgical expertise evaluation method, by adapting well-established motion studies methodologies, especially for MIS evaluation. This method relies on segmenting a primary task into sub-tasks, which can be evaluated by statistical analyses of micromotions. Motion studies were developed by 2 methods: (A) manual annotation process by experts (to serve as a benchmark); and (B) automated kinematic-analysis-of-videos; for economy, repeatability as well as dexterity. The da Vinci SKILLS simulator was used to serve as a uniform testbed. Surgeons with varied levels of expertise were recruited to perform two representative simplified tasks (Peg Board and Pick &amp; Place). The automated kinematic analysis of video was compared with the ground truth data (obtained by manual labeling) using misclassification rate and true classification confusion matrix. Future studies aimed towards analyzing real surgical procedures are already underway.
