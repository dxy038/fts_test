The objective of image fusion is to combine relevant information from two or more images of the same scene into a single composite image which is more informative and is more suitable for human and machine perception. In recent past, different methods of image fusion have been proposed in literature both in spatial domain and wavelet domain. Spatial domain based methods produce spatial distortions in the fused image. Spatial domain distortion can be well handled by the use of wavelet transform based image fusion methods. In this paper, we propose a pixel-level image fusion scheme using multiresolution Biorthogonal wavelet transform (BWT). Wavelet coefficients at different decomposition levels are fused using absolute maximum fusion rule. Two important properties wavelet symmetry and linear phase of BWT have been exploited for image fusion because they are capable to preserve edge information and hence reducing the distortions in the fused image. The performance of the proposed method have been extensively tested on several pairs of multifocus and multimodal images both free from any noise and in presence of additive white Gaussian noise and compared visually and quantitatively against existing spatial domain methods. Experimental results show that the proposed method improves fusion quality by reducing loss of significant information available in individual images. Fusion factor, entropy and standard deviation are used as quantitative quality measures of the fused image.
