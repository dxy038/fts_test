Repeated practice is one of the most effective methods in improving the performance of coordination control tasks for groups of individuals, such as marching band, soldier (tank or warcraft) formation, and unmanned aerial vehicle flying queue. The key objective of this paper is to give a theoretical explanation for this observed behavior by considering a class of coordination learning problems for groups of mobile agents. To be specific, the agents are considered to preserve the desired relative formations between each other through a learning process, for which iterative rules are applied to construct distributed algorithms based on the relative information between each agent and its neighbors. Convergence results are derived by combining the graph theory based method and the Lyapunov analysis, which can address coordination learning problems for multi-agent systems both with and without a reference as the prior knowledge. In addition, numerical simulation results are provided to demonstrate the coordination learning performance for groups of mobile agents.
