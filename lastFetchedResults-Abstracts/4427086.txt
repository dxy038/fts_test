The objective is to study the performance of multiple-symbol differential detection (MSDD) in a typical nonlinear satellite channel. The point of interest is to investigate if the phase and amplitude distortion of a typical satellite transponder would prove to be critical for the usage of the MSDD scheme for satellite applications. The investigation is done by means of simulations, and the results are encouraging in the sense that the nonlinear channel poses no special difficulties for the scheme. At the optimal working point (saturation), the loss with respect to the linear channel is approximately 1 dB at BER=1.0e-3 and BER=1.0e-4, whereas the gain which is achieved by increasing the size of the decision vector is the same for the linear and the nonlinear channels
