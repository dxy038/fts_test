Statistical shape models are powerful tools for image interpretation and shape analysis. A simple, yet effective, way of building such models is to capture the statistics of sampled point coordinates over a training set of example shapes. However, a major drawback of this approach is the need to establish a correspondence across the training set. In 2-D, a correspondence is often defined using a set of manually placed ??landmarks?? and linear interpolation to sample the shape in between. Such annotation is, however, time-consuming and subjective, particularly when extended to 3-D. In this paper, we show that it is possible to establish a dense correspondence across the whole training set automatically by treating correspondence as an optimization problem. The objective function we use for the optimization is based on the minimum description length principle, which we argue is a criterion that leads to models with good compactness, specificity, and generalization ability. We manipulate correspondence by reparameterizing each training shape. We describe an explicit representation of reparameterization for surfaces in 3-D that makes it impossible to generate an illegal (i.e., not one-to-one) correspondence. We also describe several large-scale optimization strategies for model building, and perform a detailed analysis of each approach. Finally, we derive quantitative measures of model quality, allowing meaningful comparison between models built using different methods. Results are given for several different training sets of 3-D shapes, which show that the minimum description length models perform significantly better than other approaches.
