The objective of this work is to improve the quality of life for the visually impaired by enhancing the ability of self navigating. Our system provides a 3D audio representation of the environment by synthesizing virtual sound sources corresponding to obstacles or as a guide for a safe path. The key characteristics of our system are low computational complexity and a simple user customization method. Low complexity makes our system suitable for a resource constrained embedded platform, such as a portable device, while assuring the real time reproduction of the auditive stimuli. In the paper, we discuss the basic perception model, its implementation, and experimental results that show the effectiveness of the approach.
