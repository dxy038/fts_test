Support vector machines (SVMs) often contain a large number of support vectors which reduce the run-time speeds of decision functions. In addition, this might cause an over fitting effect where the resulting SVM adapts itself to the noise in the training set rather than the true underlying data distribution and will probably fail to correctly classify unseen examples. To obtain more fast and accurate SVMs, many methods have been proposed to prune SVs in trained SVMs. In this paper, we propose a multi-objective genetic algorithm to reduce the complexity of support vector machines as well as to improve generalization accuracy by the reduction of over fitting. Experiments on four benchmark datasets show that the proposed evolutionary approach can effectively reduce the number of support vectors included in the decision functions of SVMs without sacrificing their classification accuracy.
