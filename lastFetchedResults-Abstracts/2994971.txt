In a quarter of a century of evolutionary computing, nature still seems to be teasing us with its complexity and flexibility whilst we struggle to apply our artificial creations, that perform so beautifully in blocks-world to the real world. We discuss some of the ways in which the biological world has seemed to defy the curse of dimensionality and present the results of an experiment to evolve neural network pattern detectors based on a pre-emptive `phylogenyÂ´. Strategies discussed are: congruent graduation of objective function and genome complexity; relaxation of objective function specificity; pre-evolved niche recombination; and fractal-like ontogenesis. A phyletic evolutionary architecture is proposed that combines these principles, together with three novel neural net transformations that preserve node-function integrity at different levels of complexity. Using a simple genetic algorithm, a number of 81-node fully recurrent neural nets were evolved to detect intermediate level features in 9&#215;9 subimages. It is shown that by seeding the population with transformations of pre-evolved 3&#215;3 detectors of constituent low-level features, evolution converged faster and to a more accurate and general solution than when they were evolved from a random population
