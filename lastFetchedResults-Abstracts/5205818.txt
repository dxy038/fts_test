Humans gather information from the environment around them using different senses, e.g. sight, hearing, touch, smell and taste. By combining sensory information, we are able to structure decisions and actions when interacting with the environment. Humans are capable of actively using perception capabilities in order to perform objectives in time and space. The objective of this paper is to discuss a biologically inspired sensor fusion model, named sensor fusion model with active perception (SEFMAP). The biological inspiration concept is not used to indicate biological plausibility in the sense of circuitry, networking architecture and information exchange modalities of proposed models, but the modeling point of view. SEFMAP has been developed by mimicking the human way of processing information received from sensory organs. This gives a simple and general model with great development potential, properties that in some degree are missing in existing models. SEFMAP was intended for modeling intelligent sensor fusion systems as well as traditional sensor fusion systems The model discussed in this paper, SEFMAP, includes three main processes (sensation, perception and active perception) as well as a knowledge base. SEFMAP reflects signal processing on sensory information that occurs on the way to the brain, as well as in the brain. The model also handles memory and decision-making to bring the system closer to an objective that may be changed during run-time. The benefits of SEFMAP are demonstrated in three examples, a classification application, an auditory-visual target localization system and a fire indication system. The paper also considers how time affects the result of the sensor fusion algorithm.
