Our objective in this work is to provide a better understanding of the various model updating strategies that utilize mathematical means to update a computer model based on both physical and computer observations. We examine different model updating formulations, e.g. calibration and bias-correction, as well as different solution methods. Traditional approaches to calibration treat certain computer model parameters as fixed over the physical experiment, but unknown, and the objective is to infer values for the so-called calibration parameters that provide a better match between the physical and computer data. In many practical applications, however, certain computer model parameters vary from trial to trial over the physical experiment, in which case there is no single calibrated value for a parameter. We pay particular attention to this situation and develop a maximum likelihood estimation (MLE) approach for estimating the distributional properties of the randomly varying parameters which, in a sense, calibrates them to provide the best agreement between physical and computer observations. Furthermore, we employ the newly developed u-pooling method (by Ferson et al.) as a validation metric to assess the accuracy of an updated model over a region of interest. Using the benchmark thermal challenge problem as an example, we study several possible model updating formulations using the proposed methodology. The effectiveness of the various formulations is examined. The benefits and limitations of using the MLE method versus a Bayesian approach are presented. Our study also provides insights into the potential benefits and limitations of using model updating for improving the predictive capability of a model.
