Accurate target detection and classification in hyperspectral imagery require that the spectral measurements by the imager match as closely as possible the known &#8220;true&#8221; target as collected under controlled conditions and stored in a target database. Therefore, the effect of the radiation source and the atmosphere must be factored out of the result before detection is attempted. Our objective is to evaluate detection error due to the error in estimating the atmospherics. We apply a range of atmospheric water vapor profiles, corresponding to different relative humidities, to a model-based prediction of the radiative transfer to examine the effect of water vapor on simulated hyperspectral imagery. These profiles are taken from known distribution percentiles as obtained from historic meteorological measurements close to the sites being simulated. We quantify the expected detection error for the adaptive matched filter, as measured by the receiver operating characteristic (ROC) and the area under the ROC curve, given the range of atmospheric conditions in the historic profile. We discover that, depending on the target, and given the uncertainty as to the true atmospheric conditions, detection rates improve on average across the historic range when we assume the atmospheric profile is at the 35th percentile of atmospheric relative humidity instead of the 50th percentile.
