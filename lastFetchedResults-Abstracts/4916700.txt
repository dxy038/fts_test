We propose an objective measure to evaluate perceptual similarity between an original image and its modified version. An input image is first decomposed into a collection of diametric strips to form a secondary image. The secondary image patterns, one of which is shifted and wrapped column-wise for alignment, are low-pass filtered and divided into overlapping blocks. Similarity between the corresponding blocks is then found by calculating correlation coefficients, which are then mapped to the interval. Based on the re-mapped correlation coefficients, the final similarity metric is obtained by dividing a product of several smallest coefficients by that of the same number of largest coefficients. Experimental results show that the proposed metric is insensitive to content-preserving processing such as JPEG compression, rotation, low-pass filtering, watermarking embedding, and moderate noise contamination. On the other hand, it is very sensitive to malicious modification that may only affect a small area of the image. The proposed metric is useful in applications such as image hashing and content-based image retrieval (CBIR).
