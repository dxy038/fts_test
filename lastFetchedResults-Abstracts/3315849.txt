In order to efficiently solve the unconstrained optimization problem in which the objective function is very nonlinear, an innovative framework of optimization which is different from line search framework is proposed in this paper. This new method determines the step-length first with nonmonotone line search technique, and generates a two dimensional subspace spanned by the steepest-descent direction and an auxiliary vector. In this subspace, a circle with the current point as its center and with step-length as it radius is constructed. On this circle, the minimizer of the objective function as the next iterative point can be calculated with arc search, and the search direction can be generated with the minimizer and the current point. The variation of gradient of the objective function in the search direction is used for determining the step-length of the next step. The global convergence of this new algorithm is proved in this paper under some mild assumptions. Numerical tests illustrate that this new algorithm is more efficient than conjugate gradient direction. The arc search improves the efficiency of the iterative process. This new algorithm requires only the storage of three vectors such that it is suitable for large scale problems.
