There is a growing interest in tensor subspace learning techniques for face recognition. The tensor subspace learning objective is to find a transformation such that the projected samples satisfy an optimality criterion, where the dimensionality of the projected space is much lower than the original tensor space. Many dimension reduction algorithms have traditionally been utilized with data expressed in the form of 1-D vectors, but much data are intrinsically in the form of second or higher order tensors. In this paper, we review some tensor representation methods which conduct dimension reduction with the objects represented as their intrinsic form and order rather than concatenating all the object data into a single vector. Representation of data as tensors not only preserves higher-order image structure, but can offer greater learnability in dimensionality reduction, especially in cases with small samples sizes.
