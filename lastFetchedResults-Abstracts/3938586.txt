Virtual reality (VR) simulators aim to enhance surgical education by allowing trainees to optimize their skills without patient risk. To achieve this quality, an objective analysis of surgical dexterity is crucial. The application of hidden Markov models (HMMs) has offered important insights in the evaluation of surgical skills (e.g., task decomposition), but there are still issues that need standardization, especially when constructing the hand motion vocabulary. In this paper, we investigate an alternative approach based on multivariate autoregressive (MAR) models. Kinematic signals from orientation sensors attached to the instruments of a VR simulator were used to study the laparoscopic skills of surgical residents. Two different tasks were performed: knot tying and needle driving. A variational Bayesian (VB) approximation was employed to calculate the MAR coefficients, which after data reduction were fed to a classifier. The MAR weights also provided the opportunity to study the hand motion connections. Specificity (Spec) and sensitivity (Sens) analysis was used to evaluate and compare the classification performance between MAR models and HMMs. Our results demonstrate the strength of the proposed approach in recognizing surgical maneuvers of residents with limited experience in laparoscopic suturing. The MAR approach yielded the best performance (Sens/Spec: 86%-96%), significantly outperforming the well-established approach of statistical similarity between different HMMs (Sens/Spec: 64%-87%). Subjects at the end of residency training demonstrated more and greater hand motion couplings compared to beginners. The methodological aspects of the proposed approach may be easily embedded in the assessment module of modern laparoscopic simulators.
