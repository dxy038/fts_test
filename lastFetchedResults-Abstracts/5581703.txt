A novel wake-sleep learning architecture for processing a robotpsilas facial expressions is introduced. According to neuroscience evidence, associative learning of emotional responses and facial expressions occurs in the brain in the amygdala. Here we propose an architecture inspired by how the amygdala receives information from other areas of the brain to discriminate it and generate innate responses. The architecture is composed of many individual Helmholtz machines using the wake-sleep learning algorithm for performing information transformation and recognition. The Helmholtz machine is used since its re-entrant connections support both supervised and unsupervised learning. Potentially it can explain some aspects of human learning of emotional concepts and experience. In this research, a robotic headpsilas facial expression dataset is used. The objective of this learning architecture is to demonstrate the neural basis for the association of recognized facial expressions and linguistic emotion labels. It implies the understanding of emotions from observation and is further used to generate facial expressions. In contrast with other facial expression recognition research, this work concentrates more on emotional information processing and neural concept development, rather than a technical recognition task. This approach has a lot of potential to contribute towards neurally inspired emotional experience in robotic systems.
