Consider the <i>n</i>-dimensional vector <i>y</i>=<i>X</i>&#946;+&#949; where &#946; &#8712; BBR<i>p</i> has only <i>k</i> nonzero entries and &#949; &#8712; BBR<i>n</i> is a Gaussian noise. This can be viewed as a linear system with sparsity constraints corrupted by noise, where the objective is to estimate the sparsity pattern of &#946; given the observation vector <i>y</i> and the measurement matrix <i>X</i>. First, we derive a nonasymptotic upper bound on the probability that a specific wrong sparsity pattern is identified by the maximum-likelihood estimator. We find that this probability depends (inversely) exponentially on the difference of ||<i>X</i>&#946;||<sub>2</sub> and the <i>l</i><sub>2</sub> -norm of <i>X</i>&#946; projected onto the range of columns of <i>X</i> indexed by the wrong sparsity pattern. Second, when <i>X</i> is randomly drawn from a Gaussian ensemble, we calculate a nonasymptotic upper bound on the probability of the maximum-likelihood decoder not declaring (partially) the true sparsity pattern. Consequently, we obtain sufficient conditions on the sample size <i>n</i> that guarantee almost surely the recovery of the true sparsity pattern. We find that the required growth rate of sample size <i>n</i> matches the growth rate of previously established necessary conditions.
