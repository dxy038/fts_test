A technique of designing a reduced order filter based on covariance equivalent theory is proposed. The objective is to first obtain a reduced order model of a linear time invariant system and then design a Kalman filter for this lower order system for the purpose of state estimation. All the observations are assumed to be corrupted by noise. The covariance equivalent realization theory developed by Skelton [7,8] attempts to find a reduced order model that matches the first q-output covariances of a linear system subjected to white noise input. This research extends the scope of SkeltonÂ´s theory in two ways. First, it obtains a time-variant reduced order model of a time-invariant linear system, whereas in all the previous work a time invariant model is obtained. Second, it attempts to match the first two moments (mean and covariance) of the reduced order process with the original full order one. The mean and variance have been shown to match in both the transient and steady state. The application of the results to some simple examples illustrates that filter performance obtained based on a reduced model may be comparable to that achieved when the optimal filter is employed.
