This paper considers a class of strategic scenarios in which two undirected networks of agents have opposing objectives with regards to the optimization of a common objective function. In the resulting zero-sum game, individual agents collaborate with neighbors in their respective network and have only partial knowledge of the state of the agents in the other one. We synthesize a distributed saddle-point algorithm that is implementable via local interactions and establish its convergence to the set of Nash equilibria for a class of strictly concave-convex and locally Lipschitz objective functions. Our algorithm synthesis builds on a continuous-time optimization strategy for finding the set of minimizers of a sum of convex functions in a distributed way. As a byproduct, we show that this strategy can be itself cast as a saddle-point dynamics and use this fact to establish its asymptotic convergence properties. The technical approach combines tools from algebraic graph theory, nonsmooth analysis, set-valued dynamical systems, and game theory.
