An operational model evaluation procedure is described to quantitatively assess the relative skill among several regional-scale air quality models simulating various percentiles of the cumulative frequency distribution of observed daily maximum 8-h ozone concentrations. Bootstrap sampling is used to characterize the variability in the observed percentile values, thereby providing a means for assessing whether the differences seen between model predictions are significant. The procedure was designed to facilitate model inter-comparisons, since all that is needed to implement the procedure is for each modeler to provide a listing of the daily maximum 8-h ozone concentration predictions for a summer season for grid cells containing ozone monitors. Available ozone modeling results for the summer of 2002 from four regional-scale air quality simulations are used here to illustrate the results that can be obtained. These simulations were conducted using the Community Multi-Scale Air Quality (CMAQ) model with somewhat different setups. The modeling domains were different, but there is a region in the central Eastern United States where ozone estimates from all four simulations are available. Our objective is to describe the inter-comparison procedure, to illustrate the results obtained, and to stimulate discussions on how similar procedures might be developed and improved in the future.
