This article discusses opportunities for leveraging scale in cases of recurring scenarios of comparable decisions with multiple objectives in well-defined domains. Based on a software component ranking and selection method that uses utility analysis to separate objective information gathering and subjective assessment, we discuss challenges of decision making such as criterion complexity and evaluation effort. We show that by systematically identifying criteria across cases, it becomes feasible to employ cross-referencing and quantitative assessment of decision criteria and criteria sets across scenarios and organizations to improve decision making efficiency and effectiveness. We present a method and tool that allows referencing decision criteria across cases and employs a set of impact factors for decision criteria and sets of criteria. We discuss the results of analyzing a series of real-world case studies in software component selection. We analyze the applications and implications of the method and its potential to improve decision making effectiveness and efficiency.
