In this paper, we propose a method for musical noise suppression in enhanced speech recordings. This method uses the number of iterations needed to compute the so-called pre-images for patches from complex-valued spectral data of the noisy signal. From the number of iterations a continuous mask can be derived which discriminates between speech and non-speech regions. This mask is applied to suppress musical noise that is most disturbing in non-speech regions. Compared to the original enhanced recording the performance in terms of objective quality measures slightly decreases, but the subjectively perceived quality is better, as the musical noise can be significantly reduced.
