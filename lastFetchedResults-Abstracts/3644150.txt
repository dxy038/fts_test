Computer simulations have been used to study the accuracy with which excess radio-propagation path delay due to atmospheric water vapor can be determined using a microwave remote-sensing technique. A number of strategies were investigated for the remote sensing of path delay with the objective of providing a broad foundation for the development and use of water-vapor radiometers (WVR\Â´s) for geodetic applications. A data base of nearly 10 000 radiosondes from a variety of climatological regions was used for the study. Strategies were judged by their "retrieval performance" on this data base; i.e., by the rms difference between simulations of "retrieved" path delay and "true" path delay, at the zenith, averaged over a radiosonde data base. An observing approach using the frequency set 20.7/22.2/31.4 GHz was found to be close to optimum. A statistical retrieval approach using retrieval coefficients stratified for clear and cloudy weather and for individual location was found to offer a substantial improvement over the use of a single all-weather set of retrieval coefficients. It was found that a reasonably well optimized WVR, with an estimated calibration uncertainty of 0.5 K, can achieve an overall retrieval performance of: 0.27 cm, clear; 0.51 cm, cloudy; and 0.38 cm, all weather average. The weather-averaged retrieval performance for individual locations was found to vary by no more than 14 percent from the average for all locations, in spite of the fact that the mean path delay for these locations ranged from 5 to 26 cm.
