The article presents: 1) lower bounds on energy consumption of noisy digital gates and 2) the concept of noise tolerance via coding for achieving energy efficiency in the presence of noise. A discrete channel model for noisy digital logic in deep submicron technology that captures the manifestation of circuit noise is presented. The lower bounds are derived via an information-theoretic approach whereby a VLSI architecture implemented in a certain technology is viewed as a channel with information transfer capacity C (in bits/sec). A computing application is shown to require a minimum information transfer rate R (also in bits/sec). Lower bounds are obtained by employing the information theoretic constraint C&gt;R. This constraint ensures reliability of computation though in an asymptotic sense. Lower bounds on transition activity at the output of noisy logic gates are also obtained using this constraint. Past work (for noiseless bus coding) is shown to fall out as a special case. In addition, lower bounds on energy dissipation is computed by solving an optimization problem where the objective function is the energy subject to the constraint of C&gt;R. A surprising result is that in a scenario where capacitive component of power dissipation dominates: the voltage for minimum energy is greater than the minimum voltage for reliable operation. For an off-chip I/O signaling example, we show that the lower bounds are a factor of 24/spl times/ below present day systems and that a very simple Hamming code can reduce the energy consumption by a factor of 3/spl times/. This indicates the potential of noise tolerance in achieving low energy operation in the presence of noise.
