The design of supervised learning systems for classification requires finding a suitable trade-off between several objectives, especially between model complexity and error on a set of training examples. This problem is in nature multi-objective and it is usually tackled by aggregating the objectives into a scalar function and solving it with a single-objective optimization strategy. In this paper, we formulate the learning of SVMs as a bi-objective programming problem in which the empirical error and the model complexity are minimized at the same time. Then we propose an algorithm that enumerates a representative nondominated set. The representative nondominated set reflects the entire trade-off information between the two objectives and it can help a decision maker to choose a final classifier. Finally we apply our algorithm in two microarray data classification problems. The quality of the representative is evaluated by measuring three attributes of representation, i.e., uniformity, cardinality and coverage. We compare our algorithm with the traditional weighted sum method. For both algorithms, the same number of discrete nondominated points are produced, then we measure the uniformity and coverage of the nondominated points. Experimental results show that our algorithm is superior to the traditional weighted sum method in terms of uniformity and coverage. Compared to the weighted sum algorithm, our algorithm avoids the trial and error process and it is easier for a decision maker to make a final decision.
