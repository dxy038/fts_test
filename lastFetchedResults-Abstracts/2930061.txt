It has been proposed that the simple cells of visual cortex perform either a localized Fourier transform of the image or a wavelet transform. We argue that a short term Fourier transform is unlikely since the required cells with multi-lobed receptive fields are rare or non-existent. We examine the possibility of a wavelet transform and argue that this poses a dilemma since an over-determined basis set is required for shiftability, but this results in non-unique image representations. There is no reason to assume that reconstruction of the retinal image is a cortical objective. We show that if an image is sampled at a point by seven oriented filters it is possible to compute the exact orientation and centroid position. When the set of filters is applied at two different scales, it is possible to identify the stimulus type, its intensity and width. These computations are stable under image shifts in position and orientation and can be made to subpixel resolution
