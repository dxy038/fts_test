A control technique, periodic output feedback, is investigated in the context of linear quadratic regulation of finite-dimensional linear time-invariant systems. This control technique differs from conventional feedback schemes in that discrete output samples are multiplied by a periodic gain function to form a continuous feedback control signal. Necessary conditions that the optimal periodic output feedback gain function must satisfy are derived by two methods. The first method derives the necessary conditions directly using the minimum principle, but the complexity of the resulting conditions could prohibit their use. The second method derives necessary conditions in two steps. The first step is to solve what is called the continuous problem, which optimizes intersample performance when behavior at the sample times has been specified a priori. In the second step, the minimum value of the objective for the continuous problem is used to optimize the discrete performance of the closed-loop system. This alternate derivation has the advantage of avoiding the explicit solution of a two-point boundary value problem and effectively reduces the optimal control problem under periodic output feedback to a finite-dimensional nonlinear optimization problem. Numerical examples show that the performance of this method is sometimes nearly equivalent to that of optimal continuous state feedback
