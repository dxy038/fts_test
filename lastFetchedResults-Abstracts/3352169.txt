Wearable cameras are very useful for crowdsensing since they enhance the participation of crowds with less user interventions on manipulating cameras. However, stored videos are large and may fill up the storage space very soon, leading to dropped videos. In this paper, we propose Adaptive Transcoding Algorithm (ATA) to optimally transcode the stored videos on wearable cameras under resource constraints. In particular, we formulate an adaptive transcoding problem with empirical video transcoding and transmission models to maximize the overall perceived quality of video. The objective of our problem is to select a video representation (frame rate, resolution, and quantization parameter) that minimizes the quality degradation when transcoding the stored videos. We conduct extensive simulations using real datasets to compare the performance of our proposed ATA against other algorithms. The simulation results show that our ATA algorithm: (i) outperforms other baseline algorithms averagely 12 dB in terms of PSNR (Peak Signal-to-Noise Ratio), (ii) spends only 13% energy consumption on transcoding with efficient transcoding decisions, and (iii) achieves nearly 4 times of improvement on delay than the baseline.
