The objective of this research was to investigate a technique for machine learning that would be useful in solving problems involving forcing states. In games or control problems a forcing state is one from which the final goal can always be reached, regardless of what disturbances may arise. A program that learns forcing states in a class of games (in a game-independent format) by working backwards from a previous loss has been written. The class of positions that ultimately results in the opponent´s win is learned by the program (using a specially designed description language) and stored in its memory together with the correct move to be made when this pattern reoccurs. These patterns are searched for during future plays of the game. If they are formed by the opponent, the learning program blocks them before the opponent´s win sequence can begin. If it forms the patterns first, the learning program initiates the win sequence. The class of games for which the program is effective includes Qubic, Go-Moku, Hex, and the Shannon network games, including Bridge-it. The description language enables the learning program to generalize from one example of a forcing state to all other configurations that are strategically equivalent.
