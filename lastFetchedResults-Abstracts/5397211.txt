Maximum a posteriori (MAP)-based kernel classification trained by linear programming (MAPLP) has previously been proposed as a new approach to MAP-based classification. As opposed to conventional MAP-based approaches, MAPLP does not directly estimate a posteriori probabilities for classification, but instead introduces its surrogate function to an objective function that behaves similarly to a MAP-based classifier. In this paper, two extensions of MAPLP are proposed. In the first extension we add an adjustment parameter to one of the MAPLP constraints, and in the second extension we apply a difference-type objective function. Moreover, binary classification experiments are performed to assess the performance of the MAPLP extensions. The results are compared with those of the standard MAPLP as well as those of other state-of-the-art classification methods, such as support vector machines and kernel Fisher discriminant analysis. The experimental results not only demonstrate that the MAPLP extensions provide improved performance over standard MAPLP for a number of well-known datasets, they also perform promisingly against other classification methods.
