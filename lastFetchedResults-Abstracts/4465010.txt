This paper presents a target-filtering model to predict the movements of articulators for articulatory control of hidden Markov model (HMM) based speech synthesis. This model is a bidirectional filtering process on the time-aligned articulation target sequence. The bidirectional filtering could achieve both anticipatory coarticulation and regressive coarticulation. As all the parameters of the model have definite physical meaning, we can control the generation of the articulatory features flexibly with the guidance of articulatory phonetics. And the articulatory features produced by the target-filtering model can be adopted for a multiple regression HMM (MRHMM)-based parametric speech synthesis system. So we can control the pronunciation of vowels by articulatory features instead of the set of context features. Experimental results show that we can control the pronunciation among /&#920;/, /&#949;/, /&#230;/ effectively just by modifying the articulation targets.
