Pointing tasks, for example to select a target on a graphical user interface, form a significant part of humancomputer interactions. This has triggered a notable interest in intent prediction methods to reduce the pointing duration whilst using a mouse in a 2D set-up. In this paper, we introduce a Bayesian intentionality prediction approach for pointing in 3D environments. It infers the intended item on a touchscreen interface from the available partial userÂ´s pointing finger trajectory by utilising signal models that incorporate the destination. The pointing finger is continuously tracked using a Leap Motion controller. The objective is to improve the interactive display system usability in vehicle environments by enhancing the selection accuracy, expediting the system response and possibly providing feedback to the user as a form of assistive selection routine. The substantial gains furnished by applying the proposed predictors are demonstrated using data collected in a vehicle.
