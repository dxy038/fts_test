This paper presents a new framework for achieving superior visual quality in scalable video compression. In contrast with adaptive quantization strategies, our approach compensates for motion modeling deficiencies and alleviates temporal artifacts without needing to modify the decoder. The proposed technique works on the principle of post-compression distortion scaling and consists of two key steps. Perceptual analysis identifies regions in the frame, which are visually sensitive. Spatial mappings then incorporate the non-linear effects of the motion field, projecting the sensitivity information back into the subband domain along motion trajectories. The derived sensitivity maps are used to affect the codestream embedding order when quality layers are formed. The overall objective is to raise the distortion-length slope associated with low contrast regions, which are particularly susceptible to the unmasking of artifacts, so that they will be encoded with higher fidelity. This technique substantially improves the visual quality of structural elements that otherwise suffer significant degradation.
