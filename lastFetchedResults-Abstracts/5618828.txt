We consider the problem of identifying the optimal point of an objective in simulation experiments where the objective is measured with error. The best stochastic approximation algorithms exhibit a convergence rate of n<sup>-1/6</sup> which is somewhat different from the n<sup>-1/2</sup> rate more usually encountered in statistical estimation. We describe some simple simulation experimental designs that emphasize the statistical aspects of the process. When the objective can be represented by a Taylor series near the optimum, we show that the best rate of convergence of the mean square error is when the variance and bias components balance each other. More specifically, when the objective can be approximated by a quadratic with a cubic bias, then the fastest decline in the mean square error achievable is n<sup>-2/3</sup>. Some elementary theory as well as numerical examples will be presented
