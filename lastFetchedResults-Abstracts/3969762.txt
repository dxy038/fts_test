Addresses the control design problem for discrete-time, finite-state Markov decision processes, when both risk-neutral and minimax objectives are of interest. We introduce the mixed risk-neutral/minimax objective and utilize results from risk-neutral and minimax control to derive an information state process and dynamic programming equations for the value function. We synthesize optimal control laws both on the finite and the infinite horizons. We study the effectiveness of both the mixed risk-neutral/minimax family and the risk-sensitive family of controllers as tools to tradeoff risk-neutral and minimax objectives. We conclude that the mixed risk-neutral/minimax family is more effective, at the cost of increased controller complexity
