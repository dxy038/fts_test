A stochastic control scheme is developed for scalar, discrete-time, and linear-dynamic systems driven by Cauchy distributed process and measurement noises. When addressing the optimal control problem for such systems, the standard quadratic cost criteria cannot be used. In this study we introduce a new objective function that is functionally similar to the Cauchy probability density function. The performance index, defined as the expectation of this objective function with respect to the Cauchy densities, exists. The dynamic programming solution to the fixed and finite horizon optimal control problem that uses this performance index appears to be intractable. Therefore, a moving horizon optimal model predictive control problem is implemented, for which the conditional expected value of the objective function and its gradients can be computed in closed form and without assumptions such as certainty equivalence. Numerical results are shown for this m -step model predictive optimal controller and compared to a similar, Linear-Exponential-Gaussian model predictive controller. An essential difference between the Cauchy and Gaussian controllers when applied to a system with Cauchy noises is that, while the Gaussian controller is linear and reacts strongly to all noise pulses, the Cauchy controller can differentiate between measurement and process noise pulses by ignoring the former while responding to the latter. This property of the Cauchy controller occurs when an impulsive measurement noise is more likely than an impulsive process noise. The Cauchy and Gaussian controllers react similarly when applied to a system with Gaussian noises, demonstrating the robustness of the proposed control scheme.
