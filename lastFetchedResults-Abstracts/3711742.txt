A new stochastic optimization strategy is introduced which cascades many Metropolis-like procedures to sample a Boltzmann distribution at fixed temperatures. Global optimization of an objective f(x) in a certain class is shown to require O((&#916;/T<sub>low</sub>) <sup>2</sup>) computational effort where &#916;=max<sub>x,x´</sub>(f(x)-f(x´)) and T<sub>low</sub> is a low enough temperature that the Boltzmann function of f at T<sub>low</sub> acceptably small except for optimal x. This theoretical advantage is confirmed by experimental results which are presented for a problem in vector quantization and for seven standard test problems in nonlinear optimization
