In many modeling problems that are based on inputâ€“output data, information about a plethora of variables is available. In these cases, the proper selection of explanatory variables is very critical for the success of the produced model, since it eliminates noisy variables and possible correlations, reduces the size of the model and accomplishes more accurate predictions. Many variable selection procedures have been proposed in the literature, but most of them consider only linear models. In this work, we present a novel methodology for variable selection in nonlinear modeling, which combines the advantages of several artificial intelligence technologies. More specifically, the Radial Basis Function (RBF) neural network architecture serves as the nonlinear modeling tool, by exploiting the simplicity of its topology and the fast fuzzy means training algorithm. The proper variables are selected in two stages using a multi-objective optimization approach: in the first stage, a specially designed genetic algorithm minimizes the prediction error over a monitoring data set, while in the second stage a simulated annealing technique aims at the reduction of the number of explanatory variables. The efficiency of the proposed method is illustrated through its application to a number of benchmark problems.
