The goal of this study was to develop an automated and objective method to separate swallowing sounds from breath sounds. Swallowing sound detection can be utilized as part of a system for swallowing mechanism assessment and diagnosis of swallowing dysfunction (dysphagia) by acoustical means. In this study, an algorithm based on multilayer feed forward neural networks is proposed for decomposition of tracheal sound into swallowing and respiratory segments. Among many features examined, root-mean-square of the signal, the average power of the signal over 150-450 Hz and waveform fractal dimension were selected features applied to the neural network as inputs. Findings from previous studies about temporal and durational patterns of swallowing and respiration were used in a smart algorithm for further identification of the swallow and breath segments. The proposed method was applied to 18 tracheal sound recordings of 7 healthy subjects (ages 13-30 years, 4 males). The results were validated manually by visual inspection using airflow measurement and spectrogram of the sounds and auditory means. The algorithm was able to detect 91.7% of swallows correctly. The average of missed swallows and average of false detection were 8.3% and 9.5%, respectively. With additional preprocessing and post processing, the proposed method may be used for automated extraction of swallowing sounds from breath sounds in healthy and dysphagic individuals.
