We present a discriminant measure that can be used to determine the model complexity in a speech recognition system. In the speech recognition process, sub-phonetic classes are modelled as mixtures of Gaussians, and we present a new discriminant measure that uses the classification accuracy to determine in an objective fashion, the number of Gaussians required to best model the PDF of an allophone class. We compare the performance of this criterion with other criteria such as the Bayesian information criterion (BIC), and show that the BIC and the discriminative criterion lead to parsimonious models that provide the same word error rate performance as much larger baseline systems. However, this performance improvement depends on the size of the system, and there appears to be a crossover point beyond which both the BIC and the discriminative criterion are worse than a much simpler criterion. The discriminative criterion also enables this crossover point to be controlled by means of a threshold that is used in the criterion, and can lead to a better tradeoff of complexity versus word error rate
