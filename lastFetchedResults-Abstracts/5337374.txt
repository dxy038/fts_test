The objective of our study is to recognize the sign language and re-transcribe it into a written or oral language in order to make mobile communication possible between a deaf-mute and people who donÂ´t know the sign language. For that, we used a method of correlation based on a multi-decision segmented filter. The latter has been used for a long time to recognize a target image. However an adaptation of this technique is necessary to take into account particular characteristics of gestures and to be able to send it with a high transmission rate. Moreover, in this application the target image to recognize evolves/moves in real time. Thus to take the right decision, it is necessary to carry out a very large number of correlations therefore slowing down the translation process. To reduce this processing time, we propose, in this article, to implement our system by using the multi-station technique. This technique enables us to distribute the required computing effort on various parallel stations using (PVM) a parallel virtual machine. Our Results show that we succeeded in validating our system, using multidecision filtering and multi-station by using real gesture.
