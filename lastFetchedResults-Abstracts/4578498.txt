The main contribution of this paper is the presentation of a general scheduling framework for providing both QoS and fair-share in an autonomic fashion, based on 1) configurable utility functions and 2) RL as a model-free policy enactor. The main difference in our work is that we consider a multi-criteria optimization problem, including a fair-share objective. The comparison with a real and sophisticated scheduler shows that we could improve the most our RL scheme by accelerating the learning phase. More sophisticated interpolation (or regression) could speedup this phase. We plan to explore a hybrid scheme, where the RL is calibrated off-line by using the results of a real scheduler.
