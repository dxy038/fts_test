In several scientific areas, data are sampled irregularly and insufficiently due to practical and economical limitations. The use of such data in applications results in some artifacts and poor spatial resolution. Therefore, before being used, the data are to be interpolated onto a regular grid. One of the methods achieving this objective is based on the Fourier reconstruction, which deals with the under-determined system of equations. The Stagewise Orthogonal Matching Pursuit (StOMP) is a recently proposed greedy algorithm. Compared to the other recent algorithms like l<sub>1</sub>- minimization techniques, StOMP admits certain promising features such as faster and simpler implementation even in large scale settings. The present work applies StOMP to the Fourier-based interpolation problem for the signals that have sparse Fourier spectra. The basic objective is to verify empirically the performance of the algorithm if, and how far, the measurement coordinates can be shifted from uniform distribution on the continuous interval. Taking kurtosis as a quantifier for the deviation of distribution from being uniform, we show numerically that the measurement coordinates can be significantly shifted from uniform distribution.
