This paper proposes a perceptual system for communication of a partner robot based on computational intelligence. Basically, communication is restricted by the environment. Therefore, the robot should perceive the environment the robot is facing and communicates with human naturally. From this point of view, we propose the vision-based perceptual system for environmental learning. We also propose the learning method using bidirectional spiking neural networks for learning the relationship among the linguistic terms, gestures, and objects build on the environmental state. Furthermore, we show experimental results of a partner robot, MOBiMac
