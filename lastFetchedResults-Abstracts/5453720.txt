Machine learning algorithms are commonly used in real-world applications for solving complex problems where it is difficult to get a mathematical model. The goal of machine learning algorithms is to learn an objective function from a set of training examples where each example is defined by a feature set. Regularly, real world applications have many examples with many features; however, the objective function depends on few of them. The presence of noisy examples or irrelevant features in a dataset degrades the performance of machine learning algorithms; such is the case of k-nearest neighbor machine learning algorithm (k-NN). Thus choosing good instance and feature subsets may improve the algorithmÂ´s performance. Evolutionary algorithms proved to be good techniques for finding solutions in a large solution space and to be stable in the presence of noise. In this work, we address the problem of instance selection and feature weighting for instance-based methods by means of a genetic algorithm (GA) and evolution strategies (ES). We show that combining GA and ES with a k-NN algorithm can improve the predictive accuracy of the resulting classifier
