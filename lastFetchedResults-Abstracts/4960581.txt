The proliferation of image reconstruction algorithms imposes a need for an efficient and objective evaluation procedure for comparing the efficacy of different algorithms for a particular medical task. In assessing the relative task-oriented performance of reconstruction algorithms, it is desirable to assign statistical significance to claims of superiority of one algorithm over another. However, very often the achievement of statistical significance demands a large number of observations. Performing such an evaluation on mathematical phantoms requires a means of running the competing algorithms on projection data obtained from a large number of randomly generated phantoms. Thereafter, various numerical measures of agreement between the reconstructed images and the original phantoms may be used to reach a conclusion which has some statistical substance. Here, the authors illustrate the software SuperSNARK which automates an evaluation methodology for assigning statistical significance to the observed differences in performance of two or more image reconstruction algorithms. In particular, the authors compare the relative efficacy of the maximum likelihood expectation maximization algorithm and the filtered backprojection method for performing three specific imaging tasks in positron emission tomography
