A method for nonlinear function identification and its application to learning control are presented. The control objective is to identify and compensate for a nonlinear disturbance function. The nonlinear disturbance function is represented as an integral of a predefined kernel function multiplied by an unknown influence function. Sufficient conditions for the existence of such a representation are provided. The learning rule indirectly estimates the unknown function by updating an influence function estimate. It is shown that the controller achieves the disturbance cancellation asymptotically. The method is extended to the repetitive control of robot manipulators. Simulation and actual real-time implementation results using the Berkeley/NSK robot arm show that the proposed learning is more robust and converges at a faster rate than conventional repetitive controllers
