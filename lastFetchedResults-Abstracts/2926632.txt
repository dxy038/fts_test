Linear prediction is a major technique of signal processing and has been applied to many areas. Although nonlinear prediction has been investigated with some techniques such as multilayer backpropagation neural networks, the computational and storage expenses are usually very high. Moreover, they are deficient in nonlinear analysis, leading to no way to improvement but experimentally choosing parameters and sizes in ad hoc fashion. In this paper, the author presents new architectures for autoregressive prediction based upon statistical analysis of nonlinearity and design algorithm based on steepest descent scheme and correlation maximization. Instead of a fixed configuration, a prediction model begins with a linear model, then learns and grows to a more sophisticated structure step by step, creating a minimal structure for a certain objective. It adaptively learns much faster than existing algorithms. The model determines its own size and topology and retains a minimal structure. The proposed scheme is called generalized antoregressive prediction. This technique can be also applied to general ARMA nonlinear prediction. A new speech coding system using the generalised AR prediction is presented, which takes advantages of nonlinearity and parallelism of the proposed AR model. The system outperforms the corresponding linear coders
