Learning concept descriptions from data is a challenging, and inherently multi-objective, optimization problem. The model induced by the learner has to be complete, consistent and easily interpretable, and producing it should take few computational resources. These objectives are often conflicting and require thus some heuristics to be balanced. The classical approach is to combine all the objectives into a single scoring function that is used for guiding the search in the hypothesis space. However, we believe that a multi-objective approach is more appropriate for this problem. Evolutionary Algorithms (EAs) are particularly suited for solving multi-objective optimization problems. In this paper, we propose an improved version of the Evolutionary Concept Learner (ECL) system, called Multi-Objective ECL (MOECL). While the search performed by ECL is based on a single-objective EA, MOECL adopts a multi-objective search strategy. It uses two objectives independent of class distribution, the true positive rate and the true negative rate, and is inspired by the simple and effective Pareto-based optimization algorithm SPEA2 for fitness assignement. Experiments show that the results of the MOECL system are globally more accurate than those of ECL and of the other state-of-the-art systems, on propositional datasets and on one relational dataset. As such, we believe the MOECL system to constitute a promising approach towards a multi-objective and effective concept learner.
