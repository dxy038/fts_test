Neural network tree (NNTree) is a hybrid model for machine learning. The overall structure is a decision tree (DT), and each non-terminal node is an expert neural network (ENN). Generally speaking, NNTrees can achieve better performance than conventional DTs with fewer nodes, and the performance of the tree can be improved through incremental learning. In addition, the NNTrees can be interpreted in polynomial time if the number of inputs for each ENN is limited. In this paper, we propose a multiple objective optimization based genetic algorithm (MOO-GA) for designing interpretable and comprehensible NNTrees. The efficiency of the proposed algorithm is validated by experimental results.
