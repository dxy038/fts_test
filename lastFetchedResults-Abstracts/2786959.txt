In this paper, we show that for arbitrary stochastic linear dynamical systems, the problem of optimizing parameters of a feedback control policy can be cast as a convex optimization problem when a risk-averse objective (similar to LEQG) is used. The only restriction is a condition relating the control cost, risk factor and noise in the system. The resulting approach allows us to synthesize risk-averse controllers efficiently for finite horizon problems. For the standard quadratic costs in infinite horizon, the resulting problems become degenerate if the uncontrolled system is unstable. As an alternative, we propose using a discount-based approach that ensures that costs do not blow up. We show that the discount factor can effectively be used as a homotopy parameter to gradually synthesize stabilizing controllers for unstable systems. We also propose extensions where non-quadratic costs can be used for controller synthesis, and in this case, as long as the costs are bounded, the optimization problems are well-posed and have non-trivial solutions.
