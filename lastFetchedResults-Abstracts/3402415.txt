In this paper, we propose a novel algorithm to unify color appearances in different images for image stitching applications. Instead of utilizing either histogram-matching or pixel-matching, we integrate both of them with possible degree of alignment error in the overlap region taken into account. After the mismatched pixel pairs are removed using the histogram-matching result, a confidence-weighted voting-based iteration is used to further filtrate the pixel-matching result, then the color mapping function is estimated by polynomial fitting using singular value decomposition. In our objective experiments, the algorithm proves robust to large alignment errors. The algorithm has been tested on a real-life dataset, and its effectiveness is shown in the subjective experimental results. The algorithm is applicable in various situations since only three weak assumptions are made. Moreover, it can be applied in a different color space with a different mapping function model if needed
