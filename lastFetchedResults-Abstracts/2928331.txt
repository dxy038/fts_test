A speech enhancement technique is proposed, where auditory based properties of perception are investigated for the purpose of robust speech characterization and improved speech quality in additive background noise. Constraints based on a novel auditory spectral representation are developed in a dual-channel iterative Wiener filtering framework. The spectral representation model aspects of audition include critical band filtering, intensity to loudness conversion, and lateral inhibition. The auditory transformations and perceptual constraints are shown to result in an improved set of auditory constrained and enhanced linear prediction (ACE-LP) parameters. Objective measures and informal listening tests show improved speech quality for both white Gaussian and colored noise cases. The consistency of speech quality improvement is illustrated over time and across all phonemes from a set of phonetically labeled TIMIT database sentences
