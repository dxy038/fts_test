In a previous work, the author introduced inequality constraints into the Hopfield neural networks and clarified how to determine weights in the energy function. The author presently compares his method with the slack neuron method and shows that his method is superior because weights can be determined so that solutions not satisfying inequality constraints become unstable. Taking the <e1>n</e1>-queen problem as an example, the convergence to the optimal solution is studied. It is shown that for 4- and 5-queen problems, the selection of initial values around the line segment connecting the origin and (1, . . ., 1) almost always gives the optimal solution. For the 6-queen problem, however, the above selection shows poor convergence to the optimal solution. The reason is that for a small-sized problem, the region of initial values where the network converges to the optimal solution includes the neighborhood of the center of the hypercube. But as the size becomes larger, it does not. It is also shown that the convergence of the 6-queen problem is drastically improved by the introduction of a dummy objective function
