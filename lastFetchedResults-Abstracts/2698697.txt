This paper addresses a novel approach to the multimodal medical image fusion (MIF) problem, employing multiscale geometric analysis of the nonsubsampled contourlet transform and fuzzy-adaptive reduced pulse-coupled neural network (RPCNN). The linking strengths of the RPCNNsÂ´ neurons are adaptively set by modeling them as the fuzzy membership values, representing their significance in the corresponding source image. Use of the RPCNN with a less complex structure and having less number of parameters leads to computational efficiency-an important requirement of point-of-care health care technologies. The proposed scheme is free from the common shortcomings of the state-of-the-art MIF techniques: contrast reduction, loss of image fine details, and unwanted image degradations, etc. Subjective and objective evaluations show better performance of this new approach compared to the existing techniques.
