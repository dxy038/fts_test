In this paper, we study the problem of optimizing multi-objective decision-theoretic path planning. We transform this problem in a Markov decision process with a multi-dimensional value function. We also show that dealing with resource-bounded path planning consists of considering a complementary objective that is the minimization of resource consumption. We describe techniques that allow to derive an optimal policy where it is hard to express the expected utilities, rewards and values with a numerical measure. Firstly, we present approaches based on egalitarian social welfare techniques and secondly we examine different approaches based on preferences and we define notions of optimally with preferred solutions.
