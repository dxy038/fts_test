A self-organising architecture, loosely based upon adaptive resonance theory (ART) is used here as an alternative to the fixed decoder in the seminal implementation of reinforcement learning (RL) of Barto, Sutton and Anderson (BSA) (1983). The objective is to illustrate the possibility of adaptive controllers that partition state-space through experience. Input/output pattern pairs, desired state-space regions and neurocontroller size are not known in advance. Results show that, although learning is not smooth, the novel RL implementation is successful and learns a meaningful control mapping. This work indicates that such a self-organising approach to control is viable; further work will aim to improve system performance. The adaptive search element and the adaptive critic element of the original (BSA) study are retained.
