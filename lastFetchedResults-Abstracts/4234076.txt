The problem of stochastic optimization for arbitrary objective functions presents a dual challenge. First, one needs to repeatedly estimate the objective function, which, in the absence of closed-form expressions, is only possible through simulation. Second, one has to face the possibility of determining local, rather than global, optima. In this paper, we show how the stochastic comparison (SC) approach recently proposed in Gong et al. for discrete optimization can be used in continuous optimization. We prove that the continuous SC algorithm converges to an &#949; neighborhood of the global optimum for any &#949;&gt;0
