In this paper, we present a new classification method named multitask multiclass support vector machines based on the regularization principle. Our starting point is the recent success of multitask learning which has shown that learning multiple related tasks simultaneously can get better results than learning these tasks independently. We cast multitask multiclass problems as a constrained optimization problem with a quadratic objective function. Unlike most approaches which typically decompose a multitask multiclass problem into multiple multitask binary classification problems, our approach can learning multitask multiclass problems directly and effectively. This paper also derives the dual optimization which indicates the relations between tasks. The linear multitask multiclass learning method can be generalized to non-linear cases by the kernel trick. Experimental results indicate that the new approach can get encouraging results for multitask multiclass problems.
