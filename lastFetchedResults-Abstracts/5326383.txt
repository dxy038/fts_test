This paper describes a novel approach for estimating the best hypothesis of a given word lattice, the hypothesis lattice, using another word lattice, the reference lattice, and its application to large vocabulary automatic speech recognition. This approach selects the word sequence in the hypothesis lattice which maximizes a smoothed estimate of the word accuracy with respect to the reference lattice. It is shown in the paper that two algorithms similar to the Viterbi and the forward-backward algorithms can be used to estimate the hypothesis which approximately maximizes this objective function. We present in this paper two setups to test the performance of our approach. In the first setup, only one lattice is used as both the reference and the hypothesis lattices. In the second setup, two lattices produced by different systems are used to calculate the best hypothesis. In each setup, we test our approach on two Arabic broadcast news speech recognition tasks. Compared to the baseline results, up to 2.1% relative improvement in the word error rate (WER) is obtained by using our approach.
