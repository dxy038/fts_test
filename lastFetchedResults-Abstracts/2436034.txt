The polygonal approximation is an important topic in the area of pattern recognition, computer graphics and computer vision. This paper firstly proposes a new computational energy function to properly express the objective of the polygonal approximation problem based on competitive Hopfield neural network (CHNN), and then proposes a stochastic CHNN (SCHNN) by introducing stochastic dynamics into the CHNN to help the network escape from local minima. In order to further improve the performance of the SCHNN, a multi-start strategy or re-start mechanism is introduced. The multi-start strategy or re-start mechanism super-imposed on the SCHNN is characterized by alternating phases of cooling and reheating the stochastic dynamics, thus provides a means to achieve an effective dynamic or oscillating balance between intensification and diversification during the search. The proposed multi-start SCHNN (MS-SCHNN) is tested on a set of benchmark problems and several large size test instances. Simulation results show that the proposed MS-SCHNN is better than or competitive with several typical neural network algorithms such as CHNN and transiently chaotic neural network, metaheuristic algorithms such as genetic algorithms, and 12 commonly referred state-of-the-art algorithms specifically developed for the polygonal approximation. Furthermore, the chain codes and results of the proposed algorithm for the large size curves are also provided.
