Two preferred approaches to implement selection in many-objective optimization are based on scalarizing functions and &#949;-dominance. This work introduces a Chebyshev Achievement Function in the parent selection step of the Adaptive &#949;-Sampling &#949;-Hood many-objective optimizer and studies the combined effect of the exploitative power offered by the scalarizing function with the highly dynamic and explorative features of the many-objective optimizer. Two parent selection methods are investigated to exploit solutions closer to the ideal point of the dynamically changing neighborhoods created by the many-objective optimizer. These parent selection methods are compared with the random selection within the neighborhood method used by the original many-objective optimizer. The algorithms are tested using many-objective problems with unimodal and multimodal fitness functions, fixing the number of generations with various population sizes and fixing the number of evaluations using various combinations of number of generations and population size.
