In this paper, a revisited interval approach for linear regression is proposed. In this context, according to the Midpoint–Radius (MR) representation, the uncertainty attached to the set-valued model can be decoupled from its trend. The estimated interval model is built from interval input–output data with the objective of covering all available data. The constrained optimization problem is addressed using a linear programming approach in which a new criterion is proposed for representing the global uncertainty of the interval model. The potential of the proposed method is illustrated by simulation examples.
