In this paper, we present a post-processing method for musical noise suppression in enhanced speech recordings. The method uses pre-image iterations computed patch-wise on complex-valued spectral data of the enhanced signal to discriminate between speech and non-speech regions. From this knowledge, a binary mask is derived to suppress musical noise in the non-speech regions, where it is most disturbing. The method is evaluated using objective quality measures of the PEASS toolbox. These measures confirm that a suppression of artifacts and an increase in overall quality for several noise conditions is achieved.
