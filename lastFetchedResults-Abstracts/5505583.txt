Applications using grid computing infrastructure usually require resources allocation to satisfy their quality of service (QoS) requirements. Given that the grid infrastructure is a set of computing resources geographically distributed, the support of grid applications requires the allocation of computing resources and bandwidth to enable communication among these resources. The objective is to accommodate as many applications as possible while still satisfying their requirements. Ideally, we would like to accommodate a given Grid application using a set of computing resources (e.g., one server) that are not geographically distributed (e.g., in the same LAN); however, this is not always possible. Indeed, to increase the probability of accommodating grid applications, we may need to use computing resources scattered all over the network; in this case, bandwidth allocation is required to enable communication among these resources. In this paper, we propose an optimization model that enables the "simultaneous" allocation of computing resources and bandwidth for grid application while maximizing the number of grid applications being accommodated. A heuristic is proposed to solve the model with an acceptable response time; simulations show that the proposed approach outperforms existing classical approaches.
