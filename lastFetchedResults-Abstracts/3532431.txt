With the multiplication of satellite images with complementary spatial and spectral resolution, a major issue in the classification process is the simultaneous use of several images. In this context, the objective of this letter is to propose a new method which uses information contained in both spatial resolutions. The main idea is that on one hand, the semantic level associated with an image depends on its spatial resolution, and on the other hand, information given by these images is complementary. The goal of this multiresolution image method is to automatically build a classification using knowledge extracted from both images, by unsupervised way and without preprocessing image fusion. The method is tested by using a Quickbird (2.8 m) and a SPOT-4 (20 m) image on the urban area of Strasbourg (France). The experiments have shown that the results are better than a classical unsupervised classification on each image and comparable to a supervised region-based classification on the high-spatial-resolution image.
