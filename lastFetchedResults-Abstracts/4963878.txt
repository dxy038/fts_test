Summary form only given. Recent advances in robotics have been applied to automation in industrial manufacturing, with the primary purpose of optimizing practical systems in terms of such objective measures as accuracy, speed, and cost. This paper introduces the Artificial Emotional Creature project that seeks to explore a different direction that is not so rigidly dependent on such objective measures. The goal of this project is to explore a new area in robotics, with an emphasis on human-robot interaction. There is a large body of evidence that shows the importance of the interaction between humans and animals such as pets. We have been building a pet robot, as an implementation of an artificial emotional creature, with the subjective appearance of "behaviors" that are dependent on internal states, or "emotions", as well as external stimuli from both the physical environment and human beings. Human-robot interaction plays a large role. The pet robot has visual, audio, and tactile sensors. Olfactory sensors will also be available. The paper will describe an algorithm implementing a focus of attention through the integration of those sensors. In particular, object localization has been developed through the integration of vision and audition, using the interaction of a human being with the robot as the training reference.
