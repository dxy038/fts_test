In computer vision and image processing, image interpolation has been used widely to perform magnification by predicting missing details from a sampled image. Numerous techniques have been proposed to interpolate images and produce a better and clearly defined image. However, many conventional polynomial-based interpolation methods tend to smooth or blur out image details around the edges. Although a number of different interpolation techniques are available, all of them are somewhat limited in terms of their robustness and accuracy. In this paper, an edge-directed Lagrange time delay interpolation model is developed to confront the problem. The proficiency of the new technique is compared to some of the well-known conventional interpolation techniques. The newly proposed technique is shown to provide much better resultant images compared to the other conventional interpolation methods in terms of subjective and objective evaluations of mean squared error (MSE) and structural similarity (SSIM) tests.
