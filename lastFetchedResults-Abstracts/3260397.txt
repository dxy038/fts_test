With the increasing number of users of text to speech applications, high quality speech synthesis is required. However, only few researches concern Arabic text to speech applications. Compared with other languages such as English and French the quality of Arabic synthesis speech is still poor. For these reasons, we propose in this paper an Arabic text to speech synthesis system based on statistical parametric synthesis. Mel Frequency Cepstral Coefficients (MFCC), energy and pitch are predicted using back propagation artificial neural networks and then transformed into speech using Mel Log Spectrum Approximation filter. Often, in Arabic written text, the short vowels called diacritic marks are omitted. So, a diacritization system is proposed to resolve this problem. Different unit sizes are considered in speech database which are phoneme, diphone and triphone. MFCC neural network architecture and an objective evaluation with the MFCC distortion measure are given in this paper.
