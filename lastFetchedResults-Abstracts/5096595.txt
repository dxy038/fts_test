To regulate the output of a linear system subject to bounded persistent disturbance, the L<sub>1</sub>optimal controller is one of the available design techniques. In some situations, however, the rate of change may suitably describe the characteristic of the disturbance, in addition to the magnitude bound. The entire information results in the performance index called the worst-case norm (WCN) which has been proved beneficial to performance analysis of linear systems subject to disturbances with magnitude bound and rate limit. In this paper, we attempt to investigate further the benefit of the WCN in linear controller design. Two optimal controllers, namely, the L<sub>1</sub> optimal controller and the WCN optimal controller, are designed for a two-mass-spring-damper system. The numerical results suggest that the WCN minimization problem cannot be generally cast as the L<sub>1</sub>-norm minimization problem although it is known that the two norms interrelate. In addition, the simulation results show that the optimal controller based on the WCN objective yields better control performance, which implies a significant improvement in disturbance rejection
