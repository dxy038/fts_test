A human pose estimation method from monocular image captures is presented. The objective is to develop a human-computer interface (HCI) for virtual sport activities. In the proposed technique, a graphical 3D human model is first constructed. Its projection on a virtual image plane is then used to match the silhouettes obtained from the image sequence. By iteratively adjusting the 3D pose of the graphical 3D model with the physical and anatomic constraints of human motion, the human pose and the associate 3D motion parameters can be uniquely identified. Experimental results are presented with the real scene images.
