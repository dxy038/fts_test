The available remote sensing image fusion methods, such as that based on color space transform, on statistical (e.g. principle component analysis), on multi-scale analysis (e.g. pyramid decomposition, wavelet transform, etc.), basically set down the fusion rules before fusion process. The rules which determine the attributes of fusion results cannot be adjusted according to different application. In this paper, a framework based on data assimilation for multispectral and panchromatic image fusion is proposed. Data assimilation is to combine the observational data and simulative data to obtain more objective result which is firstly used in weather field. Under this framework, weights of different attributes are determined according to their importance degree to the following process and object function constituted by the weighted sum of each evaluation index is constructed. Finally, the object fusion is optimized through genetic simulated annealing to obtain the proper image. The experiments validate the feasibility of the framework.
