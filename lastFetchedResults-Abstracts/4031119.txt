We address the problem of the estimation of an unknown signal that is known to involve sharp edges, from noisy data given at the output of a linear system. The sought solution is defined to be the global minimizer of an objective function combining a quadratic data-fidelity term and a regularization term. The latter term is a sum whose entries are obtained by applying a truncated quadratic potential function to every difference between adjacent samples. Such objective functions are naturally formulated either in a statistical framework, or in a variational framework, and they are customarily used in signal and image reconstruction. However, these objective functions are nonsmooth and highly nonconvex, and many questions related to their minimization, as well as to the features of the resulting solutions, remain open. We present some new facts characterizing the features exhibited by the minimizers of such objective functions. Our main result states that the magnitude of the differences between adjacent samples of a global minimizer are either smaller than a first threshold or larger than a second, strictly larger threshold. Conversely, no difference corresponding to a global minimizer of the objective function can be placed among these thresholds for any data. This explains how edges are recovered in a signal and estimated using truncated quadratic regularization. These thresholds are independent of the data but are related to the observation system and to the regularization parameters. They can be used to derive necessary conditions for the choice of the regularization parameters. We also show that the chance to get data for which the objective function has two or more global minimizers is . Numerical experiments corroborate the obtained theoretical results.
