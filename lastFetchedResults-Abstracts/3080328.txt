Many classification tasks benefit from integrating manifold learning with semi-supervised learning. By formulating the learning task in a semi-supervised manner, we propose a novel objective function that combines the manifold consistency of whole dataset with the hinge loss of class label prediction. This formulation results in a SVM-alike task operating on the kernel derived from the graph Laplacian, and is capable of capturing the intrinsic manifold structure of the whole dataset and maximizing the margin separating labelled examples. Results on face and handwritten digit recognition tasks show significant performance gain. The performance gain is particularly impressive when only a small training set is available, which is often the true scenario of many real-world problems
