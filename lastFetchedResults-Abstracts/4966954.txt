This paper presents a Markov method of algorithmic efficiency. A production process can be in either a good or a bad state. The true state is unknown and can only be inferred from observations. If the state is good during one period it may deteriorate and become bad during the next period. Two actions are available: continue or replace (for a fixed cost). The objective is to maximize the expected discounted value of the total future profits. We prove that ldquodominance in expectationrdquo (the expected profit is larger in the good state than in the bad state) suffices for the optimal policy to be of a control limit (CLT) type: continue if and only if the good state probability exceeds the CLT. This condition is weaker than ldquostochastic dominancerdquo, which has been prevailing. We also show that the "expected profit function" is convex, strictly increasing.
