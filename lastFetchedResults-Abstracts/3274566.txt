In this paper, we present a saliency-based feature learning for general-purpose objective no-reference (NR) image quality assessment (IQA). To find the visual attention parts, we take saliency detection before feature extraction. These salient regions, attracted more visual attention, should be given more emphasis. Our method extracted raw-image-patches mainly from these salient parts instead of the whole image or random parts, then applied these salient patches to a no-reference image assessment based on codebook representation which does not assume any specific types of distortion. Experimental results on the LIVE image quality assessment database show that our method provides consistent and reliable performance in quality estimation. Compared with the original method, our method needs less patches to get the equivalent performance, furthermore, shows much higher correlation with subjective assessment in undistorted images.
