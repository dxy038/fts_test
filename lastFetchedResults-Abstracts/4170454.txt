A model reference adaptive control problem is posed. In the problem, the objective is not the usual one of forcing the error between the plant output and the reference model output asymptotically to zero, but instead, it is that of forcing this error to be less than a (arbitrarily small) prespecified constant after a (arbitrarily short) prespecified period of time, with a (arbitrarily small) prespecified upper bound on the amount of overshoot. It is shown that to achieve this goal for a stabilizable and detectable, single-input single-output linear time-invariant (LTI) plant, it is necessary and sufficient that the plant be minimum phase. Knowledge of an upper bound on the plant order, of the relative degree, and of the sign of the high-frequency gain is not required. The controller proposed consists of an LTI compensator together with a switching mechanism to adjust the compensator parameters. If an upper bound on the relative degree is available, the compensator has dynamics of order equal to this upper bound less one; otherwise, the order of the compensator is adjusted as well as its parameters
