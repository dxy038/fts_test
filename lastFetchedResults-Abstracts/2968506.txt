A hybrid learning algorithm that combines the genetic algorithm and steepest decent method is proposed for neural networks. Also described is a method for overcoming the Jacobian problem when the hybrid learning algorithm is applied to a neural network controller. In the proposed algorithm, a parallel search by the genetic algorithm and a continuous search by the steepest descent method are carried out sequentially. This may improve the convergence speed and solve the local minimum problem. In this approach, many neural network controllers are generated in the search process of the genetic algorithm. Potential functions, defined by both the control performance of each neural network controller and the reciprocal actions between the neural network controllers, are introduced into the neural networkÂ´s learning. This allows application of the steepest descent method without either the Jacobian information or the neural network identifier. Simulations were performed using a discrete-time SISO nonlinear system as the objective system. The results confirm the feasibility of the proposed method for the learning of the neural network controller
