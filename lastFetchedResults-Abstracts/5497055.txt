Emotion recognition in speech is an important research objective in the field of man-machine interfaces. This paper focuses on human labeling of emotions to create training data for emotion recognition systems. A three-dimensional emotion space concept is used to address the complexity of emotions in natural speech. As an evaluation tool, an iconic representation of each emotion component (self assessment manikins, SAMs) is proposed. This method is shown to be a simple and efficient means for evaluating emotions at an utterance-based segmentation level. The results show a high inter-evaluator agreement and a good reliability with the help of statistical signal modeling
