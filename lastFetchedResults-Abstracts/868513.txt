The data editing problem is concerned with identifying the most likely source of errors in computerized data bases. Given a record that is known to fail one or more ological consistency edits, the objective is to determine the minimum (possibly weighted) number of fields that could be changed in order to correct the record. While this problem can easily be formulated as a pure fixed-charge problem, it can be extremely difficult to solve under certain data conditions. In this paper we show how a number of structural characteristics in this problem can be exploited to dramatically reduce the computational time required to solve particularly difficult data edition problems.
