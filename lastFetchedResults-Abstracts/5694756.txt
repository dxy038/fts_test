A novel design technique for asynchronous binary neural networks is proposed. This design uses linear programming to design two architectures: (i) a fully connected network that reads a <e1>N</e1>-digit cue and classifies it into a category represented by a <e1>N</e1>-digit pattern: and (ii) a two-layer network (with lateral connections) that has <e1>M</e1> neurons in the first layer and <e1>L </e1> neurons in the second layer; the network reads an <e1>M</e1>-digit cue to the first layer and associates it with a second-layer <e1>L</e1>-digit pattern. In both cases, the objective function is a weighted sum of the number of errors that can be corrected by the network. A cue with this number of errors (or fewer) is guaranteed to converge to the correct pattern. An economical VLSI realization of the designed networks can be easily accomplished
