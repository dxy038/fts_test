We propose a method to reconstruct the depth map from multiple estimated depth maps relying on monocular cues. Based on extracted depth cues from luminance, chrominance, motion and texture, we obtain an optimal depth estimation by analytically deriving the best combinations. We first analyze a ground truth depth map to extract a set of depth cues. Then, using these depth cues, we process the colored reference video to reconstruct the depth map. We tested this approach on different video sequences with different monocular properties. The results show that the extracted depth maps generate a 3D video with quality close to the video rendered using the ground truth depth map. We report subjective and objective results using 3VQM.
