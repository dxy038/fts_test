In this paper we address the action spotting problem, that is the spatiotemporal detection and localization of an action. We first calculate a novel objective function between an input video sequence and an actionÂ´s weights tensor, as acquired from a Support Tensor Machine classifier. We subsequently search for an appropriate transformation that maximizes the objective function, calculated as the multiplication of the original input tensor with the weights tensor. The proposed algorithm is very fast, as the above mentioned multiplication involves a set of a separable filters applied along each mode. We demonstrate the effectiveness of our method with experiments in a publicly available database where we show that our method outperforms existing techniques in terms of spatiotemporal action localization.
