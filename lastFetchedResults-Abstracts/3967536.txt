Energy efficiency has been a longstanding design challenge for wearable sensor systems. It is especially crucial in continuous subject state monitoring due to the ongoing need for compact sizes and better sensors. This paper presents an energy-efficient classification algorithm, based on partially observable Markov decision process (POMDP). In every time step, POMDP dynamically selects sensors for classification via a sensor selection policy. The sensor selection problem is formalized as an optimization problem, where the objective is to minimize misclassification cost given some energy budget. State transitions are modeled as a hidden Markov model (HMM), and the corresponding sensor selection policy is represented using a finite-state controller (FSC). To evaluate this framework, sensor data were collected from multiple subjects in their free-living conditions. Relative accuracies and energy reductions from the proposed method are compared against nai&#776;ve Bayes (always-on) and simple random strategies to validate the relative performance of the algorithm. When the objective is to maintain the same classification accuracy, significant energy reduction is achieved.
