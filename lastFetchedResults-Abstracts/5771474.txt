In this paper, we study an optimal control problem for a nonlinear system with uncertainties. It is shown that a positive definite differentiable function is convertible into the function which approximates the solution of an Hamilton-Jacobi-Bellman (HJB) equation by multiplying a scalar value coefficient to be adjusted for each state. And it is shown that a Lyapunov function designed by an adaptive backstepping method is also convertible into the function which approximates the solution of an HJB equation with an unknown parameter and an adaptive law for each state. The proposed controller doesnpsilat give the minimum value of an objective function but it decreases the value of an objective function in comparison with a backstepping controller. The effectiveness of the proposed controller is shown by numerical examples.
