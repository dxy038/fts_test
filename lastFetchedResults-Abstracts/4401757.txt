In Still-to-Video (S2V)face recognition, only a few high resolution images are enrolled for each subject, while the probe is videos of complex variations. As faces present distinct characteristics under different scenarios, recognition in the original space is obviously inefficient. In this paper, we propose a novel discriminant analysis method to learn separate mappings for different scenarios (still, video), and further pursue a common discriminant space based on these mappings. Concretely, by modeling each video as a set of local models, we form the scenario-oriented mapping learning as an Image-Model discriminant analysis framework. The learning objective is formulated by incorporating the intra-class compactness and inter-class separability for good discrimination. Moreover, a weighted learning scheme is introduced to concentrate on the discriminating information of the most confusing samples and then further enhance the performance. Experiments on the COX-S2V dataset demonstrate the effectiveness of the proposed method.
