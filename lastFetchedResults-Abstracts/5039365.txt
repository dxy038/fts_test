In this work a natural interaction framework for programming a mobile robot with gestures is developed using two low-cost human interface devices available on the market. The use of natural motion has been growing among user interface researches and developers for offering comfortable ways of interacting with the devices around us. Some examples can be seen in how touch screens, accelerometers and image processing have influenced our interactions with cellphones, gaming devices and computers, thus, allowing us to take advantage of our body ergonomics. The objective of this work is to integrate an intuitive tool for teleoperating a mobile robot through gestures as an alternative input for encouraging non-experts to relate with robotics and ease navigation tasks. For accomplishing the objective of this work, the mobile robots programming architecture is studied and integrated with those of the user interfaces for allowing the teleoperation of the robotics device. To check how the implemented framework impacts the user interaction, a navigation scenario with obstacles is used for validating the suitability of the gesture-based navigation.
