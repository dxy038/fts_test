Although recently there has been many papers dealing with how to characterize and assess interpretability, there is still a lot of work to be done. Interpretability assessment is usually addressed by evaluating the complexity and/or readability of fuzzy rule-based systems. However, comprehensibility is usually not taken into account because it implies more cognitive aspects which are difficult to formalize and to deal with. In this work we show the importance of considering not only readability but also comprehensibility during the design process of fuzzy systems. We introduce the use of a novel index for evaluating comprehensibility in the context of a three-objective evolutionary framework for designing highly interpretable fuzzy rule-based classifiers. It is named as logical view index (LVI) and it is based on a semantic cointension approach. The proposed evolutionary algorithm consists of embedding the HILK (Highly Interpretable Linguistic Knowledge) fuzzy modeling methodology into the classical NSGA-II with the aim of maximizing accuracy, readability, and comprehensibility of the generated fuzzy rule-based classifiers. Our proposal is tested in the well-known PIMA benchmark problem which corresponds to a medical diagnosis problem where interpretability is a strong requirement.
