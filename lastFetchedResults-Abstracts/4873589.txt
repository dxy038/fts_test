A receding-horizon-type LQG control problem for switched linear systems is proposed and applied to the case of Markov switching. The objective is to determine a linear dynamic output feedback control law that minimizes a finite-horizon quadratic cost over all admissible future switching paths subject to almost sure uniform stability of the closed-loop system. A solution is determined by running a series of semidefinite programs offline until a saturation in achievable performance is reached.
