This study investigates the evaluation of machine learning models based on multiple criteria. The criteria included are: predictive model accuracy, model complexity, and algorithmic complexity (related to the learning/adaptation algorithm and prediction delivery) captured by monitoring the execution time. Furthermore, it compares the models generated from optimising the criteria using two approaches. The first approach is a scalarized multi objective optimisation, where the models are generated from optimising a single cost function that combines the criteria. On the other hand the second approach uses a Pareto-based multi objective optimisation to trade-off the three criteria and to generate a set of non-dominated models. This study shows that defining universal measures for the three criteria is not always feasible. Furthermore, it was shown that, the models generated from Pareto-based multi objective optimisation approach can be more accurate and more diverse than the models generated from scalarized multi objective optimisation approach.
