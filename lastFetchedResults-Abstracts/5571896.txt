Network management and control contribute to at least half of the operating cost of current optical networks. All-optical networks with end-to-end transparent lightpaths promise significant cost savings using optical switching at network nodes. However, this cost saving cannot be realized unless the cost of network management is also reduced. In this paper we explore a promising technique towards that goal. The fault diagnosis problem for all-optical networks is investigated via an information theoretic approach, with the objective to minimize the operating ´cost´ of failure detection and localization in the optical layer. Under a probabilistic link failure model, we first interpret the run-length probing scheme previously developed for Eulerian graphs as a constrained source-coding algorithm, and characterize its performance via the code rate of its corresponding run-length code. We then extend the run-length probing scheme to non-Eulerian graphs via two alternative approaches: the disjoint-trail decomposition approach and the path-augmentation approach, and obtain their performance analytically. The analytical and numerical results indicate that the run-length probing scheme is asymptotically optimum for both Eulerian and non-Eulerian graphs of large size. The property of the run-length probing scheme also suggests that each probe in an efficient probing scheme should provide approximately one bit of network state information and thus the total number of probes (or equivalently, the operating cost of failure identification) is lower-bounded and approximated by the entropy of the network states. We believe that our approach using information theory in an inter-disciplinary effort can provide new insights on network management, and substantial cost-reduction for all-optical networks can be realized
