We present the maximum normalized likelihood estimation (MNLE) algorithm and its application for discriminative training of hidden Markov models (HMMs) for continuous speech recognition. The objective of this algorithm is to maximize the normalized frame likelihood of training data. Instead of gradient descent techniques usually applied for objective function optimization in other discriminative algorithms such as the minimum classification error (MCE) and maximum mutual information (MMI), we used a modified expectation-maximization (EM) algorithm which greatly simplifies and speeds up the training procedure. Evaluation experiments showed better recognition rates compared, to both the maximum likelihood (ML) training method and MCE/GPD discriminative method. In addition, the MNLE algorithm showed better generalization abilities and was faster than MCE/GPD
