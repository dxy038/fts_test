Sensor placement for 3D modeling is a growing area of computer vision and robotics. The objective of a sensor placement system is to make task-directed decisions for optimal pose selection. We propose a next best view solution to the sensor placement problem. Our algorithm computes the next best view by optimizing an objective function that measures the quantity of unknown information in each of a group of potential viewpoints. The potential views are either placed uniformly around the object or are calculated from the surface normals of the occupancy grid model. To initiate the collection of new data, the optimal pose is selected from the objective function calculation. The model is incrementally updated from the information acquired in each new view. This process terminates when the number of recovered voxels ceases to increase, yielding the final model. We tested two different algorithms on 8 objects of various complexity, including objects with simple concave, simple hole, and complex hole self-occlusions
