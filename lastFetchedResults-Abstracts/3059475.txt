Model based control systems ate effective for making local process changes within n specific range of operation [I]. However, the existence of highly non-linear (NL) relationships between process input/output variables represents a serious difficulty to achieve reliable mathematical models [2, 10]. On the other hand, the implementation of intelligent control technology based on soft computing methodologies such as neural networks (NN) can remarkably enhance the regulatory and advanced control capabilities of many industrial processes [3, 8, 11]. Nevertheless, modelling the dynamic response of a multivariable (MV) and NL process by means of NN based hack propagation methodologies requires a priori deep knowledge regarding NN architectures related to a particular process. In this paper will be proposed and discussed the procedure to supervixe a process modelled by applying Hybrid Modelling (HM). The objective of this work is to describe a coherent methology for detect deviation between plant and model responses assming MV and NL processes. Such technique will be useful among other applications, in fault detection tasks, possibly to be applied on plant supervision. including transient state fault detection and decision making according the well known method based on parity equations and rule based residuals evaluation. The implementation of n NN model using back propagation algorithm [12, 13, 14] based on collection of real-time data for a steady state operation condition is presented. The main relevant topic of the contribution in this work is the utilisation of artificial neural networks (ANN) technology for the inferential analysis of performance in a wide range of industrial controlled plants. The proposed NNÂ´s architectures can accurately predict various properties associated with plant performance behaviour. The back-propagation network is the most popular feedforward predictive network deployed in process industries. The hack-propagation network assumes that a- l processing elements and connections are somewhat responsible for the difference of expected output and the actual output. The training algorithm is an iterate gradient descent algorithm designed to minimise the mean square error (RMS) between the actual output and the desired output. It requires a continuous differentiable non-linear search space, which will be achieved by storing proper (data selected under some specific criterion) data into a database.
