A traditional radial basis function (RBF) network takes Gaussian functions as its basis functions and adopts the least squares (LS) criterion as the objective function. However, it is difficult to use Gaussian functions to approximate constant values. If a function has nearly constant values in some intervals, the RBF network will be found inefficient in approximating these values. In this paper an RBF network which uses composite of sigmoidal functions to replace the Gaussian functions as the basis function of the network is proposed. It is also illustrated that the shape of the activation function can be constructed to be a similar rectangular or Gaussian function. Thus, the constant-valued functions can be approximated accurately by an RBF network. A robust objective function is also adopted in the network to replace the LS objective function. Experimental results demonstrated that the proposed network has better capability of approximation to underlying functions with a fast learning speed and high robustness to outliers
