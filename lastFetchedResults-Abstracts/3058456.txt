In this paper, voice commands based on natural spoken language are used so that two or more same colored objects are tracked by a robot manipulator. More precisely, after receiving a voice command regarding the color information, the end-effector of the robot is controlled to approach a desired object out of many objects by visual feedback, in which the visual information is further applied to the human if a more correct motion of the robot is required. Thus, the present objective is to obtain a smoother cooperative system between human and robot, by coordinating voice and visual information.
