Objective: Decision support provided to users is often lack of acceptance. One of the reasons is a deficit in understanding where the suggestions come from and how they come. This essentially is not a technical problem, but a technology adoption problem. This situation was also analyzed as a result of former empirical studies conducted on ReleasePlanner<sup>TM</sup>, a decision support tool for planning product releases. To overcome this situation, three machine learning techniques have been applied to mine the tool´s solutions, and the mining results are presented to the tool users as explanations. This paper presents the evaluation on the generated explanations as a means to improve the user acceptance of the tool. Method: A three-stage controlled experiment was designed and carried out with a group of ten graduate students at the University of Calgary and another group of five project managers from the IT industry. Two research goals were addressed to (i) evaluate the impact of the explanations generated from these three applied techniques, and (ii) compare some of the findings from this study with the ones from our previous experiments. Results: Our findings for the first research goal indicated that the explanations generated from the three techniques contributed to the improvement of the subjects´ confidence in the tool solutions and trust of the tool, and therefore an overall better user acceptance of the tool. Meanwhile, no significant differences were found among the impacts of the three techniques. For the second research goal, we found that some of the findings from this study were consistent with the ones from our previous experiments.
