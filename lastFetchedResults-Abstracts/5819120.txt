Many search techniques fail to account for the information obtained from previous objective function evaluations when determining a new set of control parameters. We present an empirical study of a neural net prescreener using a random and grid search however one may use the prescreener in combination with any search procedure. A single neural network model is extended through the usage hierarchical clustering to organize the search space into groups with a corresponding neural network model. Empirical tests indicate that a neural network prescreener is beneficial in significantly reducing the number of probes with a minimal cost to accuracy, an acceptable tradeoff given the high cost of executing complex objective functions. Specifically, a single neural network model is optimal given a random search. Hierarchical clustering using m separate neural network models outperforms, in terms of deviance and number of probes, the usage of a single model with respect to a grid search. The grid search provides a broader coverage of the search space, yielding more information regarding the search space
