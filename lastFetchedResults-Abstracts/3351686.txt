We combine model-based methods and distributed stochastic approximation to propose a fully distributed algorithm for nonconvex optimization, with good empirical performance and convergence guarantees. Neither the expression of the objective nor its gradient are known. Instead, the objective is like a &#8220;black-box&#8221;, in which the agents input candidate solutions and evaluate the output. Without central coordination, the distributed algorithm naturally balances the computational load among the agents. This is especially relevant when many samples are needed (e.g., for high-dimensional objectives) or when evaluating each sample is costly. Numerical experiments over a difficult benchmark show that the networked agents match the performance of a centralized architecture, being able to approach the global optimum, while none of the individual noncooperative agents could by itself.
