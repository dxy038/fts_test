We propose a new discriminative confidence measurement approach based on an evolution strategy for spoken term detection (STD). Our evolutionary algorithm, named evolutionary discriminant analysis (EDA), optimizes classification errors directly, which is a salient advantage compared with some conventional discriminative models which optimize objective functions based on certain class encoding, e.g. MLPs and SVMs. In addition, with the intrinsic randomness of the evolution strategy, EDA largely reduces the risk of converging to local minimums in model training. This is particularly valuable when the decision boundary is complex, which is the case when dealing with out-of-vocabulary (OOV) terms in STD. Experimental results on the meeting domain in English demonstrate considerable performance improvement with the EDA-based confidence for OOV terms compared with MLPs- and SVMs-based confidences; for in-vocabulary terms, however, no significant difference is observed with the three models. This confirms our conjecture that EDA exhibits more advantage for tasks with complex decision boundaries.
