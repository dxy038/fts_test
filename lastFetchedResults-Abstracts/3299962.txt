Choosing descriptive keywords to best describe digital media content is crucial for many applications, especially those involving content-based indexing or retrieval. Traditionally such keywords are selected manually, which is labor intensive, restrictive to a limited set of words and inherently subjective to the annotator. Therefore, in this paper, we propose an automatic and objective keyword selection method for annotating video. We specifically used lecture videos and surrogate documents, e.g. transcripts, to extract potential candidate keywords. These potential keywords are then filtered based on a set of seed words to select fewer but more descriptive keywords. The seed words are extracted from the title of the video and subject category. We propose a new objective method to select top ranking keywords based on visual similarity and word sense disambiguation. To validate this approach, the selected keywords are compared to subjectively selected keywords obtained experimentally. Furthermore, the proposed ranking method is also compared to traditional term frequency inverse document frequency (TF-IDF) and state of the art latent dirichlet allocation (LDA) method. The obtained results show that the words selected by the proposed objective method correlate highly with those selected by viewers. In general, the proposed method performs better than TF-IDF and LDA.
