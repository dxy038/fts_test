As the complexity of power plants increase, so does the difficulty in accurately modeling the interactions among the subsystems. Distributed sensing and control offers a possible solution to this problem, but introduces a new one: how to ensure that each subsystem satisfying its control objective leads to the safe and reliable operation of the entire power plant. In this work we present a distributed coordination algorithm that offers safe, reliable, and scalable control of a distributed system. In this approach, each system component uses a reinforcement learning algorithms to achieve its own objectives, but those objectives are derived to coordinate implicitly and achieve the system level objective. We show that in a Time-Extended Defect Combination Problem where the agents need to determine when and whether or not they should be sensing in order to maintain QoS in a system, the proposed method outperforms traditional methods by up to two orders of magnitude.
