When aiming at the automated reconstruction of real world scenes from range images, one has to address the problem of planning the image acquisition. Although solutions for small objects in well defined environments are already available, the insufficient scalability of these approaches to large scenes and to a high number of degrees of freedom limits their applicability. In this paper we present a new planning algorithm with emphasis on practical usability in initially unknown, large indoor environments. Using a surface representation of seen and unseen parts of the environment, we propose an objective function based on the analysis of occlusions. In addition to previous approaches, we take into account both a quality criterion and the cost of the next acquisition. By optimising this objective function, the parameters of the next view are computed efficiently for a large search space with eight degrees of freedom (3D position, viewing direction, field of view, and resolution). Our technique exploits hardware-accelerated rendering (OpenGL) in order to perform the expensive visibility computation, which reduces the computation time of one planning step to a couple of minutes. Results are shown for two large indoor scenes-an artificial scene and a real world room-with numerous self occlusions
