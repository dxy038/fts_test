An analog circuit testing is considered to be most difficult and time consuming in modern mixed signal circuits design cycle. Rapid development in semiconductor technology increases the density of circuit in the chip. Testing these circuits for defects and faults using transistor level simulations is not only extremely time consuming but also very costly in terms of computational resources. Therefore, efficient alternative techniques are proposed which increase the fault simulation speed to save overall verification time. One such technique recently introduced is high level fault modeling and simulation. This technique makes use of mathematical models automatically generated for linear or nonlinear responses and replicate exact behavior of original circuits. These linear and nonlinear responses are then mapped to fault-free and faulty circuits respectively and then simulations are compared with original transistor level fault-free and faulty simulations. The objective of this paper is to provide a critical survey on automated model generation techniques and analyze them for higher level modeling and high level fault modeling.
