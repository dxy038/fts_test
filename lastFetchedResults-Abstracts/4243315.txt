In this paper, fusion of visual and inertial information is proposed for attitude measurement of remotely-operated mobile robots. The primary objective is to eliminate the drift error of the inertial sensors using visual information for exact and fast sensing of attitude. By this fusion each output is not only combined together but also helps the other yield better result. The environment is assumed unknown and corner features are utilized for rotation matrix calculation, for corners are better extracted in nature scene than lines. The measured information is to be used for stabilizing the image sent to the operator and for stabilizing the robot body itself in bumpy terrain. In the paper, the fusion algorithm based on Kalman filter is utilized, and its performance is evaluated by experiment. For the experiment, high performance camera is used with low-quality gyro sensors. The experimental results show that the vision algorithm well tracks the attitude change of the camera, and by fusing that with gyro sensor output, we could get high rate angle measurement without drift error.
