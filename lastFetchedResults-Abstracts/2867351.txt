An important, long-term objective of intelligent robotics is to develop robots that can learn about and adapt to new environments. We focus on developing a learning model that can build up new knowledge through direct experience with and feedback from an environment. We designed and constructed Context-based Adaptive Robot Behavior-Learning Model (CARB-LM) which is conceptually inspired by Hebbian and anti-Hebbian learning and by neuromodulation in neural networks. CARB-LM has two types of learning processes: (1) context-based learning and (2) reward-based learning. The former uses past accumulated positive experiences as analogies to current conditions, allowing the robot to infer likely rewarding behaviors, and the latter exploits current reward information so the robot can refine its behaviors based on current experience. The reward is acquired by checking the effect of the robotÂ´s behavior in the environment. As a first test of this model, we tasked a simulated TurtleBot robot with moving smoothly around a previously unexplored environment. We simulated this environment using ROS and Gazebo and performed experiments to evaluate the model. The robot showed substantial learning and greatly outperformed both a hand-coded controller and a randomly wandering robot.
