Image fusion is the process of combining information from two or more images of a same scene into a single composite image that is more informative and is more suitable for visual perception or computer processing. The main objective of this paper is to implement the various pixel level fusion algorithms and to determine how well the information contained in the source images are represented in the fused images on multimodality and multifocusing images. Experiments and qualitative metrics dictate that Laplacian Pyramid method performs better on both multimodality and multifocusing images.
