We introduce a statistical shape descriptor for Sketch-Based Image Retrieval. The proposed descriptor combines feature information in near and far support regions defined for each sketch point. Two feature values are extracted from each point, corresponding to near and far support regions from the pointÂ´s perspective, and used to populate a 2-D histogram representing the shape features of the sketch image. The boundary between the support regions is calculated accordingly to each sketch point, which makes the approach scale invariant. We report results of objective evaluation of the proposed approach regarding robustness against noise, and comparative evaluation with three state-of-the-art methods, using an image database of scanned handwritten alphabets, digits, mathematical symbols and expressions. Experimental results show that the proposed method has competitive distinctiveness and robustness against noise.
