In this paper we develop a new dual decomposition method for optimizing a sum of convex objective functions corresponding to multiple agents but with coupled constraints. In our method we define a smooth Lagrangian, by using a smoothing technique developed by Nesterov, which preserves separability of the problem. With this approach we propose a new decomposition method (the proximal center method) for which efficiency estimates are derived and which improves the bounds on the number of iterations of the classical dual gradient scheme by an order of magnitude. The method involves every agent optimizing an objective function that is the sum of his own objective function and a smoothing term while the coordination between agents is performed via the Lagrange multipliers corresponding to the coupled constraints. Applications of the new method for solving distributed model predictive control or network optimization problems are also illustrated.
