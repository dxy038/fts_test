Wireless local area networks (WLAN) are increasingly important in meeting the needs of next generation broadband wireless communications systems for both commercial and military applications. For the IEEE 802.11a 5 GHz WLAN standard, orthogonal frequency-division-multiplexing (OFDM) was chosen as the modulation scheme for transmission because of its well-known ability to avoid multipath effects while achieving high data rates. The objective of this paper is to investigate the performance of the IEEE 802.11a WLAN standard receiver when the signal is transmitted over a frequency-selective, slow fading Nakagami channel in a worst case, pulse-noise interference environment. The different combinations of modulation type (both binary and non-binary modulation) and convolutional code rate specified by the WLAN standard are examined. Receiver performance with Viterbi soft decision decoding (SDD) is analyzed for additive white Gaussian noise (AWGN) plus pulse-noise interference (PNI). The performance of the IEEE 802.11a WLAN standard receiver is examined both for the scenario where perfect side information is assumed (optimum receiver) and when it is not (sub-optimum receiver). For the sub-optimum receiver scenario, the receiver performance is examined both when noise-normalization is utilized and when only linear combining is utilized. The receiver performance is severely affected by the pulse-noise interference environment for the linear combining scenario; however, the sub-optimum receiver performance is significantly improved when noise-normalization is implemented.
