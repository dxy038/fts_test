We present a new method for the incremental training of multiclass support vector machines that can simultaneously modify each class separating hyperplane and provide computational efficiency for training tasks where the training data collection is sequentially enriched and dynamic adaptation of the classifier is required over time. An auxiliary function has been designed, that incorporates some desired characteristics in order to provide an upper bound for the objective function, which summarizes the multiclass classification task. A novel set of multiplicative update rules is proposed, which is independent from any kind of learning rate parameter, provides computational efficiency compared to the conventional batch training approach and is easy to implement. Convergence to the global minimum is guaranteed, since the optimization problem is convex and the global minimizer for the enriched dataset is found using a warm-start algorithm. Experimental evidence on various data collections verified that our method is faster than retraining the classifier from scratch, while the achieved classification accuracy rate is maintained at the same level.
