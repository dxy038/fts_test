This paper presents a multi-objective optimisation by reinforcement learning, called MORL, to solve complex multi-objective optimisation problems, in particular those in a high-dimensional space. In MORL, the search is undertaken on individual dimension in a high-dimensional space via a path selected by an estimated path value. Path values, estimated by weighting the state values on the selected path, represent the potentiality of finding a better solution if searching on the paths, and are used to memorize the quality of previously visited states. In MORL, visited states are assigned with different immediate rewards by comparing the objective vector of current state with those of the Pareto optimal solutions found previously. These Pareto optimal solutions are stored in an elite list, which keeps track of the non-dominated solutions found so far and is used to construct the Pareto front at the end of the optimisation process. MORL is compared with a promising multi-objective evolutionary algorithm based on decomposition (MOEA/D) on four widely-used benchmark functions. The simulation results have demonstrated that MORL is superior over MOEA/D with respect to the accuracy and the range of the Pareto fronts, especially in solving high-dimensional multi-objective optimisation problems.
