Content-based image retrieval (CBIR) has been widely used in many medical applications by providing objective depictions and the initial screening to facilitate the manual interpretations by the radiologists. To achieve accurate retrieval results, relevance feedback is usually incorporated into CBIR to refine the retrieved items, but its effectiveness is restricted by the huge number of medical cases. Therefore, in this study we propose an automated feedback extraction method to exclude the involvement of radiologists. Instead of incorporating the feedbacks from them, the similarity relationship between the initial retrieval results and all candidate images is used to indicate the preferences of these retrieved items regarding to the query, i.e., relevance or irrelevance, and to further re-rank the candidates. The experimental results on a publicly available brain image dataset for neurodegenerative disorder diagnosis demonstrate the promising retrieval performance of the proposed method.
