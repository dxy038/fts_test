In our view, the most important characteristic of a fuzzy rule-based system is its readability, which is seriously affected by, among other things, the number of features used to design the rule base. Hence, for high-dimensional data, dimensionality reduction through feature selection (not extraction) is very important. Our objective, here, is not to find an optimal rule base for classification but to select a set of useful features that may solve the classification problem. For this, we present an integrated mechanism for simultaneous extraction of fuzzy rules and selection of useful features. Since the feature selection method is integrated into the rule base formation, our scheme can account for possible subtle nonlinear interaction between features, as well as that between features and the tool, and, consequently, can select a set of useful features for the classification job. We have tried our method on several commonly used datasets as well as on a synthetic dataset with dimension varying from 4 to 60. Using a ten-fold cross-validation setup, we have demonstrated the effectiveness of our method.
