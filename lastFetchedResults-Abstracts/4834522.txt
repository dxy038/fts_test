The problem of dynamic routing in multiple-service networks is studied. The authors consider a multirate circuit-switched broadband ISDN network that supports a variety of traffic classes with different traffic characteristics (bandwidth requirement, call arrival rate, and call holding time) and reward parameter. The task is to find a dynamic routing method which minimizes the long-run average cost of lost calls. Markov decision theory, with the objective of an average cost optimization is appropriate to the solution of this problem. Using this approach, they propose a distributed, state dependent, dynamic routing method which they call least cost routing in multiple-service networks (LCRM). They define a base policy such that the corresponding relative cost function associated with the Howard (1960) policy improvement routine of Markov decision theory is easily computed. This function is then used to determine the one-step policy improvement (LCRM)
