The design of evolutionary computations based on schema processing, minimizing expected losses, and emphasizing certain genetic operators has failed to provide robust optimization performance. Recently, fitness distribution analysis has been proposed as an alternative tool for exploring operator behavior and designing efficient evolutionary computations. For example, the step size of a single parent variation operator, such as the Gaussian mutation operator, determines the corresponding probability of finding better solutions and the expected improvement that will be obtained. The paper analyses the utility of Gaussian, Cauchy, and mean mutation operators when a parent is located near a local extrema of a continuous objective function that is to be optimized
