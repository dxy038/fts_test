We consider a scenario where a wireless sensor network is formed by randomly deploying n sensors to measure some spatial function over a field, with the objective of computing the maximum value of the measurements and communicating it to an operator station. We view the problem as one of message passing distributed computation over a geometric random graph. The network is assumed to be synchronous; at each sampling instant each sensor measures a value, and then the sensors collaboratively compute and deliver the maximum of these values to the operator station. Computation algorithms differ in the messages they need to exchange, and our formulation focuses on the problem of scheduling of the message exchanges. We do not exploit techniques such as source compression, or block coding of the computations. For this problem, we study the computation time and energy expenditure for one time maximum computation, and also the pipeline throughput. We show that, for an optimal algorithm, the computation time, energy expenditure and the achievable rate of computation scale as &#920;(&#8730; n/log n), &#920;(n) and &#920;(1/log n) asymptotically (in probability) as the number of sensors n&#8594;&#8734;. We also analyze the performance of three specific computational algorithms, namely, the tree algorithm, multihop transmission, and the ripple algorithm, and obtain scaling laws for the computation time and energy expenditure as n&#8594;&#8734;. Simulation results are provided to show that our analysis indeed captures the correct scaling; the simulations also yield estimates of the constant multipliers in the scaling laws. Our analyses throughout assume a centralized scheduler and hence our results can be viewed as providing bounds for the performance with a distributed scheduler.
