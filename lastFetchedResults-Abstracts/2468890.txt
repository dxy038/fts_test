The purpose of image fusion is to combine the source images of the same scene into a single composite image with more useful information and much better visual effects, which is undoubtedly suitable for further image processing tasks. This paper presented a novel fusion method for visible light and infrared images based on non-subsampled shearlet transform (NSST)–spatial frequency (SF)–pulse coupled neural network (PCNN). As a recently developed multi-resolution geometric analysis tool, NSST not only has remarked superiorities over other past conventional tools in terms of information capturing and computational costs saving, but also overcomes the lack of shift-invariance in shearlet transform (ST), so NSST applies to conducting the decompositions and reconstructions. Besides, traditional PCNN model is also upgraded to be an improved one called IPCNN in this paper to fuse the low-frequency and high-frequency subband coefficients. In the IPCNN structure, on the one hand, the value of the linking strength β is determined by the SF which represents the gradient features of the subband image; on the other hand, the time matrix is utilized to adaptively decide the iteration number of the IPCNN model, which is helpful to increase the function efficiency and save computational resources. Experimental results indicate that the proposed method performs well and has obvious superiorities over other current typical ones in both subjective visual performance and objective criteria.
