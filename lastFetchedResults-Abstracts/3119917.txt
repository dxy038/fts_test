Persistent surveillance and reconnaissance tasks in mobile cooperative sensor networks are key to constructing recognized domain pictures over a variety of civilian and military problem instances. However, efficient information gathering for a task such as target search by a team of autonomous unmanned aerial vehicles (UAVs) still remains a major challenge to achieve system wide performance objective. Given problem complexity, most proposed distributed target search solutions so far consider simplifying assumptions such as predetermined path planning coordination strategy with implicit communication and ad hoc heuristics, and severely constrained resources. In this paper, we extend previous work reported on multiUAV target search by learning resource bounded multiagent coordination, involving explicit action control coordination. The approach first relies on a new information theoretic coevolutionary algorithm to solve cooperative search path planning over receding horizons, providing agents with mutually adaptive and self-organizing behavior. The anytime algorithm is coupled to an extended information sharing policy to periodically exchange world state information and projected agent intents. Preliminary results show the value of the proposed approach in comparison to existing techniques or methods.
